{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/zhuo/notebooks', '/home/zhuo/miniconda3/lib/python37.zip', '/home/zhuo/miniconda3/lib/python3.7', '/home/zhuo/miniconda3/lib/python3.7/lib-dynload', '', '/home/zhuo/miniconda3/lib/python3.7/site-packages', '/home/zhuo/mz-ds-deep-learning/ds-kubeflow', '/home/zhuo/miniconda3/lib/python3.7/site-packages/IPython/extensions', '/home/zhuo/.ipython', '/home/zhuo/time_lstm/time_lstm_modules']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import json\n",
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from tensorflow.keras.models import Model\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "import seaborn as sns\n",
    "\n",
    "module_path = '/home/zhuo/time_lstm/time_lstm_modules'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "if 'TimeLSTM' in sys.modules:\n",
    "    importlib.reload(sys.modules['TimeLSTM'])\n",
    "    \n",
    "from TimeLSTM import TimeLSTM0\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './event_sequence_data_20200607_hour_08.json'\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[0]\n",
    "raw_data_small = raw_data[:500000]\n",
    "neg_data = []\n",
    "pos_data = []\n",
    "\n",
    "for r in raw_data_small:\n",
    "    if r['fraud_prob'] > 0:\n",
    "        pos_data.append(r)\n",
    "    else:\n",
    "        neg_data.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "event_types = []\n",
    "labels = []\n",
    "\n",
    "vocab = ['na', 'start', 'view', 'click', 'install']\n",
    "str2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2str= np.array(vocab)\n",
    "\n",
    "for row in raw_data_small:\n",
    "    _event_type_list, _time_list = list(zip(*row['sequence']))\n",
    "    _event_type_list = tuple(str2idx[c] for c in _event_type_list)\n",
    "    # drop missing times for data points 5096332 and 8959733\n",
    "    # otherwise cause problems in creating embeddings\n",
    "    if not any(_time_list): \n",
    "        continue\n",
    "        \n",
    "    labels.append(row['fraud_prob'])    \n",
    "    event_types.append(_event_type_list)\n",
    "\n",
    "    times.append(_time_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_len = 20 \n",
    "padding_type = 'post'\n",
    "truncating_type = 'pre'\n",
    "\n",
    "# padding event types\n",
    "padded_event_types = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    event_types, \n",
    "    padding=padding_type, \n",
    "    truncating = truncating_type,\n",
    "    maxlen=padding_len,\n",
    "    value=0,\n",
    "    dtype=object,\n",
    ")\n",
    "padded_event_types = padded_event_types.astype(int)\n",
    "\n",
    "#padding time stamps\n",
    "padded_ts = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    times, \n",
    "    padding=padding_type, \n",
    "    truncating = truncating_type,\n",
    "    maxlen=padding_len,\n",
    "    value=0,\n",
    "    dtype=object,\n",
    ")\n",
    "padded_ts = padded_ts.astype(int)\n",
    "padded_ts = np.diff(padded_ts, axis=1, prepend=0)\n",
    "padded_ts = padded_ts.astype(np.float64)\n",
    "padded_ts = padded_ts.clip(0) # remove negative numbers\n",
    "padded_ts = padded_ts.reshape((DATA_SIZE,20,1))\n",
    "\n",
    "padded_event_types = padded_event_types.reshape((DATA_SIZE,20,1))\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "train_data_discriminator = padded_event_types,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change to difference of times\n",
    "# # print(padded_ts)\n",
    "# padded_ts = np.diff(padded_ts, axis=1, prepend=0)\n",
    "# print(padded_ts.shape)\n",
    "# # padded_ts[:,0] = 0\n",
    "# print(padded_event_types)\n",
    "# print(padded_event_types.shape)\n",
    "# non_zero_ts = padded_ts[padded_ts!=0]\n",
    "# non_zero_ts[0:100]\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(non_zero_ts, columns=['ts'])\n",
    "# df.quantile([.1, .2, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 20\n",
    "# temp = padded_event_types[0:10, :] # batch of 5 rows\n",
    "# temp_ts = padded_ts[0:10, :].astype(float)\n",
    "# temp = temp.reshape((10,20,1))\n",
    "# temp_ts = temp_ts.reshape((10,20,1))\n",
    "# embed0 = Embedding(input_dim=len(vocab), output_dim=16, input_length=20)(temp)\n",
    "# embed0 = Reshape((T, 16))(embed0)\n",
    "# print(embed0.shape)\n",
    "# print(temp_ts.shape)\n",
    "# tf.keras.layers.concatenate([embed0, temp_ts], axis=2).shape\n",
    "# z = tf.zeros([10,1])\n",
    "# print(z.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM for fraud/non-fraud\n",
    "\n",
    "TODO:\n",
    "1. masking loss - gaussian mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  15.]\n",
      "  [  28.]\n",
      "  [ 110.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]]\n",
      "\n",
      " [[ 103.]\n",
      "  [  19.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]]\n",
      "\n",
      " [[ 150.]\n",
      "  [ 133.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]]\n",
      "\n",
      " [[3897.]\n",
      "  [  30.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]]\n",
      "\n",
      " [[ 189.]\n",
      "  [  30.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]\n",
      "  [   0.]]], shape=(5, 20, 1), dtype=float64)\n",
      "[<tf.Tensor: shape=(5, 1), dtype=float64, numpy=\n",
      "array([[0.50183764],\n",
      "       [0.50199193],\n",
      "       [0.50166201],\n",
      "       [0.50198927],\n",
      "       [0.50198927]])>, <tf.Tensor: shape=(5, 20, 5), dtype=float64, numpy=\n",
      "array([[[-1.69433131e+02, -1.69433131e+02, -1.69433131e+02,\n",
      "         -1.69433131e+02, -1.69433131e+02],\n",
      "        [-5.73340505e+02, -5.73340505e+02, -5.73340505e+02,\n",
      "         -5.73340505e+02, -5.73340505e+02],\n",
      "        [-8.67896091e+03, -8.67896091e+03, -8.67896091e+03,\n",
      "         -8.67896091e+03, -8.67896091e+03],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01]],\n",
      "\n",
      "       [[-7.61244827e+03, -7.61244827e+03, -7.61244827e+03,\n",
      "         -7.61244827e+03, -7.61244827e+03],\n",
      "        [-2.68027562e+02, -2.68027562e+02, -2.68027562e+02,\n",
      "         -2.68027562e+02, -2.68027562e+02],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01]],\n",
      "\n",
      "       [[-1.61146342e+04, -1.61146342e+04, -1.61146342e+04,\n",
      "         -1.61146342e+04, -1.61146342e+04],\n",
      "        [-1.26755080e+04, -1.26755080e+04, -1.26755080e+04,\n",
      "         -1.26755080e+04, -1.26755080e+04],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01]],\n",
      "\n",
      "       [[-1.08366489e+07, -1.08366489e+07, -1.08366489e+07,\n",
      "         -1.08366489e+07, -1.08366489e+07],\n",
      "        [-6.56884068e+02, -6.56884068e+02, -6.56884068e+02,\n",
      "         -6.56884068e+02, -6.56884068e+02],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01]],\n",
      "\n",
      "       [[-2.55626031e+04, -2.55626031e+04, -2.55626031e+04,\n",
      "         -2.55626031e+04, -2.55626031e+04],\n",
      "        [-6.56884068e+02, -6.56884068e+02, -6.56884068e+02,\n",
      "         -6.56884068e+02, -6.56884068e+02],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01],\n",
      "        [-8.43159713e-01, -8.43159713e-01, -8.43159713e-01,\n",
      "         -8.43159713e-01, -8.43159713e-01]]])>]\n"
     ]
    }
   ],
   "source": [
    "gm = tfd.MixtureSameFamily(\n",
    "    mixture_distribution=tfd.Categorical(\n",
    "        probs=[0.3, 0.7]),\n",
    "    components_distribution=tfd.Normal(\n",
    "      loc=[-1., 1],       # One for each component.\n",
    "      scale=[0.1, 0.5]))  # And same here.\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# x = np.array([1., 2., 3.])\n",
    "# gm.log_prob(x)\n",
    "padded_ts = padded_ts.astype(np.float64)\n",
    "padded_ts = padded_ts.reshape((DATA_SIZE,20,1))\n",
    "padded_event_types = padded_event_types.reshape((DATA_SIZE,20,1))\n",
    "\n",
    "features = (padded_event_types, padded_ts)\n",
    "labels = tf.reshape(labels, (labels.shape[0],1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "dataset = dataset.shuffle(1000).batch(5, drop_remainder=True)\n",
    "\n",
    "for features, labels_batch in dataset.take(1):\n",
    "    print(features[1])\n",
    "    print(model_a(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from TimeLSTM import TimeLSTM0,TimeLSTM1\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "DATA_SIZE = 500000\n",
    "T = 20\n",
    "batch_size = 3\n",
    "emb_dim = 2\n",
    "\n",
    "# Time-LSTM:\n",
    "i_et = Input(shape=(T,1), name='event_type')  # input of discrete feature event type\n",
    "i_ts = Input(shape=(T,1), name='time_delta')  # input of continuous feature timestamp\n",
    "mask_layer = tf.keras.layers.Masking(mask_value=0., input_shape=(20, 1))\n",
    "masked_ts = mask_layer(i_ts)\n",
    "\n",
    "\n",
    "embed0 = Embedding(input_dim=len(vocab), output_dim=emb_dim, input_length=20, mask_zero=True,\n",
    "                   batch_input_shape=[batch_size, None])(i_et) \n",
    "embed0 = Reshape((T, emb_dim))(embed0) # shape=[Batch_size, 20, 16]\n",
    "merged0 = tf.keras.layers.concatenate([embed0, masked_ts], axis=2) # # shape=[Batch_size, 20, 17]\n",
    " \n",
    "hm, tm = TimeLSTM1(11, activation='selu',name='time_lstm', return_sequences=False)(merged0)\n",
    "\n",
    "# tfp.layers.MixtureNormal(num_components, event_shape)\n",
    "\n",
    "# gaussian mixture for time delta\n",
    "k_mixt = 4\n",
    "alpha = Dense(k_mixt, activation=tf.nn.softmax, name='dense_alpha')(tm)\n",
    "mu = Dense(k_mixt, activation=None, name='dense_mu')(tm)\n",
    "sigma = Dense(k_mixt, activation=tf.nn.softplus,name='dense_sigma')(tm)\n",
    "\n",
    "gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(\n",
    "        probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu, \n",
    "            scale=sigma))\n",
    "\n",
    "gaussian_log = gm.log_prob(masked_ts)# apply gaussian mixture to time stamp input\n",
    "\n",
    "\n",
    "# mask out zeros in time stamps\n",
    "mask = tf.not_equal(i_ts, 0)\n",
    "# gaussian_log = tf.boolean_mask(gaussian_log, mask)\n",
    "# time_delta = tf.boolean_mask(i_ts, mask)\n",
    "\n",
    "# predicted fraud prob\n",
    "fraud_prob = Dense(1, activation='sigmoid',name='fraud_prob')(hm)\n",
    "\n",
    "model_a = Model(\n",
    "    inputs=[i_et, i_ts], \n",
    "    outputs=[fraud_prob, gaussian_log, mask])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-LSTM, Gaussian Mixture Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian loss:15248.62127204096\n",
      "ce loss:0.6838910608126113\n",
      "gaussian loss:837670.7940127664\n",
      "ce loss:0.6798526977813342\n",
      "gaussian loss:67090.2120733248\n",
      "ce loss:0.680894297030113\n",
      "gaussian loss:24016.24264319472\n",
      "ce loss:0.6777660461798083\n",
      "gaussian loss:58183.866730547445\n",
      "ce loss:0.674238942549801\n",
      "gaussian loss:6840.653428318783\n",
      "ce loss:0.6675149081665823\n",
      "gaussian loss:3202.2699570307004\n",
      "ce loss:0.6750465567215094\n",
      "gaussian loss:20660.73261036247\n",
      "ce loss:0.6735704623185312\n",
      "gaussian loss:279378.48142471845\n",
      "ce loss:0.6597374641230456\n",
      "gaussian loss:19272.726542199332\n",
      "ce loss:0.6692251111586622\n"
     ]
    }
   ],
   "source": [
    "padded_ts = padded_ts.astype(float)\n",
    "padded_ts = padded_ts.reshape((DATA_SIZE,20,1))\n",
    "padded_event_types = padded_event_types.reshape((DATA_SIZE,20,1))\n",
    "\n",
    "features = (padded_event_types, padded_ts)\n",
    "labels = tf.reshape(labels, (labels.shape[0],1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "dataset = dataset.batch(2, drop_remainder=True)\n",
    "loss_history = []\n",
    "optimizer=Adam(lr=0.001)\n",
    "step = 0\n",
    "for features, labels_batch in dataset.take(10):\n",
    "    step+=1\n",
    "    with tf.GradientTape() as tape:\n",
    "        fraud, gaussian_log, mask = model_a(features)\n",
    "\n",
    "#         print(features[1])\n",
    "#         print('tm:{}'.format(tm))\n",
    "#         tk = [weight for weight in model_a.weights if 'time_kernel' in weight.name or 'kernel' in weight.name]\n",
    "#         print(tk)\n",
    "\n",
    "        # calculate masked neg-likelihood of gaussian mixture\n",
    "        gaussian_log = gaussian_log[:, :, 0:1]\n",
    "        gaussian_log = tf.boolean_mask(gaussian_log, mask)\n",
    "        gaussian_loss = -tf.reduce_sum(gaussian_log)\n",
    "        \n",
    "#         if step % 20 == 0:\n",
    "        print('gaussian loss:{}'.format(gaussian_loss))\n",
    "\n",
    "        # cross-entropy loss\n",
    "        ce_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(labels_batch, fraud, from_logits=False))\n",
    "        print('ce loss:{}'.format(ce_loss))\n",
    "        loss = gaussian_loss + ce_loss\n",
    "\n",
    "    loss_history.append(loss.numpy())\n",
    "#     print('loss:{}'.format(loss.numpy()))\n",
    "    grads = tape.gradient(loss, model_a.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model_a.trainable_variables))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_38/embeddings:0' shape=(5, 2) dtype=float64, numpy=\n",
       " array([[-0.02151689, -0.04787551],\n",
       "        [-0.00688214, -0.02538904],\n",
       "        [ 0.0124458 , -0.01309143],\n",
       "        [-0.04435949, -0.00242425],\n",
       "        [-0.02345365, -0.01344005]])>,\n",
       " <tf.Variable 'time_lstm_37/kernel:0' shape=(2, 55) dtype=float64, numpy=\n",
       " array([[-0.16818848, -0.21087809, -0.22806658, -0.26310317, -0.24522198,\n",
       "         -0.06905912, -0.14820319,  0.22563678,  0.23102878, -0.1627863 ,\n",
       "          0.28359145,  0.225874  , -0.31267888,  0.23602   ,  0.18284113,\n",
       "          0.01467   ,  0.00039855,  0.25259223,  0.04528701, -0.21784292,\n",
       "         -0.05647369, -0.24919943, -0.10974888,  0.15210987, -0.16133483,\n",
       "          0.07617964,  0.25685094, -0.00735286,  0.05622808, -0.02743135,\n",
       "          0.16001266,  0.04340784,  0.29236078, -0.13053473, -0.24728411,\n",
       "          0.27190462,  0.01817999, -0.2820276 , -0.25442428, -0.12716735,\n",
       "          0.00435673,  0.02105494,  0.03828799,  0.28983733, -0.27843832,\n",
       "         -0.05542784,  0.1667366 , -0.00112557,  0.177879  , -0.31020294,\n",
       "         -0.09615596,  0.15107373,  0.11882387,  0.03733901, -0.10026639],\n",
       "        [-0.03122151,  0.12779981, -0.14730479, -0.0459813 ,  0.22827733,\n",
       "          0.03621252, -0.13714453,  0.11156232,  0.10783829, -0.24471879,\n",
       "          0.00180417, -0.03053945,  0.02490738, -0.2162335 ,  0.01148076,\n",
       "         -0.03515207, -0.03436203,  0.10555518,  0.25226079,  0.03735725,\n",
       "         -0.21442683, -0.15517372,  0.00350938,  0.10078249, -0.02917257,\n",
       "         -0.12424   , -0.04897316,  0.12799813, -0.12661632, -0.01416067,\n",
       "          0.27390541,  0.00136933, -0.18715809, -0.19562546,  0.25873398,\n",
       "          0.26272039, -0.20179872, -0.19742546,  0.11809942,  0.10544194,\n",
       "          0.25966662, -0.09856356,  0.20773133, -0.1716441 , -0.00356512,\n",
       "         -0.21728263,  0.02505359, -0.28442206, -0.0361788 ,  0.1298841 ,\n",
       "          0.16687282,  0.03305703, -0.20923009,  0.12608301, -0.24278805]])>,\n",
       " <tf.Variable 'time_lstm_37/time_kernel:0' shape=(1, 22) dtype=float64, numpy=\n",
       " array([[ 0.4972599 ,  0.03903327, -0.07302172,  0.42710184,  0.38742745,\n",
       "         -0.23493495,  0.43169219, -0.29166846, -0.39326724,  0.43455009,\n",
       "         -0.20174547,  0.33807857, -0.49593288,  0.14016985, -0.03882418,\n",
       "         -0.27350918, -0.37522042,  0.15254362,  0.21523804, -0.1412543 ,\n",
       "         -0.08048706, -0.25909051]])>,\n",
       " <tf.Variable 'time_lstm_37/recurrent_kernel:0' shape=(11, 44) dtype=float64, numpy=\n",
       " array([[ 2.66606158e-01, -1.15914324e-02,  9.12132839e-02,\n",
       "         -6.81224764e-02,  1.90931728e-01,  1.14335681e-01,\n",
       "         -7.41594228e-02,  6.31882231e-02,  7.95679041e-02,\n",
       "          7.01857963e-02, -2.40856534e-01, -2.95363599e-01,\n",
       "          5.55932812e-02, -4.10530099e-02,  7.23604362e-02,\n",
       "          1.83839921e-01,  6.85456822e-02,  1.56263493e-01,\n",
       "          9.61440146e-02, -7.76857931e-02, -5.13588578e-02,\n",
       "         -1.89175343e-01, -5.60492619e-02, -2.80092228e-01,\n",
       "          2.55210355e-03,  7.35242102e-02, -1.84043509e-01,\n",
       "         -6.67060036e-03, -9.19463389e-02, -4.06692217e-02,\n",
       "         -1.34652700e-01,  4.99279611e-02,  7.93820067e-02,\n",
       "          1.21201705e-01,  3.79882761e-01, -1.44824929e-03,\n",
       "          5.44700934e-02,  1.35335213e-01, -5.11131972e-02,\n",
       "         -3.34677044e-01,  1.12576659e-01, -1.49117277e-01,\n",
       "          6.05887052e-02, -2.86275114e-01],\n",
       "        [ 1.86950995e-01, -5.34117617e-02,  4.78078850e-02,\n",
       "          7.58470957e-02,  1.22666741e-01,  1.24088113e-01,\n",
       "          1.25119127e-01, -1.68194933e-01, -1.33529806e-01,\n",
       "         -2.67426465e-01,  2.40948826e-01,  1.91088790e-02,\n",
       "          9.35226045e-02,  3.91704121e-03, -7.98705559e-02,\n",
       "         -1.68121291e-01, -2.73416743e-01,  3.48818847e-03,\n",
       "          5.43463330e-02, -2.71137340e-01,  1.61039620e-01,\n",
       "         -2.23517508e-02,  2.08019833e-01, -1.60054045e-01,\n",
       "         -9.90901544e-02,  1.14302263e-01, -3.73535178e-02,\n",
       "          2.54203574e-02, -2.01718108e-01,  2.41003641e-01,\n",
       "         -8.99102501e-02, -1.31088598e-01,  1.86185058e-01,\n",
       "         -1.17409437e-01,  1.89098997e-01,  2.60783671e-01,\n",
       "          4.56462116e-02,  2.79001422e-02, -2.15240203e-02,\n",
       "          2.46716372e-02, -1.76330617e-01,  2.93044641e-01,\n",
       "         -1.39700220e-01,  2.73286732e-02],\n",
       "        [-1.22998212e-01, -2.47617906e-02, -3.66722381e-04,\n",
       "          3.03046055e-01, -3.45240053e-01, -1.72960741e-01,\n",
       "         -9.13510066e-02, -2.48018908e-01, -2.45047344e-01,\n",
       "          7.09881180e-02,  3.49141428e-02, -1.29378036e-01,\n",
       "         -2.49862511e-01, -1.53528307e-01, -8.23180921e-02,\n",
       "          7.85204534e-02,  6.16168315e-02, -1.65700090e-01,\n",
       "          1.23640560e-01, -1.07262301e-01,  1.89031385e-02,\n",
       "          2.28390313e-01, -9.22616990e-02, -1.64606424e-01,\n",
       "          1.88987722e-01, -5.48958009e-02,  2.19658854e-01,\n",
       "          6.90409999e-02,  1.36092684e-01, -1.76090913e-01,\n",
       "         -1.73842199e-01, -1.34241986e-01,  3.26346940e-02,\n",
       "          1.79716976e-02,  1.43772141e-01,  2.44062539e-01,\n",
       "         -4.59743126e-02,  9.34275952e-02,  3.92980923e-02,\n",
       "         -2.34221524e-01, -5.70098328e-02, -3.07182931e-02,\n",
       "          5.75293905e-03, -5.17670978e-02],\n",
       "        [ 7.45827649e-02,  3.02291663e-01, -5.89947073e-02,\n",
       "          2.13479069e-01,  1.30878872e-01, -2.93686545e-02,\n",
       "         -2.57242946e-02,  2.58582825e-01, -2.03038786e-01,\n",
       "          1.40528887e-02, -2.38086324e-02,  1.60739813e-02,\n",
       "         -9.15203025e-02,  5.02972570e-02,  4.77563009e-02,\n",
       "         -1.80856863e-01, -1.67616717e-01, -1.46887217e-01,\n",
       "         -6.20385023e-02,  4.41337722e-02,  8.25701800e-02,\n",
       "          4.92654514e-03, -4.43059612e-02,  1.02905648e-01,\n",
       "         -1.59160760e-01,  7.01954671e-02, -7.88342653e-02,\n",
       "         -2.40560953e-01,  2.58816464e-01,  5.66677028e-02,\n",
       "         -1.67178101e-01,  3.39917082e-02, -4.76036278e-01,\n",
       "         -1.84699614e-02,  2.46979565e-01, -9.38213710e-03,\n",
       "          1.81069588e-01,  1.71269442e-01, -4.32691923e-02,\n",
       "         -3.05628358e-03, -1.85766240e-01, -1.34860177e-01,\n",
       "         -7.26684547e-02,  4.84570748e-02],\n",
       "        [ 1.85292813e-01,  3.04383893e-01, -3.03837187e-02,\n",
       "         -2.57187608e-01, -2.28010123e-02, -1.27355723e-01,\n",
       "         -3.04256025e-02, -7.46709946e-02,  1.22936475e-01,\n",
       "         -1.24561100e-01, -1.02590965e-02,  1.78023055e-02,\n",
       "         -3.03554928e-03, -5.02379928e-02,  1.75612772e-01,\n",
       "          1.13903243e-02, -3.70723889e-02,  1.42667039e-02,\n",
       "          3.92461253e-02,  7.33276873e-02, -7.13677210e-02,\n",
       "          1.44989992e-01,  1.14470308e-01, -1.91275687e-01,\n",
       "          3.15046199e-03, -5.73464618e-02,  1.66576965e-01,\n",
       "         -2.61173769e-01,  1.72930943e-02, -1.43419142e-01,\n",
       "         -2.51360106e-01, -1.50907872e-01,  7.42523345e-02,\n",
       "          1.57520520e-01,  1.24358818e-01,  4.74605288e-02,\n",
       "          9.35149435e-02, -3.34048422e-01, -1.92756389e-01,\n",
       "          7.77804728e-02,  1.49075719e-01,  2.66648002e-02,\n",
       "          1.90922401e-01,  3.95849779e-01],\n",
       "        [-3.71374997e-03, -1.18655806e-01, -8.81316674e-02,\n",
       "          2.71609235e-02,  7.74889926e-02,  5.24596284e-02,\n",
       "         -3.98222991e-02, -8.66971406e-02, -3.67807428e-01,\n",
       "          4.64432397e-02, -6.41330696e-02, -1.72130404e-01,\n",
       "          1.60781147e-01,  1.25007252e-02,  9.20977178e-02,\n",
       "          2.45255877e-01, -4.27011262e-02,  1.93720051e-01,\n",
       "          1.90972692e-01, -4.77176450e-04,  1.50467005e-01,\n",
       "         -1.68659652e-01,  9.64311130e-02,  3.63641346e-01,\n",
       "          1.44346387e-01,  3.22273954e-01,  1.51013963e-02,\n",
       "         -9.54565106e-02, -1.03575465e-01, -1.16724442e-01,\n",
       "         -4.90620469e-02, -3.83939181e-01, -6.40188066e-02,\n",
       "          4.91667987e-02, -1.50382062e-01, -3.13200442e-03,\n",
       "          1.00615182e-01, -2.48610547e-03,  9.24148726e-02,\n",
       "          6.64923795e-02, -2.85079313e-02, -1.21091415e-01,\n",
       "          1.68106803e-01,  1.48150143e-01],\n",
       "        [-6.71672032e-02,  3.13890544e-01,  1.37980604e-01,\n",
       "          1.39154136e-01, -1.83233741e-01,  1.30171530e-02,\n",
       "         -4.35337599e-02, -3.43112116e-01,  5.21913750e-02,\n",
       "         -1.19944692e-01, -1.55494222e-02, -1.18946710e-02,\n",
       "         -1.30130247e-01, -6.31511319e-02,  1.06520794e-01,\n",
       "          9.08626764e-02,  7.38168352e-04,  4.53979880e-02,\n",
       "          2.60217819e-01,  2.12652658e-01,  1.50637435e-01,\n",
       "         -2.44263997e-01, -7.94999805e-03,  7.78475321e-02,\n",
       "         -1.19877911e-01, -6.85316484e-02, -3.13045859e-01,\n",
       "          2.96458991e-01,  8.92717555e-02,  7.28260599e-02,\n",
       "          1.04315557e-01,  7.85065216e-02,  5.54006883e-02,\n",
       "         -1.32601724e-01,  2.38528329e-01, -2.38345947e-02,\n",
       "          8.74106016e-02, -5.59771483e-02,  8.17965211e-02,\n",
       "          2.91691769e-01,  1.14183529e-01, -9.83243931e-02,\n",
       "          3.61332342e-02,  6.29711401e-02],\n",
       "        [ 4.77360496e-02,  3.18190205e-02,  9.81205182e-02,\n",
       "          2.00195443e-01,  8.04822629e-03, -1.75426712e-01,\n",
       "         -6.79900810e-02, -1.11775739e-01, -1.72194185e-01,\n",
       "         -2.15475313e-01,  2.50730665e-02,  5.96022848e-02,\n",
       "          3.70608648e-01, -8.21533860e-02, -1.05626720e-01,\n",
       "          8.37890068e-02,  2.40754537e-01,  1.37888425e-01,\n",
       "         -3.46937481e-01, -3.52804638e-02, -3.43403000e-02,\n",
       "         -6.27727710e-02,  2.94085370e-02, -1.72083414e-01,\n",
       "         -3.01458785e-01, -3.01801578e-01,  1.01762961e-01,\n",
       "          4.15802714e-02,  4.04653269e-02,  7.66955540e-02,\n",
       "          7.68928987e-02, -1.86028352e-01,  7.70218607e-03,\n",
       "          2.34392098e-01, -2.23336921e-02, -1.64723222e-01,\n",
       "          1.00536232e-01,  1.62575209e-01,  1.51353741e-01,\n",
       "          2.25832913e-02, -6.66464076e-02, -1.45617327e-01,\n",
       "          9.22649128e-02,  6.47779671e-02],\n",
       "        [-8.90481375e-02,  1.36212882e-01,  3.44778351e-01,\n",
       "          6.60608230e-02,  2.51484030e-02, -1.01912283e-01,\n",
       "          1.64697883e-01,  6.36110436e-02, -2.11824946e-01,\n",
       "          2.69767160e-01, -6.68786592e-02, -1.89199636e-01,\n",
       "          3.38145560e-03, -1.14546686e-02,  4.66435696e-01,\n",
       "         -1.14253932e-01, -2.54088353e-02,  6.02556218e-02,\n",
       "         -1.42946735e-01, -1.18395623e-01, -1.35672148e-02,\n",
       "          1.34949415e-01, -1.44559903e-02, -3.80707468e-02,\n",
       "          1.03218276e-01,  7.06799111e-02,  9.00049001e-02,\n",
       "          2.38725600e-01,  7.26369297e-02,  2.80958436e-01,\n",
       "         -1.11135836e-02, -3.38010211e-02,  1.00538514e-01,\n",
       "          1.21396568e-01, -1.23293016e-01, -1.26339526e-01,\n",
       "          1.58448261e-01, -7.94301802e-02, -2.15031298e-01,\n",
       "          1.21183675e-01,  2.93027272e-02,  1.55141491e-01,\n",
       "          1.06652513e-02, -1.47521566e-01],\n",
       "        [ 1.98415993e-01, -1.06898045e-01,  1.80696558e-01,\n",
       "         -1.17888533e-01, -1.95535719e-01, -7.92115732e-02,\n",
       "         -1.11855178e-01, -2.07876376e-01,  1.00073815e-01,\n",
       "          2.91685924e-02,  1.07409326e-01,  4.80965852e-02,\n",
       "         -1.18600274e-01, -1.35271242e-01,  1.37124418e-01,\n",
       "         -1.84898629e-01,  4.24152677e-02, -1.00812306e-02,\n",
       "         -9.43814138e-02,  1.28189617e-01,  2.64745844e-01,\n",
       "         -1.25765026e-01,  1.14910373e-01, -1.16293185e-01,\n",
       "         -4.21049858e-02,  3.08349800e-01,  1.39976857e-01,\n",
       "         -4.23176002e-02, -1.31564758e-01, -2.19749467e-01,\n",
       "          2.83725350e-01,  1.29619718e-01, -2.05102355e-01,\n",
       "          1.28773446e-01, -5.03117489e-02, -1.55387616e-01,\n",
       "          2.40732316e-01, -1.07394414e-01,  6.78755514e-02,\n",
       "         -1.96825519e-01, -2.43594728e-01,  6.42254867e-03,\n",
       "         -1.03272548e-01, -5.73040379e-02],\n",
       "        [ 6.56157175e-02,  1.94927952e-02,  2.12185723e-01,\n",
       "          4.56948253e-02,  2.00891374e-01, -1.06986496e-01,\n",
       "         -7.09040471e-03, -1.22001309e-01, -8.87081989e-02,\n",
       "          1.64476844e-01,  2.46233402e-01,  9.25197709e-02,\n",
       "         -1.04641115e-01,  2.72463812e-01,  9.60058875e-02,\n",
       "          1.17923107e-01,  1.61027446e-01,  8.33757278e-02,\n",
       "          1.87783090e-02, -4.77461995e-02,  1.62914290e-01,\n",
       "         -1.84811014e-01, -3.37013991e-01, -1.43470828e-01,\n",
       "          8.36246466e-02, -1.30658205e-01, -9.77622844e-02,\n",
       "         -2.89445425e-01, -1.02746215e-01, -1.58122777e-01,\n",
       "         -8.04267579e-02,  2.39362588e-01,  4.98633505e-02,\n",
       "          9.97294749e-02, -1.63070867e-01,  2.41380093e-01,\n",
       "         -1.09704412e-01,  1.30159047e-01, -5.44069988e-02,\n",
       "          2.42795781e-01, -1.65992890e-01,  2.73665630e-02,\n",
       "          6.04864472e-02,  5.08823018e-02]])>,\n",
       " <tf.Variable 'time_lstm_37/bias:0' shape=(55,) dtype=float64, numpy=\n",
       " array([ 5.75608815e-04,  9.35682419e-05, -7.15299637e-04, -5.30317817e-04,\n",
       "         3.61636513e-04,  6.38141174e-04,  9.69998036e-04,  3.13174161e-04,\n",
       "         8.93086078e-04,  2.02721176e-04,  7.83845244e-04,  1.00084234e+00,\n",
       "         1.00006248e+00,  9.99249040e-01,  9.99218091e-01,  9.99949853e-01,\n",
       "         1.00055664e+00,  1.00098000e+00,  9.99172325e-01,  1.00084061e+00,\n",
       "         1.00010500e+00,  1.00076729e+00, -9.99994055e-04, -9.88983461e-04,\n",
       "        -9.99965186e-04, -9.99507214e-04, -9.99507386e-04, -9.99449569e-04,\n",
       "         9.99987315e-04, -9.99978512e-04, -9.99688826e-04, -9.99782914e-04,\n",
       "         9.99699432e-04,  1.04843038e-04,  9.54348044e-04,  3.21668542e-04,\n",
       "        -7.99302844e-04,  5.55145652e-04,  8.77286144e-04,  5.48417197e-04,\n",
       "         1.73161184e-04,  9.25061364e-04,  5.58388991e-04,  8.82906484e-04,\n",
       "        -1.00000004e-03,  1.00000005e-03,  1.00000005e-03, -1.00000005e-03,\n",
       "        -1.00000004e-03,  1.00000005e-03,  1.00000005e-03, -1.00000005e-03,\n",
       "         1.00000004e-03,  1.00000005e-03, -1.00000004e-03])>,\n",
       " <tf.Variable 'time_lstm_37/input_gate_peephole_weights:0' shape=(11,) dtype=float64, numpy=\n",
       " array([-0.26069045, -0.02026408, -0.29276418, -0.49437352, -0.20567516,\n",
       "         0.31580686, -0.14909903,  0.28244434, -0.3832535 , -0.27155732,\n",
       "        -0.05247784])>,\n",
       " <tf.Variable 'time_lstm_37/forget_gate_peephole_weights:0' shape=(11,) dtype=float64, numpy=\n",
       " array([ 0.2762575 , -0.47161964,  0.15857568, -0.165901  ,  0.36634682,\n",
       "         0.48859754,  0.28491596,  0.01826156,  0.33633293,  0.12974974,\n",
       "         0.46293976])>,\n",
       " <tf.Variable 'time_lstm_37/output_gate_peephole_weights:0' shape=(11,) dtype=float64, numpy=\n",
       " array([-0.23159249, -0.09937231, -0.42111886, -0.06451672,  0.4662388 ,\n",
       "         0.13469438,  0.46321943, -0.45676049,  0.0828633 , -0.03442067,\n",
       "         0.02871044])>,\n",
       " <tf.Variable 'dense_sigma/kernel:0' shape=(11, 4) dtype=float64, numpy=\n",
       " array([[ 0.59230917, -0.10983299, -0.20302727,  0.49893497],\n",
       "        [-0.07384239,  0.40740034, -0.20836649,  0.04604706],\n",
       "        [ 0.12244956,  0.50079204,  0.06659303, -0.51688745],\n",
       "        [ 0.19794687, -0.40004407,  0.39906758, -0.58167933],\n",
       "        [ 0.3436083 , -0.17444513,  0.05328487, -0.32195045],\n",
       "        [-0.43176361,  0.54123921, -0.16489463,  0.22942942],\n",
       "        [-0.07589034,  0.30802404,  0.49886261, -0.30239436],\n",
       "        [-0.46451621, -0.41194661,  0.53620357, -0.13411791],\n",
       "        [-0.08468407,  0.10989329, -0.16899577,  0.13189727],\n",
       "        [ 0.16591185,  0.59501041, -0.18629859, -0.56718617],\n",
       "        [ 0.48757342, -0.17229438, -0.35229426, -0.20246489]])>,\n",
       " <tf.Variable 'dense_sigma/bias:0' shape=(4,) dtype=float64, numpy=array([9.99999852e-04, 1.00000005e-03, 9.95345133e-04, 9.43287116e-36])>,\n",
       " <tf.Variable 'dense_mu/kernel:0' shape=(11, 4) dtype=float64, numpy=\n",
       " array([[-0.153405  ,  0.18289027, -0.62972502,  0.4176795 ],\n",
       "        [-0.17166948,  0.26753361, -0.0942796 ,  0.36453189],\n",
       "        [-0.11930068, -0.43216875, -0.43285037, -0.36710326],\n",
       "        [-0.08754823, -0.56362748,  0.40760278, -0.50235752],\n",
       "        [-0.12570635,  0.3615741 ,  0.38312542, -0.17578734],\n",
       "        [ 0.10045888, -0.01388302,  0.26312744,  0.26949785],\n",
       "        [ 0.60149229,  0.36652266, -0.11528978,  0.46328909],\n",
       "        [-0.31218832, -0.48052891, -0.19172276,  0.5368796 ],\n",
       "        [-0.476263  , -0.28024853,  0.42465857,  0.05792211],\n",
       "        [-0.04137932, -0.49860639, -0.1397437 , -0.00791639],\n",
       "        [ 0.50658767, -0.61048777, -0.36490822,  0.41906412]])>,\n",
       " <tf.Variable 'dense_mu/bias:0' shape=(4,) dtype=float64, numpy=array([9.99999339e-04, 1.00000004e-03, 9.83605331e-04, 2.62826813e-36])>,\n",
       " <tf.Variable 'dense_alpha/kernel:0' shape=(11, 4) dtype=float64, numpy=\n",
       " array([[ 0.25772059, -0.15824183,  0.3088252 , -0.11588349],\n",
       "        [-0.27544034,  0.37291697,  0.0380295 , -0.03537676],\n",
       "        [ 0.52739193,  0.26138433,  0.12060167,  0.36533799],\n",
       "        [ 0.15532489,  0.61628987,  0.44381463, -0.06440871],\n",
       "        [-0.43822193, -0.09139862,  0.43718927,  0.34002018],\n",
       "        [ 0.45612264, -0.52312261, -0.3252555 , -0.37630937],\n",
       "        [ 0.1642795 ,  0.53898156, -0.23739533, -0.00557338],\n",
       "        [ 0.15948121,  0.48461158,  0.08689999, -0.31358345],\n",
       "        [-0.42093359, -0.19668323, -0.40371602,  0.55359264],\n",
       "        [ 0.4851072 , -0.29872687, -0.53212297,  0.44723525],\n",
       "        [ 0.08422942, -0.40262287, -0.50114992,  0.0897469 ]])>,\n",
       " <tf.Variable 'dense_alpha/bias:0' shape=(4,) dtype=float64, numpy=array([-0.001,  0.001, -0.001, -0.001])>,\n",
       " <tf.Variable 'fraud_prob_32/kernel:0' shape=(11, 1) dtype=float64, numpy=\n",
       " array([[ 0.63767385],\n",
       "        [-0.13722932],\n",
       "        [ 0.2274004 ],\n",
       "        [ 0.31769829],\n",
       "        [-0.08538515],\n",
       "        [ 0.06521728],\n",
       "        [-0.32201881],\n",
       "        [ 0.25741049],\n",
       "        [-0.01062495],\n",
       "        [-0.22021516],\n",
       "        [ 0.5339344 ]])>,\n",
       " <tf.Variable 'fraud_prob_32/bias:0' shape=(1,) dtype=float64, numpy=array([-0.00099999])>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator with CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer gru is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 20, 1, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-556dba2a8708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     recurrent_initializer='glorot_uniform')(outputs)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# embed0 = Reshape((T, 16))(embed0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 737\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer gru is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 20, 1, 16]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "T = 20\n",
    "batch_size = 1\n",
    "# time LSTM usage example:\n",
    "i_et = Input(shape=(T, 1))  # input of discrete feature event type\n",
    "i_ts = Input(shape=(T, 1))  # input of continuous feature timestamp\n",
    "\n",
    "outputs = Embedding(input_dim=len(vocab), output_dim=16, input_length=20, batch_input_shape=[batch_size, None])(i_et)\n",
    "outputs = tf.keras.layers.GRU(32,\n",
    "                    return_sequences=True,\n",
    "                    stateful=True,\n",
    "                    recurrent_initializer='glorot_uniform')(outputs)\n",
    "\n",
    "# embed0 = Reshape((T, 16))(embed0)\n",
    "#         tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
    "#                                   batch_input_shape=[batch_size, None]),\n",
    "#         tf.keras.layers.GRU(rnn_units,\n",
    "#                             return_sequences=True,\n",
    "#                             stateful=True,\n",
    "#                             recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "outputs = Dense(1)(outputs)\n",
    "\n",
    "m = Model(i_et, outputs)\n",
    "m(padded_event_types[1:100, :])\n",
    "# merged0 = tf.keras.layers.concatenate([embed0, dense0], axis=2)\n",
    "# x_b, _ = TimeLSTM0(15, activation='selu')(merged0)\n",
    "# x_b = Dense(1, activation='sigmoid')(x_b)\n",
    "\n",
    "# model_b = Model([i_et, i_ts], x_b)\n",
    "# model_b([padded_event_types[1:5, :], padded_ts[1:5, :]])\n",
    "\n",
    "# model_b.compile(loss='binary_crossentropy', \n",
    "#               optimizer=Adam(lr=0.001),\n",
    "#              )\n",
    "\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', patience=5\n",
    "# )\n",
    "\n",
    "# r_b = model_b.fit(\n",
    "#     [padded_event_types, padded_ts], labels,\n",
    "#     epochs=1,\n",
    "# )\n",
    "\n",
    "# # x_b, _ = TimeLSTM0(15, activation='selu')(merged0)\n",
    "# # x_b = Dense(1, activation='sigmoid')(x_b)\n",
    "\n",
    "# # model_b = Model([i_et, i_ts], x_b)\n",
    "\n",
    "# i_et = Input(shape=(20, 1))  # input of discrete feature event type\n",
    "# i_ts = Input(shape=(20, 1))  # input of continuous feature timestamp\n",
    "\n",
    "# # dense0 = Dense(1)(i_ts)\n",
    "\n",
    "# discriminator = Embedding(len(vocab), 16, \\\n",
    "#                             input_length=padding_len)(i_et)\n",
    "# discriminator = tf.keras.layers.concatenate([discriminator, dense0], axis=2)\n",
    "# discriminator = (Conv1D(32, 3, activation='relu'))(discriminator)\n",
    "# discriminator.add(MaxPooling1D(5))\n",
    "# discriminator.add(Conv1D(32, 3, activation='relu'))\n",
    "# discriminator.add(GlobalMaxPooling1D())\n",
    "# discriminator.add(Dense(1))\n",
    "# discriminator.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy',metrics=['acc'])\n",
    "# history = discriminator.fit(inp, labels,\n",
    "# epochs=2, batch_size=500, validation_split=0.2)\n",
    "\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(train_data_discriminator)\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE).batch(500, drop_remainder=True)\n",
    "# discriminator.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy',metrics=['acc'])\n",
    "# discriminator.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "features = (padded_event_types, padded_ts)\n",
    "labels = tf.reshape(labels, (labels.shape[0],1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "dataset = dataset.shuffle(1000).batch(3, drop_remainder=True)\n",
    "loss_history = []\n",
    "optimizer=Adam(lr=0.001)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:, :-1, :]\n",
    "    target_text = chunk[:, 1:, :]\n",
    "    return input_text, target_text\n",
    "\n",
    "for features, labels_batch in dataset.take(1):\n",
    "    et, ts = features\n",
    "    input_ts, target_ts = split_input_target(ts)\n",
    "    input_et, target_et = split_input_target(et)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(pos_padded_event_types)\n",
    "# dataset = dataset.map(split_input_target)\n",
    "\n",
    "# BATCH_SIZE = 12\n",
    "# BUFFER_SIZE = 1000\n",
    "\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# for input_example, target_example in  dataset.take(1):\n",
    "#     print('input_example:{}'.format(input_example))\n",
    "#     print('target_example:{}'.format(target_example))\n",
    "# input_example.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_example:[[[1]\n",
      "  [2]\n",
      "  [1]\n",
      "  [2]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n",
      "target_example:[[[2]\n",
      "  [1]\n",
      "  [2]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 19, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_et)\n",
    "dataset = dataset.map(split_input_target)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('input_example:{}'.format(input_example))\n",
    "    print('target_example:{}'.format(target_example))\n",
    "    \n",
    "et = train_et[0,:]\n",
    "ts = train_ts[0,:]\n",
    "    \n",
    "i_et = Input(shape=(T,1))  # input of discrete feature event type\n",
    "i_ts = Input(shape=(T,1))  # input of continuous feature timestamp\n",
    "\n",
    "embed0 = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,)(i_et)\n",
    "embed0 = Reshape((T, 16))(embed0)\n",
    "merged0 = tf.keras.layers.concatenate([embed0, i_ts], axis=2)\n",
    "\n",
    "x_b, _ = TimeLSTM0(15, activation='selu')(merged0)\n",
    "x_b = Dense(vocab_size, activation='sigmoid')(x_b)\n",
    "model_b = Model([i_et, i_ts], x_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Generator based on Time-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19, 1)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Could not compute output Tensor(\"dense_63/Identity:0\", shape=(None, 5), dtype=float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-27bacdf47a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_example\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0moutput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Could not compute output Tensor(\"dense_63/Identity:0\", shape=(None, 5), dtype=float64)"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 16\n",
    "rnn_units = 32\n",
    "T = 19\n",
    "def build_model_time_lstm(vocab_size, embedding_dim, rnn_units, batch_size=1):\n",
    "    \n",
    "    i_et = Input(shape=(T,1))  # input of discrete feature event type\n",
    "    i_ts = Input(shape=(T,1))  # input of continuous feature timestamp\n",
    "\n",
    "    embed0 = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,)(i_et)\n",
    "    embed0 = Reshape((T, 16))(embed0)\n",
    "    merged0 = tf.keras.layers.concatenate([embed0, i_ts], axis=2)\n",
    "    \n",
    "    x_b, _ = TimeLSTM0(15, activation='selu')(merged0)\n",
    "    x_b = Dense(vocab_size, activation='sigmoid')(x_b)\n",
    "    model_b = Model([i_et, i_ts], x_b)\n",
    "    model_b.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr=0.001),\n",
    "                 )\n",
    "    return model_b\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model = build_model_time_lstm(vocab_size = len(vocab),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=1)\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print(input_example.shape)\n",
    "    print(model(input_example).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 19)\n",
      "(10, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 16\n",
    "rnn_units = 32\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size=1):\n",
    "    \n",
    "    i_et = Input(shape=(T,1))  # input of discrete feature event type\n",
    "    i_ts = Input(shape=(T,1))  # input of continuous feature timestamp\n",
    "\n",
    "    embed0 = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,),\n",
    "    embed0 = Reshape((T, 16))(embed0)\n",
    "    merged0 = tf.keras.layers.concatenate([embed0, i_ts], axis=2)\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model = build_model(vocab_size = len(vocab),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print(input_example.shape)\n",
    "    print(model(input_example).shape)\n",
    "\n",
    "# model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "# checkpoint_dir = './training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "# checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_prefix,\n",
    "#     save_weights_only=True)\n",
    "\n",
    "# EPOCHS = 2\n",
    "# history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ebd4e0106a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mrnn_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     batch_size=1)\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minput_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_example\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd7645662d0>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "generator = build_model(vocab_size, embedding_dim, rnn_units, batch_size=50)\n",
    "\n",
    "generator.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll-out policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_event(model, batch_size=50, length=20):\n",
    "    states = [1] * batch_size\n",
    "    states = tf.expand_dims(states, -1)\n",
    "    all_actions_one_hot = tf.one_hot(states, depth=5)\n",
    "    all_predicted_actions = None\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(length):\n",
    "        predictions = model(states)\n",
    "        if all_predicted_actions is None:\n",
    "            all_predicted_actions = predictions\n",
    "        else:\n",
    "            all_predicted_actions =tf.keras.layers.concatenate([all_predicted_actions, predictions], axis=1)\n",
    "        \n",
    "        # sample an action - token\n",
    "        predictions = tf.squeeze(predictions)\n",
    "        predicted_idx = tf.random.categorical(predictions, num_samples=1)\n",
    "        \n",
    "        # maintain 16 gaussians, use predicted_idx to index which one to use to sample\n",
    "        current_gaussian = list_gaussian[predicted_idx, prev_predicted_idx]\n",
    "        current_delta_t = current_gaussian(sample\n",
    "                                          )\n",
    "        \n",
    "        # sample a timestamp - Gaussian?\n",
    "        predicted_idx_one_hot = tf.one_hot(predicted_idx, depth=5)\n",
    "        all_actions_one_hot = tf.concat([all_actions_one_hot, predicted_idx_one_hot], axis=1)\n",
    "        \n",
    "        # pass the predicted action as the next input to the model\n",
    "        states = predicted_idx\n",
    "\n",
    "    return  all_actions_one_hot, all_predicted_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:-0.028991742059588432\n",
      "loss:-0.029290182515978813\n",
      "loss:-0.029063435271382332\n",
      "loss:-0.03051750175654888\n",
      "loss:-0.03157886117696762\n",
      "loss:-0.03368803858757019\n",
      "loss:-0.030589960515499115\n",
      "loss:-0.03016679361462593\n",
      "loss:-0.03109685517847538\n",
      "loss:-0.031214972957968712\n",
      "loss:[230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 10000 values, but the requested shape has 100 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-7134b185eeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         message=\"Converting sparse IndexedSlices to a dense Tensor.*\")\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   7438\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7440\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7441\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7442\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 10000 values, but the requested shape has 100 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_history = []\n",
    "g_steps = 10\n",
    "d_steps = 10\n",
    "# Generator training\n",
    "\n",
    "for i in range(g_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_actions_one_hot, all_predicted_actions = generate_event(generator, length=20)\n",
    "        all_actions_one_hot = all_actions_one_hot[:, 1:,]\n",
    "\n",
    "        # policy gradient loss\n",
    "        negative_likelihoods = tf.keras.losses.categorical_crossentropy\\\n",
    "            (all_actions_one_hot, all_predicted_actions,from_logits=True)\n",
    "        in_dis = tf.argmax(all_actions_one_hot, axis = -1)\n",
    "        q_values = tf.broadcast_to(discriminator(in_dis), negative_likelihoods.shape) # this needs N-time Monte Carlo search\n",
    "        weighted_negative_likelihoods = tf.multiply(negative_likelihoods, q_values)\n",
    "        loss = tf.reduce_mean(weighted_negative_likelihoods)\n",
    "\n",
    "    loss_history.append(loss.numpy())\n",
    "    print('loss:{}'.format(loss.numpy()))\n",
    "    grads = tape.gradient(loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "# Discriminator training\n",
    "for i in range(d_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_actions_one_hot, all_predicted_actions = generate_event(generator, length=20)\n",
    "        all_actions_one_hot = all_actions_one_hot[:, 1:,]\n",
    "\n",
    "        fake_train = tf.argmax(all_actions_one_hot, axis = -1)\n",
    "        fake_labels = tf.zeros(in_dis.shape[0])\n",
    "\n",
    "        real_train = np.random.permutation(pos_padded_event_types)[:50]\n",
    "        real_labels = tf.ones(real_train.shape[0])\n",
    "        train_all = np.concatenate((real_train, fake_train), axis=0)\n",
    "        labels_all = np.concatenate((real_labels, fake_labels, ), axis=0)\n",
    "\n",
    "        pred = discriminator(train_all)\n",
    "        dis_loss = tf.keras.losses.categorical_crossentropy\\\n",
    "                (labels_all, pred, from_logits=True)\n",
    "\n",
    "    print('loss:{}'.format(dis_loss.numpy()))\n",
    "    grads = tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:[230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853 230.25853\n",
      " 230.25853 230.25853]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 10000 values, but the requested shape has 100 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-0cf24aac7403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         message=\"Converting sparse IndexedSlices to a dense Tensor.*\")\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   7438\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7440\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7441\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7442\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 10000 values, but the requested shape has 100 [Op:Reshape]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20)\n",
      "(50, 20)\n",
      "(50, 20)\n",
      "(50, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 20), dtype=float32, numpy=\n",
       "array([[-0.03283375, -0.03283375, -0.03283375, -0.03283375, -0.03283375,\n",
       "        -0.03283375, -0.03283375, -0.03283375, -0.03283375, -0.03283375,\n",
       "        -0.03283375, -0.03283375, -0.03283375, -0.03283375, -0.03283375,\n",
       "        -0.03283375, -0.03283375, -0.03283375, -0.03283375, -0.03283375],\n",
       "       [-0.02649174, -0.02649174, -0.02649174, -0.02649174, -0.02649174,\n",
       "        -0.02649174, -0.02649174, -0.02649174, -0.02649174, -0.02649174,\n",
       "        -0.02649174, -0.02649174, -0.02649174, -0.02649174, -0.02649174,\n",
       "        -0.02649174, -0.02649174, -0.02649174, -0.02649174, -0.02649174],\n",
       "       [-0.03558667, -0.03558667, -0.03558667, -0.03558667, -0.03558667,\n",
       "        -0.03558667, -0.03558667, -0.03558667, -0.03558667, -0.03558667,\n",
       "        -0.03558667, -0.03558667, -0.03558667, -0.03558667, -0.03558667,\n",
       "        -0.03558667, -0.03558667, -0.03558667, -0.03558667, -0.03558667],\n",
       "       [-0.03349002, -0.03349002, -0.03349002, -0.03349002, -0.03349002,\n",
       "        -0.03349002, -0.03349002, -0.03349002, -0.03349002, -0.03349002,\n",
       "        -0.03349002, -0.03349002, -0.03349002, -0.03349002, -0.03349002,\n",
       "        -0.03349002, -0.03349002, -0.03349002, -0.03349002, -0.03349002],\n",
       "       [-0.02874753, -0.02874753, -0.02874753, -0.02874753, -0.02874753,\n",
       "        -0.02874753, -0.02874753, -0.02874753, -0.02874753, -0.02874753,\n",
       "        -0.02874753, -0.02874753, -0.02874753, -0.02874753, -0.02874753,\n",
       "        -0.02874753, -0.02874753, -0.02874753, -0.02874753, -0.02874753],\n",
       "       [-0.02462566, -0.02462566, -0.02462566, -0.02462566, -0.02462566,\n",
       "        -0.02462566, -0.02462566, -0.02462566, -0.02462566, -0.02462566,\n",
       "        -0.02462566, -0.02462566, -0.02462566, -0.02462566, -0.02462566,\n",
       "        -0.02462566, -0.02462566, -0.02462566, -0.02462566, -0.02462566],\n",
       "       [-0.01087364, -0.01087364, -0.01087364, -0.01087364, -0.01087364,\n",
       "        -0.01087364, -0.01087364, -0.01087364, -0.01087364, -0.01087364,\n",
       "        -0.01087364, -0.01087364, -0.01087364, -0.01087364, -0.01087364,\n",
       "        -0.01087364, -0.01087364, -0.01087364, -0.01087364, -0.01087364],\n",
       "       [-0.03237629, -0.03237629, -0.03237629, -0.03237629, -0.03237629,\n",
       "        -0.03237629, -0.03237629, -0.03237629, -0.03237629, -0.03237629,\n",
       "        -0.03237629, -0.03237629, -0.03237629, -0.03237629, -0.03237629,\n",
       "        -0.03237629, -0.03237629, -0.03237629, -0.03237629, -0.03237629],\n",
       "       [-0.02675229, -0.02675229, -0.02675229, -0.02675229, -0.02675229,\n",
       "        -0.02675229, -0.02675229, -0.02675229, -0.02675229, -0.02675229,\n",
       "        -0.02675229, -0.02675229, -0.02675229, -0.02675229, -0.02675229,\n",
       "        -0.02675229, -0.02675229, -0.02675229, -0.02675229, -0.02675229],\n",
       "       [-0.02304214, -0.02304214, -0.02304214, -0.02304214, -0.02304214,\n",
       "        -0.02304214, -0.02304214, -0.02304214, -0.02304214, -0.02304214,\n",
       "        -0.02304214, -0.02304214, -0.02304214, -0.02304214, -0.02304214,\n",
       "        -0.02304214, -0.02304214, -0.02304214, -0.02304214, -0.02304214],\n",
       "       [-0.01541897, -0.01541897, -0.01541897, -0.01541897, -0.01541897,\n",
       "        -0.01541897, -0.01541897, -0.01541897, -0.01541897, -0.01541897,\n",
       "        -0.01541897, -0.01541897, -0.01541897, -0.01541897, -0.01541897,\n",
       "        -0.01541897, -0.01541897, -0.01541897, -0.01541897, -0.01541897],\n",
       "       [-0.00611325, -0.00611325, -0.00611325, -0.00611325, -0.00611325,\n",
       "        -0.00611325, -0.00611325, -0.00611325, -0.00611325, -0.00611325,\n",
       "        -0.00611325, -0.00611325, -0.00611325, -0.00611325, -0.00611325,\n",
       "        -0.00611325, -0.00611325, -0.00611325, -0.00611325, -0.00611325],\n",
       "       [-0.01516983, -0.01516983, -0.01516983, -0.01516983, -0.01516983,\n",
       "        -0.01516983, -0.01516983, -0.01516983, -0.01516983, -0.01516983,\n",
       "        -0.01516983, -0.01516983, -0.01516983, -0.01516983, -0.01516983,\n",
       "        -0.01516983, -0.01516983, -0.01516983, -0.01516983, -0.01516983],\n",
       "       [-0.02331973, -0.02331973, -0.02331973, -0.02331973, -0.02331973,\n",
       "        -0.02331973, -0.02331973, -0.02331973, -0.02331973, -0.02331973,\n",
       "        -0.02331973, -0.02331973, -0.02331973, -0.02331973, -0.02331973,\n",
       "        -0.02331973, -0.02331973, -0.02331973, -0.02331973, -0.02331973],\n",
       "       [-0.02433286, -0.02433286, -0.02433286, -0.02433286, -0.02433286,\n",
       "        -0.02433286, -0.02433286, -0.02433286, -0.02433286, -0.02433286,\n",
       "        -0.02433286, -0.02433286, -0.02433286, -0.02433286, -0.02433286,\n",
       "        -0.02433286, -0.02433286, -0.02433286, -0.02433286, -0.02433286],\n",
       "       [-0.03852224, -0.03852224, -0.03852224, -0.03852224, -0.03852224,\n",
       "        -0.03852224, -0.03852224, -0.03852224, -0.03852224, -0.03852224,\n",
       "        -0.03852224, -0.03852224, -0.03852224, -0.03852224, -0.03852224,\n",
       "        -0.03852224, -0.03852224, -0.03852224, -0.03852224, -0.03852224],\n",
       "       [-0.03565032, -0.03565032, -0.03565032, -0.03565032, -0.03565032,\n",
       "        -0.03565032, -0.03565032, -0.03565032, -0.03565032, -0.03565032,\n",
       "        -0.03565032, -0.03565032, -0.03565032, -0.03565032, -0.03565032,\n",
       "        -0.03565032, -0.03565032, -0.03565032, -0.03565032, -0.03565032],\n",
       "       [-0.02215336, -0.02215336, -0.02215336, -0.02215336, -0.02215336,\n",
       "        -0.02215336, -0.02215336, -0.02215336, -0.02215336, -0.02215336,\n",
       "        -0.02215336, -0.02215336, -0.02215336, -0.02215336, -0.02215336,\n",
       "        -0.02215336, -0.02215336, -0.02215336, -0.02215336, -0.02215336],\n",
       "       [-0.01518082, -0.01518082, -0.01518082, -0.01518082, -0.01518082,\n",
       "        -0.01518082, -0.01518082, -0.01518082, -0.01518082, -0.01518082,\n",
       "        -0.01518082, -0.01518082, -0.01518082, -0.01518082, -0.01518082,\n",
       "        -0.01518082, -0.01518082, -0.01518082, -0.01518082, -0.01518082],\n",
       "       [-0.03619196, -0.03619196, -0.03619196, -0.03619196, -0.03619196,\n",
       "        -0.03619196, -0.03619196, -0.03619196, -0.03619196, -0.03619196,\n",
       "        -0.03619196, -0.03619196, -0.03619196, -0.03619196, -0.03619196,\n",
       "        -0.03619196, -0.03619196, -0.03619196, -0.03619196, -0.03619196],\n",
       "       [-0.02114632, -0.02114632, -0.02114632, -0.02114632, -0.02114632,\n",
       "        -0.02114632, -0.02114632, -0.02114632, -0.02114632, -0.02114632,\n",
       "        -0.02114632, -0.02114632, -0.02114632, -0.02114632, -0.02114632,\n",
       "        -0.02114632, -0.02114632, -0.02114632, -0.02114632, -0.02114632],\n",
       "       [-0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 ,\n",
       "        -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 ,\n",
       "        -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 ,\n",
       "        -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 , -0.0310711 ],\n",
       "       [-0.03465372, -0.03465372, -0.03465372, -0.03465372, -0.03465372,\n",
       "        -0.03465372, -0.03465372, -0.03465372, -0.03465372, -0.03465372,\n",
       "        -0.03465372, -0.03465372, -0.03465372, -0.03465372, -0.03465372,\n",
       "        -0.03465372, -0.03465372, -0.03465372, -0.03465372, -0.03465372],\n",
       "       [-0.03500308, -0.03500308, -0.03500308, -0.03500308, -0.03500308,\n",
       "        -0.03500308, -0.03500308, -0.03500308, -0.03500308, -0.03500308,\n",
       "        -0.03500308, -0.03500308, -0.03500308, -0.03500308, -0.03500308,\n",
       "        -0.03500308, -0.03500308, -0.03500308, -0.03500308, -0.03500308],\n",
       "       [-0.02933529, -0.02933529, -0.02933529, -0.02933529, -0.02933529,\n",
       "        -0.02933529, -0.02933529, -0.02933529, -0.02933529, -0.02933529,\n",
       "        -0.02933529, -0.02933529, -0.02933529, -0.02933529, -0.02933529,\n",
       "        -0.02933529, -0.02933529, -0.02933529, -0.02933529, -0.02933529],\n",
       "       [-0.02866649, -0.02866649, -0.02866649, -0.02866649, -0.02866649,\n",
       "        -0.02866649, -0.02866649, -0.02866649, -0.02866649, -0.02866649,\n",
       "        -0.02866649, -0.02866649, -0.02866649, -0.02866649, -0.02866649,\n",
       "        -0.02866649, -0.02866649, -0.02866649, -0.02866649, -0.02866649],\n",
       "       [-0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 ,\n",
       "        -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 ,\n",
       "        -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 ,\n",
       "        -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 , -0.0253471 ],\n",
       "       [-0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 ,\n",
       "        -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 ,\n",
       "        -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 ,\n",
       "        -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 , -0.0273164 ],\n",
       "       [-0.03264028, -0.03264028, -0.03264028, -0.03264028, -0.03264028,\n",
       "        -0.03264028, -0.03264028, -0.03264028, -0.03264028, -0.03264028,\n",
       "        -0.03264028, -0.03264028, -0.03264028, -0.03264028, -0.03264028,\n",
       "        -0.03264028, -0.03264028, -0.03264028, -0.03264028, -0.03264028],\n",
       "       [-0.03324295, -0.03324295, -0.03324295, -0.03324295, -0.03324295,\n",
       "        -0.03324295, -0.03324295, -0.03324295, -0.03324295, -0.03324295,\n",
       "        -0.03324295, -0.03324295, -0.03324295, -0.03324295, -0.03324295,\n",
       "        -0.03324295, -0.03324295, -0.03324295, -0.03324295, -0.03324295],\n",
       "       [-0.01925052, -0.01925052, -0.01925052, -0.01925052, -0.01925052,\n",
       "        -0.01925052, -0.01925052, -0.01925052, -0.01925052, -0.01925052,\n",
       "        -0.01925052, -0.01925052, -0.01925052, -0.01925052, -0.01925052,\n",
       "        -0.01925052, -0.01925052, -0.01925052, -0.01925052, -0.01925052],\n",
       "       [-0.03955641, -0.03955641, -0.03955641, -0.03955641, -0.03955641,\n",
       "        -0.03955641, -0.03955641, -0.03955641, -0.03955641, -0.03955641,\n",
       "        -0.03955641, -0.03955641, -0.03955641, -0.03955641, -0.03955641,\n",
       "        -0.03955641, -0.03955641, -0.03955641, -0.03955641, -0.03955641],\n",
       "       [-0.03812994, -0.03812994, -0.03812994, -0.03812994, -0.03812994,\n",
       "        -0.03812994, -0.03812994, -0.03812994, -0.03812994, -0.03812994,\n",
       "        -0.03812994, -0.03812994, -0.03812994, -0.03812994, -0.03812994,\n",
       "        -0.03812994, -0.03812994, -0.03812994, -0.03812994, -0.03812994],\n",
       "       [-0.02646836, -0.02646836, -0.02646836, -0.02646836, -0.02646836,\n",
       "        -0.02646836, -0.02646836, -0.02646836, -0.02646836, -0.02646836,\n",
       "        -0.02646836, -0.02646836, -0.02646836, -0.02646836, -0.02646836,\n",
       "        -0.02646836, -0.02646836, -0.02646836, -0.02646836, -0.02646836],\n",
       "       [-0.04436719, -0.04436719, -0.04436719, -0.04436719, -0.04436719,\n",
       "        -0.04436719, -0.04436719, -0.04436719, -0.04436719, -0.04436719,\n",
       "        -0.04436719, -0.04436719, -0.04436719, -0.04436719, -0.04436719,\n",
       "        -0.04436719, -0.04436719, -0.04436719, -0.04436719, -0.04436719],\n",
       "       [-0.02287402, -0.02287402, -0.02287402, -0.02287402, -0.02287402,\n",
       "        -0.02287402, -0.02287402, -0.02287402, -0.02287402, -0.02287402,\n",
       "        -0.02287402, -0.02287402, -0.02287402, -0.02287402, -0.02287402,\n",
       "        -0.02287402, -0.02287402, -0.02287402, -0.02287402, -0.02287402],\n",
       "       [-0.02254411, -0.02254411, -0.02254411, -0.02254411, -0.02254411,\n",
       "        -0.02254411, -0.02254411, -0.02254411, -0.02254411, -0.02254411,\n",
       "        -0.02254411, -0.02254411, -0.02254411, -0.02254411, -0.02254411,\n",
       "        -0.02254411, -0.02254411, -0.02254411, -0.02254411, -0.02254411],\n",
       "       [-0.04941806, -0.04941806, -0.04941806, -0.04941806, -0.04941806,\n",
       "        -0.04941806, -0.04941806, -0.04941806, -0.04941806, -0.04941806,\n",
       "        -0.04941806, -0.04941806, -0.04941806, -0.04941806, -0.04941806,\n",
       "        -0.04941806, -0.04941806, -0.04941806, -0.04941806, -0.04941806],\n",
       "       [-0.04024087, -0.04024087, -0.04024087, -0.04024087, -0.04024087,\n",
       "        -0.04024087, -0.04024087, -0.04024087, -0.04024087, -0.04024087,\n",
       "        -0.04024087, -0.04024087, -0.04024087, -0.04024087, -0.04024087,\n",
       "        -0.04024087, -0.04024087, -0.04024087, -0.04024087, -0.04024087],\n",
       "       [-0.02028899, -0.02028899, -0.02028899, -0.02028899, -0.02028899,\n",
       "        -0.02028899, -0.02028899, -0.02028899, -0.02028899, -0.02028899,\n",
       "        -0.02028899, -0.02028899, -0.02028899, -0.02028899, -0.02028899,\n",
       "        -0.02028899, -0.02028899, -0.02028899, -0.02028899, -0.02028899],\n",
       "       [-0.03215358, -0.03215358, -0.03215358, -0.03215358, -0.03215358,\n",
       "        -0.03215358, -0.03215358, -0.03215358, -0.03215358, -0.03215358,\n",
       "        -0.03215358, -0.03215358, -0.03215358, -0.03215358, -0.03215358,\n",
       "        -0.03215358, -0.03215358, -0.03215358, -0.03215358, -0.03215358],\n",
       "       [-0.03262469, -0.03262469, -0.03262469, -0.03262469, -0.03262469,\n",
       "        -0.03262469, -0.03262469, -0.03262469, -0.03262469, -0.03262469,\n",
       "        -0.03262469, -0.03262469, -0.03262469, -0.03262469, -0.03262469,\n",
       "        -0.03262469, -0.03262469, -0.03262469, -0.03262469, -0.03262469],\n",
       "       [-0.01614763, -0.01614763, -0.01614763, -0.01614763, -0.01614763,\n",
       "        -0.01614763, -0.01614763, -0.01614763, -0.01614763, -0.01614763,\n",
       "        -0.01614763, -0.01614763, -0.01614763, -0.01614763, -0.01614763,\n",
       "        -0.01614763, -0.01614763, -0.01614763, -0.01614763, -0.01614763],\n",
       "       [-0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 ,\n",
       "        -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 ,\n",
       "        -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 ,\n",
       "        -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 , -0.0198884 ],\n",
       "       [-0.00293329, -0.00293329, -0.00293329, -0.00293329, -0.00293329,\n",
       "        -0.00293329, -0.00293329, -0.00293329, -0.00293329, -0.00293329,\n",
       "        -0.00293329, -0.00293329, -0.00293329, -0.00293329, -0.00293329,\n",
       "        -0.00293329, -0.00293329, -0.00293329, -0.00293329, -0.00293329],\n",
       "       [-0.03419662, -0.03419662, -0.03419662, -0.03419662, -0.03419662,\n",
       "        -0.03419662, -0.03419662, -0.03419662, -0.03419662, -0.03419662,\n",
       "        -0.03419662, -0.03419662, -0.03419662, -0.03419662, -0.03419662,\n",
       "        -0.03419662, -0.03419662, -0.03419662, -0.03419662, -0.03419662],\n",
       "       [-0.03093218, -0.03093218, -0.03093218, -0.03093218, -0.03093218,\n",
       "        -0.03093218, -0.03093218, -0.03093218, -0.03093218, -0.03093218,\n",
       "        -0.03093218, -0.03093218, -0.03093218, -0.03093218, -0.03093218,\n",
       "        -0.03093218, -0.03093218, -0.03093218, -0.03093218, -0.03093218],\n",
       "       [-0.03771326, -0.03771326, -0.03771326, -0.03771326, -0.03771326,\n",
       "        -0.03771326, -0.03771326, -0.03771326, -0.03771326, -0.03771326,\n",
       "        -0.03771326, -0.03771326, -0.03771326, -0.03771326, -0.03771326,\n",
       "        -0.03771326, -0.03771326, -0.03771326, -0.03771326, -0.03771326],\n",
       "       [-0.02647121, -0.02647121, -0.02647121, -0.02647121, -0.02647121,\n",
       "        -0.02647121, -0.02647121, -0.02647121, -0.02647121, -0.02647121,\n",
       "        -0.02647121, -0.02647121, -0.02647121, -0.02647121, -0.02647121,\n",
       "        -0.02647121, -0.02647121, -0.02647121, -0.02647121, -0.02647121],\n",
       "       [-0.02880747, -0.02880747, -0.02880747, -0.02880747, -0.02880747,\n",
       "        -0.02880747, -0.02880747, -0.02880747, -0.02880747, -0.02880747,\n",
       "        -0.02880747, -0.02880747, -0.02880747, -0.02880747, -0.02880747,\n",
       "        -0.02880747, -0.02880747, -0.02880747, -0.02880747, -0.02880747]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_actions_one_hot, all_predicted_actions = generate_event(generator, length=20)\n",
    "all_actions_one_hot = all_actions_one_hot[:, 1:,]\n",
    "all_actions_one_hot\n",
    "# policy gradient loss\n",
    "negative_likelihoods = tf.keras.losses.categorical_crossentropy\\\n",
    "    (all_actions_one_hot, all_predicted_actions,from_logits=True)\n",
    "in_dis = tf.argmax(all_actions_one_hot, axis = -1)\n",
    "print(in_dis.shape)\n",
    "discriminator(in_dis)\n",
    "q_values = tf.broadcast_to(discriminator(in_dis), negative_likelihoods.shape) # this needs N-time Monte Carlo search\n",
    "weighted_negative_likelihoods = tf.multiply(negative_likelihoods, q_values)\n",
    "loss = tf.reduce_mean(weighted_negative_likelihoods)\n",
    "    \n",
    "print(negative_likelihoods.shape)\n",
    "print(in_dis.shape)\n",
    "print(q_values.shape)\n",
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mnist_model(images, training=True)\n",
    "    \n",
    "        # Add asserts to check the shape of the output.\n",
    "        tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "\n",
    "        loss_value = loss_object(labels, logits)\n",
    "\n",
    "    loss_history.append(loss_value.numpy().mean())\n",
    "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "    print('grads:{}'.format(grads))\n",
    "    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start view view view view click view view start view install install view click view start install start install click view \n",
      "start start click view install start view click view view view install click start view view install install view view na \n",
      "start click install install click install na click na na na na na na na na na na na na na \n",
      "start click click view view view view install start na install click view view start start start install start click view \n",
      "start view start view start click click click install click view install start view install start click start start view install \n",
      "start start start click view view view na na na na na na na na na na na na na na \n",
      "start view view start start view view view install click start start start click view install click view click click view \n",
      "start view view click install start view view click start install click view install start click click view start view install \n",
      "start view install view click view install start view click install click view start view install install click view view start \n",
      "start start click click install view install click install start view view view view view start start view start click install \n",
      "start view view click click click view view click view view view view install view click click install start view install \n",
      "start view start install start install view install na na na na na na na na na na na na na \n",
      "start view start view click view install click view install install install start start install install click start view install click \n",
      "start view view click start view start start start install start view start start install view click view start install install \n",
      "start na na na na na na na na na na na na na na na na na na na na \n",
      "start view start click install click view install click view click start view view install view click install view click view \n",
      "start view click start view view click start start start view install view start click view view install install view click \n",
      "start na na na na na na na na na na na na na na na na na na na na \n",
      "start start view start view click start view install start start click start view view start view view view view click \n",
      "start view start click view view view view view start click view view view start view view view click install install \n"
     ]
    }
   ],
   "source": [
    "# for i in range(20):\n",
    "seq_str, seq_int = generate_event(model)\n",
    "#     print(seq_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 2, 3, 4, 4]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 20, 16)            80        \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 18, 32)            1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 4, 32)             3104      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,785\n",
      "Trainable params: 4,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02621368]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discriminator - CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(len(vocab), 16, input_length=20))\n",
    "cnn_model.add(Conv1D(32, 3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(3))\n",
    "cnn_model.add(Conv1D(32, 3, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy',metrics=['acc'])\n",
    "# history = model.fit(x_train, y_train,\n",
    "# epochs=10, batch_size=128, validation_split=0.2)\n",
    "cnn_model.predict(np.array([seq_int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, discriminator, rollout_policy, path):\n",
    "        self.path = path\n",
    "        self.discriminator = discriminator\n",
    "        self.mdp = rollout_policy # an pretrained RNN model\n",
    "        self.base_state = [1]\n",
    "        self.state = self.base_state\n",
    "        self.reset()\n",
    "        self.T = 20\n",
    "        self.n_sample = 100\n",
    "    \n",
    "    def load_model():\n",
    "        tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "        model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        model.build(tf.TensorShape([1, None]))\n",
    "        model.summary()\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "    \n",
    "    def reset(self):\n",
    "        self.t = t\n",
    "        self.mdp.reset_states()\n",
    "        self.state = self.base_state\n",
    "        return True\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.t = self.t + 1\n",
    "\n",
    "        reward = self.get_reward(action, self.n_sample)\n",
    "        is_episode_end = self.t > self.T\n",
    "\n",
    "        self.state.append(action)\n",
    "        next_state = self.get_state()\n",
    "\n",
    "        return [next_state, reward, is_episode_end]\n",
    "    \n",
    "    def render(self):\n",
    "        for c in self.state:\n",
    "            \n",
    "        full_seq_str.append(idx2str[predicted_idx] + \" \")\n",
    "        full_seq_int.append(predicted_idx)\n",
    "\n",
    "    return 'start ' + ''.join(full_seq_str), full_seq_int\n",
    "\n",
    "\n",
    "    def get_reward(self, action, n_sample):\n",
    "        reward = 0\n",
    "        for idx_sample in range(n_sample):\n",
    "            full_seq = self.generate_event(state, self.T)\n",
    "            reward += self.discriminator.predict(full_seq) / n_sample\n",
    "        return reward\n",
    "        \n",
    "    def generate_event(state, length):\n",
    "        input_eval = state\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "        full_seq = input_eval\n",
    "        # Empty string to store our results\n",
    "        text_generated = []\n",
    "\n",
    "        self.rollout_policy.reset_states()\n",
    "        for i in range(length):\n",
    "            predictions = mdp(input_eval)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "            predictions = predictions\n",
    "            predicted_idx = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "            \n",
    "            # pass the predicted action as the next input to the model\n",
    "            input_eval = tf.expand_dims([predicted_idx], 0)\n",
    "            text_generated.append(idx2str[predicted_idx])\n",
    "            full_seq.append(predicted_idx)\n",
    "        return full_seq\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
