{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for synthesized Temporal Sequence Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of version 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive sequence is the minority class which follows the patterns below:\n",
    "\n",
    "1. __[Minimum Same Token Delay]__: The minimum time delay between two consecutive __same__ tokens is 20 secs\n",
    "\n",
    "2. __[Pairing C & D]__: Each C event can either appear alone, or be paired with one and only one later D event. Each D event has to be paired with one and only one previous C event. Pairing can be non-unique. \n",
    "\n",
    "3. __[Maximum Pair Delay]__: The time delay between a paired C and D cannot be > 300 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp distributions conditioned on the upcoming event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ts distribution is conditioned on the previous event\n",
    "# e.g. if the upcoming event is an A, it follows chi-square 8 distribution\n",
    "event_to_ts_dist = dict({\n",
    "    'A' : lambda: np.random.chisquare(df=10),\n",
    "    'B' : lambda: np.random.chisquare(df=20),\n",
    "    'C' : lambda: np.random.chisquare(df=40),\n",
    "    'D' : lambda: np.random.chisquare(df=80),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Context and Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_TYPES = ['A', 'B', 'C', 'D']\n",
    "EVENT_ENCODE = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "\n",
    "MIN_SAME_DELAY = 20\n",
    "MAX_PAIR_DELAY = 200\n",
    "\n",
    "\n",
    "def check_min_delay_rule(seq, use_init_token=False):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    prev_et, _ = None, 0.0\n",
    "    for et, dt in seq:\n",
    "        if et == prev_et and dt < MIN_SAME_DELAY:\n",
    "            return False\n",
    "        prev_et = et\n",
    "    return True\n",
    "\n",
    "def check_paring_rule(seq, use_init_token=False):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]    \n",
    "    # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq)-1, -1, -1):\n",
    "        if seq[i][0] == EVENT_ENCODE['D']: # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif seq[i][0] == EVENT_ENCODE['C'] and queue: # encounter a C event\n",
    "            queue.pop(0)\n",
    "    return len(queue) == 0\n",
    "\n",
    "def check_max_delay_rule(seq, use_init_token=False):    \n",
    "    if use_init_token:\n",
    "        seq = seq[1:]    \n",
    "        \n",
    "    def recover_timedelta_to_timestamp(time_seq):\n",
    "        csum = []\n",
    "        curr = 0\n",
    "        for dt in time_seq:\n",
    "            if dt != 0:\n",
    "                curr += dt\n",
    "                csum.append(curr)\n",
    "            else:\n",
    "                csum.append(0)\n",
    "        return csum\n",
    "    \n",
    "    ets = [e[0] for e in seq]\n",
    "    tss = recover_timedelta_to_timestamp([e[1] for e in seq])\n",
    "        \n",
    "    # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq)-1, -1, -1):\n",
    "        if ets[i] == EVENT_ENCODE['D']: # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif ets[i] == EVENT_ENCODE['C'] and queue: # encounter a C event\n",
    "            if tss[queue[0]] - tss[i] <= MAX_PAIR_DELAY:\n",
    "                queue.pop(0)\n",
    "            else:\n",
    "                return False\n",
    "    # for rule 6, it's fine if there are unpaired D in queue\n",
    "    # b/c this rules is to ensure for each paired (C, D), the delay is bounded\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Uniform-length Dataset: generate valid and invalid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# length of a temporal sequence\n",
    "L = 20\n",
    "\n",
    "# Max size of the dataset\n",
    "N_pos = 20000\n",
    "\n",
    "pos_seqs = []\n",
    "neg_seqs = []\n",
    "\n",
    "use_init_token = True\n",
    "\n",
    "while len(pos_seqs) < N_pos:\n",
    "    seq_len = L\n",
    "    \n",
    "    # Generate the type sequences only\n",
    "    type_seq = np.random.randint(low=EVENT_ENCODE['A'], high=EVENT_ENCODE['D']+1, size=seq_len).tolist()\n",
    "    \n",
    "    # Generate a seq of timestamps. Time delta conditions on the upcoming token\n",
    "    dts = []\n",
    "    for et in type_seq:\n",
    "        token = EVENT_TYPES[et]\n",
    "        dt_dist = event_to_ts_dist[token]\n",
    "        dt_sample = float(np.ceil(dt_dist()))\n",
    "        dts.append(dt_sample)\n",
    "        \n",
    "    seq = list(zip(type_seq, dts))\n",
    "    \n",
    "    # check rules one by one:\n",
    "    if check_min_delay_rule(seq) and check_paring_rule(seq) and check_max_delay_rule(seq):\n",
    "        pos_seqs.append(seq)\n",
    "    else:\n",
    "        neg_seqs.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, 3, 3, 0, 2, 1, 3, 1, 2, 0, 3, 0, 2, 0, 3, 2, 2, 3]\n",
      "[38.0, 8.0, 34.0, 84.0, 86.0, 7.0, 27.0, 40.0, 83.0, 17.0, 33.0, 11.0, 82.0, 7.0, 34.0, 9.0, 83.0, 30.0, 53.0, 102.0]\n",
      "[(2, 38.0), (0, 8.0), (2, 34.0), (3, 84.0), (3, 86.0), (0, 7.0), (2, 27.0), (1, 40.0), (3, 83.0), (1, 17.0), (2, 33.0), (0, 11.0), (3, 82.0), (0, 7.0), (2, 34.0), (0, 9.0), (3, 83.0), (2, 30.0), (2, 53.0), (3, 102.0)]\n"
     ]
    }
   ],
   "source": [
    "seq = list(zip(type_seq, dts))\n",
    "print(type_seq)\n",
    "print(dts)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 827146)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_seqs), len(neg_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5.0),\n",
       " (0, 22.0),\n",
       " (1, 27.0),\n",
       " (2, 44.0),\n",
       " (2, 43.0),\n",
       " (3, 87.0),\n",
       " (1, 30.0),\n",
       " (2, 36.0),\n",
       " (3, 75.0),\n",
       " (2, 28.0),\n",
       " (0, 9.0),\n",
       " (1, 24.0),\n",
       " (0, 9.0),\n",
       " (2, 40.0),\n",
       " (1, 29.0),\n",
       " (2, 37.0),\n",
       " (0, 10.0),\n",
       " (1, 19.0),\n",
       " (2, 26.0),\n",
       " (1, 7.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_seqs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_seqs_downsample = pos_seqs[:400]\n",
    "neg_seqs_downsample = neg_seqs[:400000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset : Dump into binay files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pos_seqs_filename = 'positive_long_sequences.pickle'\n",
    "neg_seqs_filename = 'negative_long_sequences.pickle'\n",
    "\n",
    "repo_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/\"\n",
    "\n",
    "with open(os.path.join(repo_path, 'data', 'long_seqs_v11_val', pos_seqs_filename), 'wb') as f:\n",
    "    pickle.dump(pos_seqs_downsample, f)\n",
    "    \n",
    "with open(os.path.join(repo_path, 'data', 'long_seqs_v11_val', neg_seqs_filename), 'wb') as f:\n",
    "    pickle.dump(neg_seqs_downsample, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
