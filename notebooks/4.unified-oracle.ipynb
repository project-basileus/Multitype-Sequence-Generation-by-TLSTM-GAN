{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = #'.../path-to-module/'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of version 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence length T = 20; (plus 1 initial token, in total 21)\n",
    "\n",
    "Token Types (Token-Encoding-meaning): \n",
    "\n",
    "P-0-padding, reserved token\n",
    "\n",
    "N-1-initial token\n",
    "\n",
    "A-2-start\n",
    "\n",
    "B-3-view\n",
    "\n",
    "C-4-click\n",
    "\n",
    "D-5-install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden patterns:\n",
    "\n",
    "1. __[Starting with A]__: A sequence starts with an A event.\n",
    "\n",
    "2. __[multi-types]__: There are __more than 3__ distinct types of events after the init token, and at least 1 in all types should be A.\n",
    "\n",
    "3. __[Pairing C & D]__: Each D event is paired with one and only one previous C event. Each C event can be paired with atmost one later D event.\n",
    "\n",
    "4. __[Number Decay]__: The total number of A is greater or equal to that of B; The total number of B is greater or equal to that of C; The total number of C is greater or equal to that of D.\n",
    "\n",
    "5. __[Minimum Same Delay]__: The time delay between any two consecutive __same__ events is no less than 10.\n",
    "\n",
    "6. __[Maximum Pair Delay]__: The time delay between any paired C and D is no greater than 50.\n",
    "\n",
    "If a sequence follows __more than 3__ of the above rules, it will be classified as a positive sequence, otherwise negative;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original and generated seqs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_path = #'.../path-to-gan-generated/performance_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_seqs_prefix = gen_data_path + 'pos_seqs/'\n",
    "neg_seqs_prefix = gen_data_path + 'neg_seqs/'\n",
    "g0_seqs_prefix = gen_data_path + 'g0_seqs/'\n",
    "g1_seqs_prefix = gen_data_path + 'g1_seqs/'\n",
    "g2_seqs_prefix = gen_data_path + 'g2_seqs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVENT_TYPES = {0:'':'A', 3:'B', 4:'C'} # 0 is reserved for padding 1 is for 'init token'\n",
    "EVENT_TYPES = ['P', 'N', 'A', 'B', 'C', 'D']\n",
    "EVENT_ENCODE = {'P': 0, 'N': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5}\n",
    "INIT_TOKEN = EVENT_ENCODE['N']\n",
    "END_TOKEN = EVENT_ENCODE['P']\n",
    "\n",
    "MIN_SAME_DELAY = 10\n",
    "MAX_PAIR_DELAY = 50\n",
    "\n",
    "\n",
    "def check_increasing_rule(seq):\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i][1] <= seq[i - 1][1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_rule_1(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    return seq[0][0] == EVENT_ENCODE['A']\n",
    "\n",
    "\n",
    "def check_rule_2(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    cnt = Counter()\n",
    "    for et, dt in seq:\n",
    "        cnt[et] += 1\n",
    "    # rule 2\n",
    "    if len(cnt.keys()) > 3 and EVENT_ENCODE['A'] in cnt.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_rule_3(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "        # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq) - 1, -1, -1):\n",
    "        if seq[i][0] == EVENT_ENCODE['D']:  # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif seq[i][0] == EVENT_ENCODE['C'] and queue:  # encounter a C event\n",
    "            queue.pop(0)\n",
    "    return len(queue) == 0\n",
    "\n",
    "\n",
    "def check_rule_4(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    cnt = Counter()\n",
    "    for et, dt in seq:\n",
    "        cnt[et] += 1\n",
    "    # rule 4\n",
    "    if cnt[EVENT_ENCODE['A']] < EVENT_ENCODE['B']:\n",
    "        return False\n",
    "    if cnt[EVENT_ENCODE['B']] < EVENT_ENCODE['C']:\n",
    "        return False\n",
    "    if cnt[EVENT_ENCODE['C']] < EVENT_ENCODE['D']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_rule_5(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    prev_et, _ = EVENT_ENCODE['N'], 0.0\n",
    "    for et, dt in seq:\n",
    "        if et == prev_et and dt < MIN_SAME_DELAY:\n",
    "            return False\n",
    "        prev_et = et\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_rule_6(seq, use_init_token=True):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "\n",
    "    def recover_timedelta_to_timestamp(time_seq):\n",
    "        csum = []\n",
    "        curr = 0\n",
    "        for dt in time_seq:\n",
    "            if dt != 0:\n",
    "                curr += dt\n",
    "                csum.append(curr)\n",
    "            else:\n",
    "                csum.append(0)\n",
    "        return csum\n",
    "\n",
    "    ets = [e[0] for e in seq]\n",
    "    tss = recover_timedelta_to_timestamp([e[1] for e in seq])\n",
    "\n",
    "    # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq) - 1, -1, -1):\n",
    "        if ets[i] == EVENT_ENCODE['D']:  # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif ets[i] == EVENT_ENCODE['C'] and queue:  # encounter a C event\n",
    "            if tss[queue[0]] - tss[i] <= MAX_PAIR_DELAY:\n",
    "                queue.pop(0)\n",
    "            else:\n",
    "                return False\n",
    "    # for rule 6, it's fine if there are unpaired D in queue\n",
    "    # b/c this rules is to ensure for each paired (C, D), the delay is bounded\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_rule_dist(seqs, use_init_token=True):\n",
    "    seq_to_rules = [0] * 7\n",
    "    N = len(seqs)\n",
    "\n",
    "    for i in range(N):\n",
    "        seq = seqs[i]\n",
    "        # check rules one by one:\n",
    "        if check_rule_1(seq):\n",
    "            seq_to_rules[1] += 1\n",
    "        if check_rule_2(seq):\n",
    "            seq_to_rules[2] += 1\n",
    "        if check_rule_3(seq):\n",
    "            seq_to_rules[3] += 1\n",
    "        if check_rule_4(seq):\n",
    "            seq_to_rules[4] += 1\n",
    "        if check_rule_5(seq):\n",
    "            seq_to_rules[5] += 1\n",
    "        if check_rule_6(seq):\n",
    "            seq_to_rules[6] += 1\n",
    "\n",
    "    return [freq / N for freq in seq_to_rules[1:]]\n",
    "\n",
    "\n",
    "def get_rule_foreach(seqs, use_init_token=True):\n",
    "    seq_to_rules = defaultdict(set)\n",
    "    N = len(seqs)\n",
    "\n",
    "    for i in range(N):\n",
    "        seq = seqs[i]\n",
    "        # check rules one by one:\n",
    "        if check_rule_1(seq):\n",
    "            seq_to_rules[i].add(1)\n",
    "        if check_rule_2(seq):\n",
    "            seq_to_rules[i].add(2)\n",
    "        if check_rule_3(seq):\n",
    "            seq_to_rules[i].add(3)\n",
    "        if check_rule_4(seq):\n",
    "            seq_to_rules[i].add(4)\n",
    "        if check_rule_5(seq):\n",
    "            seq_to_rules[i].add(5)\n",
    "        if check_rule_6(seq):\n",
    "            seq_to_rules[i].add(6)\n",
    "\n",
    "    return seq_to_rules\n",
    "\n",
    "\n",
    "def get_all_combs(rules=[1, 2, 3, 4, 5, 6]):\n",
    "    all_combs = set()\n",
    "    for k in range(1, len(rules) + 1):\n",
    "        all_combs.update(set(combinations(rules, k)))\n",
    "    return all_combs\n",
    "\n",
    "\n",
    "def check_all_combinations(rule_dict):\n",
    "    rules = [1, 2, 3, 4, 5, 6]\n",
    "    combs = set()\n",
    "    comb_dict = defaultdict(Counter)\n",
    "\n",
    "    for k in range(1, len(rules) + 1):\n",
    "        combs.update(set(combinations(rules, k)))\n",
    "\n",
    "    for i, rule_list in rule_dict.items():\n",
    "        for c in combs:\n",
    "            if set(c).issubset(set(rule_list)):\n",
    "                comb_dict[i][c] += 1\n",
    "\n",
    "    return comb_dict\n",
    "\n",
    "\n",
    "def get_comb_dist(all_combs, comb_dict):\n",
    "    comb_dist = {c: 0 for c in all_combs}\n",
    "    comb_dist.update({(0,): 0})  # no rules followed\n",
    "\n",
    "    for d in comb_dict.values():\n",
    "        if not d or len(d) == 0:\n",
    "            comb_dist[(0,)] += 1\n",
    "            continue\n",
    "        for c in all_combs:\n",
    "            if c in d:\n",
    "                comb_dist[c] += 1\n",
    "\n",
    "    return comb_dist\n",
    "\n",
    "\n",
    "def seqs_to_comb_dist(seqs, all_combs):\n",
    "    seq_to_rules = get_rule_foreach(seqs, True)\n",
    "    comb_results = check_all_combinations(seq_to_rules)\n",
    "\n",
    "    comb_freq = get_comb_dist(all_combs, comb_results)\n",
    "\n",
    "    # sort the combo distribution\n",
    "    all_comb_list = [(0,)] + sorted(list(all_combs), key=lambda e: (len(e), e))\n",
    "\n",
    "    sorted_comb_dist = [(comb, comb_freq[comb]) for comb in all_comb_list]\n",
    "\n",
    "    return comb_freq, sorted_comb_dist\n",
    "\n",
    "\n",
    "def seqs_to_scores(seqs):\n",
    "    seq_to_rules = get_rule_foreach(seqs, True)\n",
    "    comb_results = check_all_combinations(seq_to_rules)\n",
    "    seq_to_score = dict()\n",
    "\n",
    "    for i, combs in comb_results.items():\n",
    "        score = 0\n",
    "        for comb, cnt in combs.items():\n",
    "            if comb == (0,):\n",
    "                continue\n",
    "            score += 2 ** len(comb) * cnt\n",
    "        seq_to_score[i] = score\n",
    "\n",
    "    return sum(seq_to_score.values()) / len(seq_to_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FID_batch(batch1, batch2, weight=1):\n",
    "    mu1, sigma1 = batch1.mean(axis=0), np.cov(batch1, rowvar=False)\n",
    "    mu2, sigma2 = batch2.mean(axis=0), np.cov(batch2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid2 = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAD:\n",
    "    \"\"\" Sum square of one-hot distance between tokens\n",
    "    Params:\n",
    "    -- batch1         : The first batch of sequences to be compared with the second one\n",
    "                        or it can be the comparison base\n",
    "    -- batch2\n",
    "    Returns:\n",
    "    --   : dict, sum square of distances and base medians\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_ssad = []\n",
    "        self.base_med = []\n",
    "        self.base_med_oh = []\n",
    "        self.one_hot_map = {0: [0, 0, 0, 0, 0],\n",
    "                            1: [1, 0, 0, 0, 0],\n",
    "                            2: [0, 1, 0, 0, 0],\n",
    "                            3: [0, 0, 1, 0, 0],\n",
    "                            4: [0, 0, 0, 1, 0],\n",
    "                            5: [0, 0, 0, 0, 1]}\n",
    "\n",
    "    def nan_if(self, arr, value):\n",
    "        return np.where(arr == value, np.nan, arr)\n",
    "\n",
    "    def fit(self, batch1):\n",
    "        assert len(batch1) > 1, 'batch1 should have more than one sequence'\n",
    "        X_tok = []\n",
    "        for i in batch1:\n",
    "            X_tok.append([j[0] for j in i])\n",
    "        X_tok_t = np.array(X_tok).T\n",
    "        X_tok_oh = [[self.one_hot_map[j] for j in i] for i in X_tok]\n",
    "        medians = [int(i) for i in np.nanmedian(self.nan_if(X_tok_t, 0), axis=1)]\n",
    "        medians_oh = [self.one_hot_map[j] for j in medians]\n",
    "        self.base_med = medians\n",
    "        self.base_med_oh = medians_oh\n",
    "        tok_dist = []\n",
    "        for tok in X_tok_oh:\n",
    "            dist = []\n",
    "            for j in range(len(tok)):\n",
    "                tt = np.array(tok[j])\n",
    "                med = np.array(medians_oh[j])\n",
    "                # skip 0\n",
    "                dist.append(np.nansum(np.abs(self.nan_if(tt, 0) - med)))\n",
    "            tok_dist.append(dist)\n",
    "        self.base_ssad = np.mean(tok_dist)\n",
    "\n",
    "    def compare(self, batch2):\n",
    "        assert len(batch2) > 1, 'batch2 should have more than one sequence'\n",
    "        X_tok = []\n",
    "        for i in batch2:\n",
    "            X_tok.append([j[0] for j in i])\n",
    "        X_tok_t = np.array(X_tok).T\n",
    "        X_tok_oh = [[self.one_hot_map[j] for j in i] for i in X_tok]\n",
    "        medians = [int(i) for i in np.nanmedian(self.nan_if(X_tok_t, 0), axis=1)]\n",
    "        medians_oh = [self.one_hot_map[j] for j in medians]\n",
    "        tok_dist = []\n",
    "        for tok in X_tok_oh:\n",
    "            dist = []\n",
    "            for j in range(len(tok)):\n",
    "                tt = np.array(tok[j])\n",
    "                med = np.array(self.base_med_oh[j])\n",
    "                # skip 0\n",
    "                dist.append(np.nansum(np.abs(self.nan_if(tt, 0) - med)))\n",
    "            tok_dist.append(dist)\n",
    "        compare_ssd = np.mean(tok_dist)\n",
    "        return {'mad': compare_ssd,\n",
    "                'base_medians': np.array(self.base_med),\n",
    "                'base_medians_oh': np.array(self.base_med_oh),\n",
    "                'comp_medians': np.array(medians),\n",
    "                'comp_medians_oh': np.array(medians_oh)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_mmd2(X, Y, sigma=1, biased=True):\n",
    "    X = tf.cast(X, tf.float64)\n",
    "    Y = tf.cast(Y, tf.float64)\n",
    "    return mix_rbf_mmd2(X, Y, sigmas=[sigma], biased=biased)\n",
    "\n",
    "\n",
    "def mix_rbf_mmd2(X, Y, sigmas=(1,), wts=None, biased=True):\n",
    "    K_XX, K_XY, K_YY, d = _mix_rbf_kernel(X, Y, sigmas, wts)\n",
    "    return _mmd2(K_XX, K_XY, K_YY, const_diagonal=d, biased=biased)\n",
    "\n",
    "\n",
    "def _mix_rbf_kernel(X, Y, sigmas, wts=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if isinstance(sigmas, list):\n",
    "        sigmas = tf.convert_to_tensor(np.array(sigmas))\n",
    "    if wts is None:\n",
    "        # print('sigmas:{}'.format(sigmas))\n",
    "        wts = [1.0] * sigmas.get_shape()[0]\n",
    "\n",
    "    # debug!\n",
    "    if len(X.shape) == 2:\n",
    "        # matrix\n",
    "        XX = tf.matmul(X, X, transpose_b=True)\n",
    "        XY = tf.matmul(X, Y, transpose_b=True)\n",
    "        YY = tf.matmul(Y, Y, transpose_b=True)\n",
    "    elif len(X.shape) == 3:\n",
    "        # tensor -- this is computing the Frobenius norm\n",
    "        XX = tf.tensordot(X, X, axes=[[1, 2], [1, 2]])\n",
    "        XY = tf.tensordot(X, Y, axes=[[1, 2], [1, 2]])\n",
    "        YY = tf.tensordot(Y, Y, axes=[[1, 2], [1, 2]])\n",
    "    else:\n",
    "        raise ValueError(X)\n",
    "\n",
    "    X_sqnorms = tf.linalg.diag_part(XX)\n",
    "    Y_sqnorms = tf.linalg.diag_part(YY)\n",
    "\n",
    "    r = lambda x: tf.expand_dims(x, 0)\n",
    "    c = lambda x: tf.expand_dims(x, 1)\n",
    "\n",
    "    K_XX, K_XY, K_YY = 0, 0, 0\n",
    "    for sigma, wt in zip(tf.unstack(sigmas, axis=0), wts):\n",
    "        gamma = 1 / (2 * sigma ** 2)\n",
    "        K_XX += wt * tf.exp(-gamma * (-2 * XX + c(X_sqnorms) + r(X_sqnorms)))\n",
    "        K_XY += wt * tf.exp(-gamma * (-2 * XY + c(X_sqnorms) + r(Y_sqnorms)))\n",
    "        K_YY += wt * tf.exp(-gamma * (-2 * YY + c(Y_sqnorms) + r(Y_sqnorms)))\n",
    "\n",
    "    return K_XX, K_XY, K_YY, tf.reduce_sum(wts)\n",
    "\n",
    "\n",
    "def _mmd2(K_XX, K_XY, K_YY, const_diagonal=False, biased=False):\n",
    "    m = tf.cast(K_XX.get_shape()[0], tf.float64)\n",
    "    n = tf.cast(K_YY.get_shape()[0], tf.float64)\n",
    "\n",
    "    if biased:\n",
    "        c1 = tf.reduce_sum(K_XX) / (m * m)\n",
    "        c2 = tf.reduce_sum(K_YY) / (n * n)\n",
    "        c3 = 2 * tf.reduce_sum(K_XY) / (m * n)\n",
    "        mmd2 = c1 + c2 - c3\n",
    "        # mmd2 = (tf.reduce_sum(K_XX) / (m * m)\n",
    "        #       + tf.reduce_sum(K_YY) / (n * n)\n",
    "        #       - 2 * tf.reduce_sum(K_XY) / (m * n))\n",
    "    else:\n",
    "        if const_diagonal is not False:\n",
    "            trace_X = m * const_diagonal\n",
    "            trace_Y = n * const_diagonal\n",
    "        else:\n",
    "            trace_X = tf.trace(K_XX)\n",
    "            trace_Y = tf.trace(K_YY)\n",
    "\n",
    "        mmd2 = ((tf.reduce_sum(K_XX) - trace_X) / (m * (m - 1))\n",
    "                + (tf.reduce_sum(K_YY) - trace_Y) / (n * (n - 1))\n",
    "                - 2 * tf.reduce_sum(K_XY) / (m * n))\n",
    "\n",
    "    return mmd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unified scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_FID_batch(pos_seqs[:,:,1], g1_seqs[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = MAD()\n",
    "mad.fit(pos_seqs[:64,:,:])\n",
    "mad.compare(pos_seqs[:64,:,:])['mad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_mmd2(pos_seqs[:64,:,:], g2_seqs[:64,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G_metrics(pos_batch, gen_batch):\n",
    "    rbq = seqs_to_scores(gen_batch)\n",
    "    fid = calculate_FID_batch(pos_batch[:,:,1], gen_batch[:,:,1])\n",
    "    \n",
    "    mad_obj = MAD()\n",
    "    mad_obj.fit(pos_batch)\n",
    "    mad = mad_obj.compare(gen_batch)['mad']\n",
    "    \n",
    "    mmd = rbf_mmd2(pos_batch, gen_batch).numpy()\n",
    "    mmd_et = rbf_mmd2(pos_batch[:,:,0], gen_batch[:,:,0]).numpy()\n",
    "    mmd_ts = rbf_mmd2(pos_batch[:,:,1], gen_batch[:,:,1]).numpy()\n",
    "    \n",
    "    return [rbq, fid, mad, mmd, mmd_et, mmd_ts]\n",
    "\n",
    "mts_1 = get_G_metrics(pos_seqs[:,:,:], g1_seqs[:,:,:])\n",
    "mts_2 = get_G_metrics(pos_seqs[:,:,:], g2_seqs[:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_metrics(time_comb_1, time_comb_2):\n",
    "\n",
    "    fid = calculate_FID_batch(time_comb_1.numpy(), time_comb_2.numpy())\n",
    "    mmd = rbf_mmd2(time_comb_1, time_comb_2).numpy()\n",
    "    \n",
    "    return [fid, mmd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate the batch quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_seqs_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchs_to_scores(batch_prefix, num_batchs=30, verbose=True):\n",
    "    scores = []\n",
    "    for i in range(num_batchs):\n",
    "        batch_path = os.path.join(batch_prefix, f'batch_{i}.npy')        \n",
    "        batch_seqs = np.load(batch_path)\n",
    "        batch_score = seqs_to_scores(batch_seqs)\n",
    "        scores.append(batch_score)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Read Batch from:', batch_path)        \n",
    "            print('batch quality score:', batch_score)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_scores = batchs_to_scores(pos_seqs_prefix, num_batchs=30, verbose=True)\n",
    "neg_scores = batchs_to_scores(neg_seqs_prefix, num_batchs=30, verbose=True)\n",
    "g0_scores = batchs_to_scores(g0_seqs_prefix, num_batchs=30, verbose=True)\n",
    "g1_scores = batchs_to_scores(g1_seqs_prefix, num_batchs=30, verbose=True)\n",
    "g2_scores = batchs_to_scores(g2_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pos_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(neg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(g0_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(g1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(g2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "def twoSampleTtest(samp1, samp2):\n",
    "    tset, pval = ttest_ind(samp1, samp2, equal_var = False)\n",
    "    return pval/2\n",
    "\n",
    "def AB_test(data, controls, base, alpha):\n",
    "    pvals = {}\n",
    "    n = len(data[base])\n",
    "    for c in controls:\n",
    "        control = data[c]\n",
    "        pvals[c]= twoSampleTtest(control,data[base])\n",
    "        if pvals[c]>alpha:\n",
    "            print(\"no diff from {} to {}\".format(c, base))\n",
    "            mu = np.mean(control)\n",
    "            std = np.std(control)\n",
    "            print ('CI_{} = ({},{})'.format(c, mu - 1.65*std, mu + 1.65*std))\n",
    "            mu = np.mean(data[base])\n",
    "            std = np.std(data[base])        \n",
    "            print ('CI_{} = ({},{})'.format(base, mu - 1.65*std, mu + 1.65*std))\n",
    "        else:\n",
    "            if pvals[c]<alpha:\n",
    "                mu_c = np.mean(control)\n",
    "                std_c = np.std(control)\n",
    "                mu_b = np.mean(data[base])\n",
    "                std_b = np.std(data[base]) \n",
    "                if mu_c>=mu_b:\n",
    "                    print(\"{} is better than {}\".format(c, base))\n",
    "                    print ('CI_{} = ({},{})'.format(c, mu_c - 1.65*std_c, mu_c + 1.65*std_c))\n",
    "                    print ('CI_{} = ({},{})'.format(base, mu_b - 1.65*std_b, mu_b + 1.65*std_b))\n",
    "                else:\n",
    "                    print(\"{} is better than {}\".format(base, c))\n",
    "                    print ('CI_{} = ({},{})'.format(c, mu_c - 1.65*std_c, mu_c + 1.65*std_c))\n",
    "                    print ('CI_{} = ({},{})'.format(base, mu_b - 1.65*std_b, mu_b + 1.65*std_b))                   \n",
    "\n",
    "                    \n",
    "    print('two-sided t-test p-values', pvals)\n",
    "\n",
    "# controls = np_lst\n",
    "# base = 'pos'\n",
    "# alpha = 0.05\n",
    "# AB_test(mad_pos, controls, base,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbq_data = {'g0' : g0_scores,\n",
    "            'g1' : g1_scores,\n",
    "            'g2' : g2_scores,\n",
    "            'pos': pos_scores,\n",
    "            'neg': neg_scores,            \n",
    "           }\n",
    "controls = rbq_data.keys()\n",
    "base = 'neg'\n",
    "\n",
    "AB_test(rbq_data, controls, base, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgtlstm.oracle import get_G_metrics, get_hidden_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_to_metrics(batch_prefix_pos, batch_prefix_tar, num_batchs=30, verbose=True):\n",
    "    scores = []\n",
    "    for i in range(num_batchs):\n",
    "        pos_batch_path = os.path.join(batch_prefix_pos, f'batch_{i}.npy')        \n",
    "        pos_batch_seqs = np.load(pos_batch_path)\n",
    "        \n",
    "        tar_batch_path = os.path.join(batch_prefix_tar, f'batch_{i}.npy')        \n",
    "        tar_batch_seqs = np.load(tar_batch_path)\n",
    "        \n",
    "        # [rbq, fid, mad, mmd, mmd_et, mmd_ts]\n",
    "        batch_score = get_G_metrics(pos_batch_seqs, tar_batch_seqs)\n",
    "        scores.append(batch_score)\n",
    "        \n",
    "        if verbose:   \n",
    "            print('batch quality score:', batch_score)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics with pos base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_metrics = batches_to_metrics(pos_seqs_prefix, g1_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_metrics = batches_to_metrics(pos_seqs_prefix, g2_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics = batches_to_metrics(pos_seqs_prefix, g0_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_metrics = batches_to_metrics(pos_seqs_prefix, pos_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_metrics = batches_to_metrics(pos_seqs_prefix, neg_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics = np.array(g0_metrics)\n",
    "g1_metrics = np.array(g1_metrics)\n",
    "g2_metrics = np.array(g2_metrics)\n",
    "pos_metrics = np.array(pos_metrics)\n",
    "neg_metrics = np.array(neg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_metrics[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_metrics[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_metrics[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_metrics[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_path = #'.../path-to-gan-generated/performance_test/'\n",
    "\n",
    "np.save(gen_data_path + 'metrics_pos_base/g0_metrics.npy', g0_metrics)\n",
    "np.save(gen_data_path + 'metrics_pos_base/g1_metrics.npy', g1_metrics)\n",
    "np.save(gen_data_path + 'metrics_pos_base/g2_metrics.npy', g2_metrics)\n",
    "np.save(gen_data_path + 'metrics_pos_base/pos_metrics.npy', pos_metrics)\n",
    "np.save(gen_data_path + 'metrics_pos_base/pos_metrics.npy', neg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics with neg base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics_n = batches_to_metrics(neg_seqs_prefix, g0_seqs_prefix, num_batchs=30, verbose=True)\n",
    "g1_metrics_n = batches_to_metrics(neg_seqs_prefix, g1_seqs_prefix, num_batchs=30, verbose=True)\n",
    "g2_metrics_n = batches_to_metrics(neg_seqs_prefix, g2_seqs_prefix, num_batchs=30, verbose=True)\n",
    "pos_metrics_n = batches_to_metrics(neg_seqs_prefix, pos_seqs_prefix, num_batchs=30, verbose=True)\n",
    "neg_metrics_n = batches_to_metrics(neg_seqs_prefix, neg_seqs_prefix, num_batchs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics_n = np.array(g0_metrics_n)\n",
    "g1_metrics_n = np.array(g1_metrics_n)\n",
    "g2_metrics_n = np.array(g2_metrics_n)\n",
    "pos_metrics_n = np.array(pos_metrics_n)\n",
    "neg_metrics_n = np.array(neg_metrics_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_metrics_n[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_metrics_n[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_metrics_n[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_metrics_n[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_metrics_n[:,-1].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
