{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "starting-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "module_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/\"\n",
    "data_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/data/long_seqs_v11/\"\n",
    "model_save_dir = '/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11'\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "blessed-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "N_DATA = 4000\n",
    "T = 20\n",
    "VOCAB = ['start', 'view', 'click', 'install']\n",
    "EVENT_VOCAB_DIM = len(VOCAB)\n",
    "EMB_DIM = 16\n",
    "HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-object",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reflected-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data_path = os.path.join(data_path, 'positive_long_sequences.pickle')\n",
    "# neg_data_path = os.path.join(data_path, 'negative_long_sequences.pickle')\n",
    "\n",
    "def load_sequence_from_pickle_to_numpy(pickle_file_path, use_init_token=False):\n",
    "    \"\"\"\n",
    "        A list of sequence in format of (event_type, time_delta)\n",
    "    :param pickle_file_path: e.g. /.../project-basileus/seq-gan/data/fixed_length/valid_sequences.pickle\n",
    "    :return: (event_type_seqs, time_delta)\n",
    "    \"\"\"\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "        raw_seqs = pickle.load(f)\n",
    "\n",
    "    if not raw_seqs or not raw_seqs[0]:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    N = len(raw_seqs)\n",
    "    T = len(raw_seqs[0])\n",
    "    \n",
    "    seqs = np.array(raw_seqs)\n",
    "        \n",
    "    et_seqs = seqs[:, :, 0].astype(np.float64).reshape((N, T, 1))\n",
    "    ts_seqs = seqs[:, :, 1].astype(np.float64).reshape((N, T, 1))\n",
    "    \n",
    "    return et_seqs, ts_seqs\n",
    "\n",
    "raw_pos_event_type_seqs, raw_pos_timestamp_seqs = load_sequence_from_pickle_to_numpy(pos_data_path, use_init_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "saving-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast indicator data into one-hot\n",
    "pos_event_type_seqs = tf.cast(raw_pos_event_type_seqs, tf.int32)\n",
    "pos_event_type_seqs = tf.one_hot(pos_event_type_seqs, depth=EVENT_VOCAB_DIM, axis=2, dtype=tf.float64)\n",
    "pos_event_type_seqs = tf.squeeze(pos_event_type_seqs, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stylish-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcore_norm(data):\n",
    "    N = data.shape[0]\n",
    "    \n",
    "    _mean = tf.reduce_mean(data, axis=0)\n",
    "    _mean = tf.expand_dims(_mean, axis=0)\n",
    "    _mean = tf.repeat(_mean, N, axis=0)\n",
    "\n",
    "    _std = tf.math.reduce_std(data, axis=0)\n",
    "    _std = tf.expand_dims(_std, axis=0)\n",
    "    _std = tf.repeat(_std, N, axis=0)\n",
    "\n",
    "    return (data - _mean) / _std, _mean[0,:,:], _std[0,:,:]\n",
    "\n",
    "def get_mean_std(data):\n",
    "    _mean = tf.reduce_mean(data, axis=0)\n",
    "    _mean = tf.expand_dims(_mean, axis=0)\n",
    "\n",
    "    _std = tf.math.reduce_std(data, axis=0)\n",
    "    _std = tf.expand_dims(_std, axis=0)\n",
    "\n",
    "    return _mean, _std\n",
    "\n",
    "def apply_mean_std(data, _mean, _std):\n",
    "    N = data.shape[0]\n",
    "    \n",
    "    _mean = tf.reshape(_mean, (1, T, 1))\n",
    "    _mean = tf.repeat(_mean, N, axis=0)\n",
    "    \n",
    "    _std = tf.reshape(_std, (1, T, 1))\n",
    "    _std = tf.repeat(_std, N, axis=0)\n",
    "    \n",
    "    return data * _std + _mean\n",
    "\n",
    "pos_timestamp_seqs, GLOBAL_MEAN, GLOBAL_STD = zcore_norm(raw_pos_timestamp_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-smoke",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prepared-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(features: np.array, labels: np.array, batch_size=2, epochs=10, buffer_size=10000):\n",
    "    \"\"\"\n",
    "    Create dataset from numpy arrays\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deluxe-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_noise(max_token=EVENT_VOCAB_DIM, time_mean=0, time_std=1):\n",
    "    init_token_noise_index = tf.random.uniform(shape=[BATCH_SIZE, 1, 1], maxval=max_token, dtype=tf.int32)\n",
    "    init_token_noise = tf.squeeze(tf.one_hot(init_token_noise_index, EVENT_VOCAB_DIM, axis=2, dtype=tf.float64), axis=3)\n",
    "    init_time_noise = tf.random.truncated_normal(shape=[BATCH_SIZE, 1, 1], mean=time_mean, stddev=time_std, dtype=tf.float64)\n",
    "    return init_token_noise, init_time_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "composed-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_FID_batch(batch1, batch2, weight=1, N=4000, T=20):\n",
    "    batch1, batch2 = np.array(batch1).reshape((N, T)), np.array(batch2).reshape((N, T))\n",
    "    mu1, sigma1 = batch1.mean(axis=0), np.cov(batch1, rowvar=False)\n",
    "    mu2, sigma2 = batch2.mean(axis=0), np.cov(batch2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid2 = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid2\n",
    "\n",
    "calculate_FID_score = lambda batch: calculate_FID_batch(raw_pos_timestamp_seqs, batch)\n",
    "# calculate_FID_score(raw_pos_timestamp_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satellite-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAD:\n",
    "    \"\"\" Sum square of one-hot distance between tokens\n",
    "    Params:\n",
    "    -- batch1         : The first batch of sequences to be compared with the second one\n",
    "                        or it can be the comparison base\n",
    "    -- batch2\n",
    "    Returns:\n",
    "    --   : dict, sum square of distances and base medians\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_ssad = []\n",
    "        self.base_med = []\n",
    "        self.base_med_oh = []\n",
    "        self.one_hot_map = {0: [0, 0, 0, 0, 0],\n",
    "                            1: [1, 0, 0, 0, 0],\n",
    "                            2: [0, 1, 0, 0, 0],\n",
    "                            3: [0, 0, 1, 0, 0]}\n",
    "\n",
    "    def nan_if(self, arr, value):\n",
    "        return np.where(arr == value, np.nan, arr)\n",
    "\n",
    "    def fit(self, batch1):\n",
    "        assert len(batch1) > 1, 'batch1 should have more than one sequence'\n",
    "        X_tok = []\n",
    "        for i in batch1:\n",
    "            X_tok.append([j[0] for j in i])\n",
    "        X_tok_t = np.array(X_tok).T\n",
    "        X_tok_oh = [[self.one_hot_map[j] for j in i] for i in X_tok]\n",
    "        medians = [int(i) for i in np.nanmedian(self.nan_if(X_tok_t, 0), axis=1)]\n",
    "        medians_oh = [self.one_hot_map[j] for j in medians]\n",
    "        self.base_med = medians\n",
    "        self.base_med_oh = medians_oh\n",
    "        tok_dist = []\n",
    "        for tok in X_tok_oh:\n",
    "            dist = []\n",
    "            for j in range(len(tok)):\n",
    "                tt = np.array(tok[j])\n",
    "                med = np.array(medians_oh[j])\n",
    "                # skip 0\n",
    "                dist.append(np.nansum(np.abs(self.nan_if(tt, 0) - med)))\n",
    "            tok_dist.append(dist)\n",
    "        self.base_ssad = np.mean(tok_dist)\n",
    "\n",
    "    def compare(self, batch2):\n",
    "        assert len(batch2) > 1, 'batch2 should have more than one sequence'\n",
    "        X_tok = []\n",
    "        for i in batch2:\n",
    "            X_tok.append([j[0] for j in i])\n",
    "        X_tok_t = np.array(X_tok).T\n",
    "        X_tok_oh = [[self.one_hot_map[j] for j in i] for i in X_tok]\n",
    "        medians = [int(i) for i in np.nanmedian(self.nan_if(X_tok_t, 0), axis=1)]\n",
    "        medians_oh = [self.one_hot_map[j] for j in medians]\n",
    "        tok_dist = []\n",
    "        for tok in X_tok_oh:\n",
    "            dist = []\n",
    "            for j in range(len(tok)):\n",
    "                tt = np.array(tok[j])\n",
    "                med = np.array(self.base_med_oh[j])\n",
    "                # skip 0\n",
    "                dist.append(np.nansum(np.abs(self.nan_if(tt, 0) - med)))\n",
    "            tok_dist.append(dist)\n",
    "        compare_ssd = np.mean(tok_dist)\n",
    "        return {'mad': compare_ssd,\n",
    "                'base_medians': np.array(self.base_med),\n",
    "                'base_medians_oh': np.array(self.base_med_oh),\n",
    "                'comp_medians': np.array(medians),\n",
    "                'comp_medians_oh': np.array(medians_oh)}\n",
    "    \n",
    "mad_obj = MAD()\n",
    "mad_obj.fit(raw_pos_event_type_seqs)\n",
    "calculate_MAD_score = lambda batch: mad_obj.compare(batch)['mad']\n",
    "# calculate_MAD_score(raw_pos_event_type_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "systematic-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_TYPES = ['A', 'B', 'C', 'D']\n",
    "EVENT_ENCODE = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "\n",
    "MIN_SAME_DELAY = 20\n",
    "MAX_PAIR_DELAY = 200\n",
    "\n",
    "\n",
    "def check_min_delay_rule(seq, use_init_token=False):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]\n",
    "    prev_et, _ = None, 0.0\n",
    "    for et, dt in seq:\n",
    "        if et == prev_et and dt < MIN_SAME_DELAY:\n",
    "            return False\n",
    "        prev_et = et\n",
    "    return True\n",
    "\n",
    "def check_paring_rule(seq, use_init_token=False):\n",
    "    if use_init_token:\n",
    "        seq = seq[1:]    \n",
    "    # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq)-1, -1, -1):\n",
    "        if seq[i][0] == EVENT_ENCODE['D']: # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif seq[i][0] == EVENT_ENCODE['C'] and queue: # encounter a C event\n",
    "            queue.pop(0)\n",
    "    return len(queue) == 0\n",
    "\n",
    "def check_max_delay_rule(seq, use_init_token=False):    \n",
    "    if use_init_token:\n",
    "        seq = seq[1:]    \n",
    "        \n",
    "    def recover_timedelta_to_timestamp(time_seq):\n",
    "        csum = []\n",
    "        curr = 0\n",
    "        for dt in time_seq:\n",
    "            if dt != 0:\n",
    "                curr += dt\n",
    "                csum.append(curr)\n",
    "            else:\n",
    "                csum.append(0)\n",
    "        return csum\n",
    "    \n",
    "    ets = [e[0] for e in seq]\n",
    "    tss = recover_timedelta_to_timestamp([e[1] for e in seq])\n",
    "        \n",
    "    # one-pass: add D to queue to be attributed to the first available C in a reversed linear scanning\n",
    "    queue = []\n",
    "    for i in range(len(seq)-1, -1, -1):\n",
    "        if ets[i] == EVENT_ENCODE['D']: # encounter a D event\n",
    "            queue.append(i)\n",
    "        elif ets[i] == EVENT_ENCODE['C'] and queue: # encounter a C event\n",
    "            if tss[queue[0]] - tss[i] <= MAX_PAIR_DELAY:\n",
    "                queue.pop(0)\n",
    "            else:\n",
    "                return False\n",
    "    # for rule 6, it's fine if there are unpaired D in queue\n",
    "    # b/c this rules is to ensure for each paired (C, D), the delay is bounded\n",
    "    return True\n",
    "\n",
    "\n",
    "def calculate_rule_score(batch):\n",
    "    N_batch = batch.shape[0]\n",
    "    cnt = 0\n",
    "    for i in range(N_batch):\n",
    "        seq = batch[i, :, :]\n",
    "        if check_min_delay_rule(seq) and check_paring_rule(seq) and check_max_delay_rule(seq):\n",
    "            cnt += 1    \n",
    "    return cnt / N_batch\n",
    "\n",
    "# calculate_rule_score(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-organic",
   "metadata": {},
   "source": [
    "## Create multitype SeqGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "linear-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Reshape, Dense, Dropout, Activation, Multiply, Add, Lambda\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sgtlstm.TimeLSTM import TimeLSTM0, TimeLSTM1, TimeLSTM2, TimeLSTM3\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "def build_G(batch_size, event_vocab_dim, emb_dim, hidden_dim=16):\n",
    "    # inputs of Time-LSTM:\n",
    "    i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "    i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "\n",
    "    embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "    merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "\n",
    "    hm = LSTM(hidden_dim,\n",
    "          name='lstm_token',\n",
    "          stateful=True,\n",
    "          return_sequences=False,\n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "\n",
    "    \n",
    "    tm = LSTM(hidden_dim,\n",
    "          name='lstm_time',\n",
    "          stateful=True,\n",
    "          return_sequences=False,\n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "    \n",
    "    \n",
    "    token_time_comb = tf.keras.layers.concatenate([hm, tm], axis=1)\n",
    "    \n",
    "    dense_combined = Dense(hidden_dim, \n",
    "                           activation='elu',\n",
    "                           name='dense_combination')(token_time_comb)\n",
    "        \n",
    "    token_logits = Dense(event_vocab_dim,\n",
    "                   activation='linear',\n",
    "                   name='dense_token',\n",
    "                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                   bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(dense_combined)\n",
    "        \n",
    "    time_delta_out = Dense(1,\n",
    "                   activation='linear',\n",
    "                   name='dense_time',\n",
    "                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                   bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(dense_combined)\n",
    "    \n",
    "    generator = Model(\n",
    "        inputs=[i_et, i_ts],\n",
    "        outputs=[token_logits, time_delta_out])\n",
    "        \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alternate-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_D(batch_size, T, event_vocab_dim, emb_dim, hidden_dim, dropout_rate=0.25):\n",
    "    # normal LSTM\n",
    "    i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "    i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "    \n",
    "    embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "    merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "    hm = LSTM(hidden_dim,\n",
    "          name='lstm_token',\n",
    "          stateful=False,\n",
    "          return_sequences=False, \n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "\n",
    "    tm = LSTM(hidden_dim,\n",
    "          name='lstm_time',\n",
    "          stateful=False,\n",
    "          return_sequences=False,\n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "    \n",
    "    token_time_comb = tf.keras.layers.concatenate([hm, tm], axis=1)\n",
    "    \n",
    "    dropped = Dropout(rate=dropout_rate)(token_time_comb)\n",
    "    \n",
    "    prob = Dense(1, \n",
    "             activation='sigmoid',\n",
    "             name='final',\n",
    "             kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None),\n",
    "             bias_initializer=tf.keras.initializers.Constant(value=0.1))(dropped)\n",
    "        \n",
    "    discriminator = Model(\n",
    "        inputs=[i_et, i_ts],\n",
    "        outputs=prob)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "devoted-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic is a copy of D, except that stateful=True\n",
    "\n",
    "def build_critic(batch_size, T, event_vocab_dim, emb_dim, hidden_dim, dropout_rate=0.25):\n",
    "    # normal LSTM\n",
    "    i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "    i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "    \n",
    "    embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "    merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "    hm = LSTM(hidden_dim,\n",
    "          name='lstm_token',\n",
    "          stateful=True, # stateful, critic makes prediction on a partial sequence\n",
    "          return_sequences=False,\n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "\n",
    "    tm = LSTM(hidden_dim,\n",
    "          name='lstm_time',\n",
    "          stateful=True, # stateful, critic makes prediction on a partial sequence\n",
    "          return_sequences=False,\n",
    "          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "          bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "    \n",
    "    token_time_comb = tf.keras.layers.concatenate([hm, tm], axis=1)\n",
    "    \n",
    "    dropped = Dropout(rate=dropout_rate)(token_time_comb)\n",
    "    \n",
    "    critic_value = Dense(1, \n",
    "             activation='sigmoid',\n",
    "             name='critic_final',\n",
    "             kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None),\n",
    "             bias_initializer=tf.keras.initializers.Constant(value=0.1))(dropped)\n",
    "        \n",
    "    discriminator = Model(\n",
    "        inputs=[i_et, i_ts],\n",
    "        outputs=critic_value)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "healthy-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam, SGD\n",
    "# from tensorflow.keras.layers import Input, LSTM, Embedding, Reshape, Dense, Dropout, Activation, Multiply, Add, Lambda\n",
    "# from tensorflow.keras import regularizers\n",
    "\n",
    "# from sgtlstm.TimeLSTM import TimeLSTM0, TimeLSTM1, TimeLSTM2, TimeLSTM3\n",
    "\n",
    "# tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# def build_G(batch_size, event_vocab_dim, emb_dim, hidden_dim=16):\n",
    "#     # inputs of Time-LSTM:\n",
    "#     i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "#     i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "\n",
    "#     embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "#     merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "#     hm, tm = TimeLSTM1(hidden_dim,\n",
    "#                        name='time_lstm',\n",
    "#                        stateful=True, \n",
    "#                        return_sequences=False,\n",
    "#                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        time_kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)    \n",
    "        \n",
    "#     token_logits = Dense(event_vocab_dim,\n",
    "#                    activation='linear',\n",
    "#                    name='dense_token',\n",
    "#                    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                    bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(hm)\n",
    "        \n",
    "#     time_delta_out = Dense(1,\n",
    "#                    activation='linear',\n",
    "#                    name='dense_time',\n",
    "#                    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                    bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(tm)\n",
    "    \n",
    "#     generator = Model(\n",
    "#         inputs=[i_et, i_ts],\n",
    "#         outputs=[token_logits, time_delta_out])\n",
    "        \n",
    "#     return generator\n",
    "\n",
    "\n",
    "# def build_D(batch_size, T, event_vocab_dim, emb_dim, hidden_dim, dropout_rate=0.25):\n",
    "#     # normal LSTM\n",
    "#     i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "#     i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "    \n",
    "#     embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "#     merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "#     hm, tm = TimeLSTM1(hidden_dim,\n",
    "#                        name='time_lstm',\n",
    "#                        stateful=True, \n",
    "#                        return_sequences=False,\n",
    "#                        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        time_kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#                        bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "    \n",
    "#     token_time_comb = tf.keras.layers.concatenate([hm, tm], axis=1)\n",
    "    \n",
    "#     dropped = Dropout(rate=dropout_rate)(token_time_comb)\n",
    "    \n",
    "#     prob = Dense(1, \n",
    "#              activation='sigmoid',\n",
    "#              name='final',\n",
    "#              kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None),\n",
    "#              bias_initializer=tf.keras.initializers.Constant(value=0.1))(dropped)\n",
    "        \n",
    "#     discriminator = Model(\n",
    "#         inputs=[i_et, i_ts],\n",
    "#         outputs=prob)\n",
    "#     return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-neighborhood",
   "metadata": {},
   "source": [
    "## Define rollout and sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "modified-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_from_initial_mcc(G, batch_size, init_et, init_ts, L=T):\n",
    "    # Begin from dummy init state (init_token=1, init_timestamp=0.0)\n",
    "    all_state_et = init_et\n",
    "    all_state_ts = init_ts\n",
    "    all_token_logits = tf.zeros_like(init_et)\n",
    "    \n",
    "    l_prefix = init_et.shape[1]\n",
    "    \n",
    "    G.reset_states()\n",
    "#     # LSTM-token\n",
    "    G.layers[4].states[0] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "    G.layers[4].states[1] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "    # LSTM-time\n",
    "    G.layers[5].states[0] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "    G.layers[5].states[1] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "    \n",
    "    # Time-LSTM\n",
    "#     G.layers[4].states[0] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "#     G.layers[4].states[1] = tf.Variable(tf.random.normal(shape=(BATCH_SIZE, HIDDEN_DIM), mean=0.0, stddev=1, dtype=tf.float64))\n",
    "\n",
    "    for _ in range(L + 1 - l_prefix):  # sequence length\n",
    "        curr_state_et = all_state_et[:, -1:, :]\n",
    "        curr_state_ts = all_state_ts[:, -1:, :]\n",
    "        \n",
    "        # add step noise to token and time inputs\n",
    "#         curr_state_et = tf.cast(tf.where(curr_state_et == 1, 0.9, 0.1/3), tf.float64)\n",
    "#         curr_state_ts = curr_state_ts + tf.random.truncated_normal(shape=tf.shape(curr_state_ts), mean=0.0, stddev=1, dtype=tf.float64)\n",
    "\n",
    "        token_logits, time_delta_out = G([curr_state_et, curr_state_ts])\n",
    "        \n",
    "        # non-differentiable sampling\n",
    "        sampled_et_ind = tf.random.categorical(token_logits, num_samples=1, dtype=tf.int32)\n",
    "        sampled_et = tf.one_hot(sampled_et_ind, depth=EVENT_VOCAB_DIM, axis=2, dtype=tf.float64)\n",
    "        \n",
    "        sampled_et = tf.reshape(sampled_et, [batch_size, 1, EVENT_VOCAB_DIM])        \n",
    "        sampled_et = tf.cast(sampled_et, dtype=tf.float64) # cast sampled_et into float\n",
    "        \n",
    "        time_delta_out = tf.reshape(time_delta_out, [batch_size, 1, 1]) \n",
    "        token_logits = tf.reshape(token_logits, [batch_size, 1, EVENT_VOCAB_DIM]) \n",
    "        \n",
    "        # Do NOT stop genererating once hit end_token; G is supposed to learn it.\n",
    "        all_state_et = tf.concat([all_state_et, sampled_et], axis=1)\n",
    "        all_state_ts = tf.concat([all_state_ts, time_delta_out], axis=1)\n",
    "        all_token_logits = tf.concat([all_token_logits, token_logits], axis=1)\n",
    "\n",
    "    # the initlal random states are excluded in output\n",
    "    return all_state_et[:, 1:, :], all_state_ts[:, 1:, :], all_token_logits[:,1:,:]\n",
    "\n",
    "\n",
    "def generate_sequences_mcc(N_gen, generator, batch_size, T):\n",
    "    \"\"\"\n",
    "        Generate sequences batch per batch\n",
    "    :param N_gen: total number of seqs to be generated\n",
    "    :param generator:\n",
    "    :param batch_size:\n",
    "    :param T:\n",
    "    :return: a python list of shape [N_gen, T, 1]\n",
    "    \"\"\"\n",
    "    N = 0\n",
    "    all_type_seq = None\n",
    "    all_time_seq = None\n",
    "    all_token_logits = None\n",
    "    \n",
    "    init_token_noise, init_time_noise = generate_initial_noise()\n",
    "        \n",
    "    while N < N_gen:\n",
    "        batch_state_et, batch_state_ts, batch_token_logits = rollout_from_initial_mcc(generator, batch_size, init_token_noise, init_time_noise, T)\n",
    "\n",
    "        if all_type_seq is None or all_time_seq is None:\n",
    "            all_type_seq = batch_state_et\n",
    "            all_time_seq = batch_state_ts\n",
    "            all_token_logits = batch_token_logits\n",
    "        else:\n",
    "            all_type_seq = tf.concat([all_type_seq, batch_state_et], axis=0)\n",
    "            all_time_seq = tf.concat([all_time_seq, batch_state_ts], axis=0)\n",
    "            all_token_logits = tf.concat([all_token_logits, batch_token_logits], axis=0)\n",
    "\n",
    "        N += batch_size\n",
    "\n",
    "    all_type_seq = all_type_seq[:N_gen, :, :]\n",
    "    all_time_seq = all_time_seq[:N_gen, :, :]\n",
    "    all_token_logits = all_token_logits[:N_gen, :, :]\n",
    "\n",
    "    return all_type_seq, all_time_seq, all_token_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-stadium",
   "metadata": {},
   "source": [
    "## Pre-Training using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dense-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_discriminator(event_type_batch, time_delta_batch, label_batch, discriminator, verbose=False, optimizer=Adam(lr=0.001)):\n",
    "    # train the discriminator\n",
    "    with tf.GradientTape() as tape:\n",
    "        # train discriminator\n",
    "        true_prob = discriminator([event_type_batch, time_delta_batch])\n",
    "\n",
    "        # cross-entropy loss\n",
    "        discriminator_loss = ce_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(label_batch, true_prob, from_logits=False)\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print('total discriminator loss:{}'.format(discriminator_loss))\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    return discriminator_loss\n",
    "\n",
    "\n",
    "def pretrain_generator(event_type_batch, time_delta_batch, generator, verbose=False, optimizer=Adam(lr=0.001)):\n",
    "    _, T, _ = event_type_batch.shape\n",
    "    \n",
    "    # train the generator\n",
    "    with tf.GradientTape() as tape:\n",
    "        generator.reset_states()\n",
    "        step_token_ce_loss_list = []\n",
    "        step_time_mxe_loss_list = []\n",
    "\n",
    "        for i in range(0, T - 1):\n",
    "            curr_state_et = event_type_batch[:, i:i + 1, :]\n",
    "            curr_state_ts = time_delta_batch[:, i:i + 1, :]\n",
    "            \n",
    "            target_et = event_type_batch[:, i + 1, :]\n",
    "            target_ts = time_delta_batch[:, i + 1, :]            \n",
    "            \n",
    "            token_logits, time_delta_out = generator([curr_state_et, curr_state_ts])\n",
    "\n",
    "            token_ce_losses = tf.keras.losses.categorical_crossentropy(target_et, token_logits, from_logits=True)\n",
    "            token_ce_loss = tf.reduce_mean(token_ce_losses)\n",
    "            step_token_ce_loss_list.append(token_ce_loss)\n",
    "            \n",
    "            time_mxe_losses = tf.keras.losses.MAE(target_ts, time_delta_out)\n",
    "            time_mxe_loss = tf.reduce_mean(time_mxe_losses)\n",
    "            step_time_mxe_loss_list.append(time_mxe_loss)                        \n",
    "    \n",
    "        episode_token_ce_loss = tf.reduce_mean(step_token_ce_loss_list)\n",
    "        episode_time_mxe_loss = tf.reduce_mean(step_time_mxe_loss_list)\n",
    "        generator_loss = episode_token_ce_loss + episode_time_mxe_loss\n",
    "\n",
    "    if verbose:\n",
    "        print('token ce loss:{}'.format(episode_token_ce_loss))\n",
    "        print('time mae loss:{}'.format(episode_time_mxe_loss))\n",
    "        print('train loss:{}'.format(generator_loss))\n",
    "\n",
    "    # apply gradient decent per batch\n",
    "    grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "    return generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-worker",
   "metadata": {},
   "source": [
    "### pre-train G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "attached-allen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_total_G = pos_event_type_seqs.shape[0]\n",
    "\n",
    "EPOCHS = 3\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_G / BATCH_SIZE)\n",
    "\n",
    "pretrain_G_dataset = create_dataset((pos_event_type_seqs, pos_timestamp_seqs),\n",
    "                                  np.ones((N_total_G, 1)),\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  buffer_size=N_total_G)\n",
    "_TOTAL_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "mobile-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_gen_loss_history = []\n",
    "\n",
    "pretrained_generator = build_G(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "charitable-woman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f4849a350>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f4849a350>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "token ce loss:1.4297610685091509\n",
      "time mae loss:0.8102964999059232\n",
      "train loss:2.2400575684150743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2\n",
      "token ce loss:1.3824813390791142\n",
      "time mae loss:0.8078768942268217\n",
      "train loss:2.190358233305936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3\n",
      "token ce loss:1.3603935554606859\n",
      "time mae loss:0.7968666094972093\n",
      "train loss:2.1572601649578953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:03,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4\n",
      "token ce loss:1.3638821646099162\n",
      "time mae loss:0.7827206920984559\n",
      "train loss:2.146602856708372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:04,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5\n",
      "token ce loss:1.3668334285488115\n",
      "time mae loss:0.7805461581412271\n",
      "train loss:2.1473795866900387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:05,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6\n",
      "token ce loss:1.3598033114333585\n",
      "time mae loss:0.7898709780835271\n",
      "train loss:2.1496742895168857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7\n",
      "token ce loss:1.3501882059906665\n",
      "time mae loss:0.7820348552699143\n",
      "train loss:2.132223061260581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8\n",
      "token ce loss:1.3492598949762507\n",
      "time mae loss:0.7834722857788528\n",
      "train loss:2.132732180755103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9\n",
      "token ce loss:1.3408185913359618\n",
      "time mae loss:0.7859998575001824\n",
      "train loss:2.1268184488361443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 10\n",
      "token ce loss:1.332043169656852\n",
      "time mae loss:0.7854343313245531\n",
      "train loss:2.117477500981405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:09,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 11\n",
      "token ce loss:1.3294287553437822\n",
      "time mae loss:0.7880910235409002\n",
      "train loss:2.1175197788846827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:10,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 12\n",
      "token ce loss:1.3266973931450012\n",
      "time mae loss:0.781516894648236\n",
      "train loss:2.1082142877932375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:11,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 13\n",
      "token ce loss:1.323825366953003\n",
      "time mae loss:0.7758475271329229\n",
      "train loss:2.0996728940859257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14\n",
      "token ce loss:1.3234860433244429\n",
      "time mae loss:0.7930476244834652\n",
      "train loss:2.116533667807908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15\n",
      "token ce loss:1.326557020265003\n",
      "time mae loss:0.782767228578124\n",
      "train loss:2.109324248843127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16\n",
      "token ce loss:1.322190460576782\n",
      "time mae loss:0.7854038286550077\n",
      "train loss:2.10759428923179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17\n",
      "token ce loss:1.316508633055769\n",
      "time mae loss:0.7700862948090426\n",
      "train loss:2.0865949278648115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 18\n",
      "token ce loss:1.3147999075132282\n",
      "time mae loss:0.7856230446311122\n",
      "train loss:2.1004229521443403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 19\n",
      "token ce loss:1.3127208989719603\n",
      "time mae loss:0.7826448322748295\n",
      "train loss:2.09536573124679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:18,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 20\n",
      "token ce loss:1.309259125751405\n",
      "time mae loss:0.7733634368106524\n",
      "train loss:2.0826225625620576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:19,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 21\n",
      "token ce loss:1.313441986201901\n",
      "time mae loss:0.7887055974878739\n",
      "train loss:2.1021475836897747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:20,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 22\n",
      "token ce loss:1.302237970563268\n",
      "time mae loss:0.7767801797895897\n",
      "train loss:2.0790181503528578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:21,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 23\n",
      "token ce loss:1.3071395811698903\n",
      "time mae loss:0.7819585244634333\n",
      "train loss:2.0890981056333233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:22,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 24\n",
      "token ce loss:1.3049790889287345\n",
      "time mae loss:0.7819231596700846\n",
      "train loss:2.086902248598819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:23,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 25\n",
      "token ce loss:1.298887749320043\n",
      "time mae loss:0.778625510859132\n",
      "train loss:2.077513260179175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [00:24,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 26\n",
      "token ce loss:1.3033745586622008\n",
      "time mae loss:0.7768005104174446\n",
      "train loss:2.0801750690796452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:25,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 27\n",
      "token ce loss:1.2949149218295297\n",
      "time mae loss:0.7795714611599985\n",
      "train loss:2.0744863829895284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [00:26,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 28\n",
      "token ce loss:1.2928710836338688\n",
      "time mae loss:0.7808646771536938\n",
      "train loss:2.073735760787563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [00:27,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 29\n",
      "token ce loss:1.2896759658613863\n",
      "time mae loss:0.7870204333932395\n",
      "train loss:2.076696399254626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [00:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 30\n",
      "token ce loss:1.2964983332507212\n",
      "time mae loss:0.7736234268158761\n",
      "train loss:2.0701217600665975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [00:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 31\n",
      "token ce loss:1.29876293252765\n",
      "time mae loss:0.7758471049203007\n",
      "train loss:2.074610037447951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [00:30,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 32\n",
      "token ce loss:1.2978327258042446\n",
      "time mae loss:0.7959846315616568\n",
      "train loss:2.0938173573659014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [00:31,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 33\n",
      "token ce loss:1.2943247242568934\n",
      "time mae loss:0.7827617848632659\n",
      "train loss:2.0770865091201594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [00:32,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 34\n",
      "token ce loss:1.2911590848398042\n",
      "time mae loss:0.7781059221282228\n",
      "train loss:2.069265006968027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [00:33,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 35\n",
      "token ce loss:1.2858037204509352\n",
      "time mae loss:0.7735953982735255\n",
      "train loss:2.0593991187244605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [00:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 36\n",
      "token ce loss:1.2909523334775088\n",
      "time mae loss:0.7707368926963586\n",
      "train loss:2.0616892261738675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [00:35,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 37\n",
      "token ce loss:1.2887655689761346\n",
      "time mae loss:0.7804171701901715\n",
      "train loss:2.069182739166306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [00:36,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 38\n",
      "token ce loss:1.2933104244943865\n",
      "time mae loss:0.7784248098448782\n",
      "train loss:2.0717352343392648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [00:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 39\n",
      "token ce loss:1.2917742081366186\n",
      "time mae loss:0.7795866502275766\n",
      "train loss:2.071360858364195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [00:38,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 40\n",
      "token ce loss:1.2860569400032151\n",
      "time mae loss:0.7834438162558871\n",
      "train loss:2.069500756259102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [00:38,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 41\n",
      "token ce loss:1.2894921702350717\n",
      "time mae loss:0.7665345972729094\n",
      "train loss:2.056026767507981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [00:39,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 42\n",
      "token ce loss:1.2821232409246115\n",
      "time mae loss:0.7681254306858615\n",
      "train loss:2.050248671610473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [00:40,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 43\n",
      "token ce loss:1.285756990443013\n",
      "time mae loss:0.7682815204866507\n",
      "train loss:2.0540385109296637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [00:41,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 44\n",
      "token ce loss:1.2825614090918493\n",
      "time mae loss:0.7725570103520516\n",
      "train loss:2.055118419443901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [00:42,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 45\n",
      "token ce loss:1.2839594062357775\n",
      "time mae loss:0.7966468888637873\n",
      "train loss:2.0806062950995647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [00:43,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 46\n",
      "token ce loss:1.276259760085819\n",
      "time mae loss:0.7877001128950027\n",
      "train loss:2.0639598729808215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:44,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "OPTIMIZER = Adam(lr=1e-3)\n",
    "# _TOTAL_STEPS = 100\n",
    "\n",
    "for feature_batch, _ in tqdm(pretrain_G_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    step += 1\n",
    "    print('Training Step:', step)\n",
    "        \n",
    "    gen_loss =  pretrain_generator(event_type_batch, time_delta_batch, pretrained_generator, verbose=True, optimizer=OPTIMIZER)                    \n",
    "    pretrain_gen_loss_history.append(gen_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "driven-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/pretrained_gen_weights'):\n",
    "    os.makedirs(model_save_dir + '/pretrained_gen_weights')\n",
    "\n",
    "G_save_path = model_save_dir + '/pretrained_gen_weights/model.tf'\n",
    "pretrained_generator.save_weights(G_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "configured-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      80          event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_10 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_token (LSTM)               (256, 128)           74752       tf_op_layer_concat_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_time (LSTM)                (256, 128)           74752       tf_op_layer_concat_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (256, 256)           0           lstm_token[0][0]                 \n",
      "                                                                 lstm_time[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_combination (Dense)       (256, 128)           32896       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_token (Dense)             (256, 4)             516         dense_combination[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_time (Dense)              (256, 1)             129         dense_combination[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 183,125\n",
      "Trainable params: 183,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload_pretrained_gen = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "reload_pretrained_gen.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "reload_pretrained_gen.load_weights(G_save_path)\n",
    "reload_pretrained_gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-container",
   "metadata": {},
   "source": [
    "### pre-train D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "shaped-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fake_D = N_real_D = N_total_G "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "discrete-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data by G to pre-train D\n",
    "fake_pos_event_type_seqs, fake_pos_timestamp_seqs, _ = generate_sequences_mcc(N_fake_D, pretrained_generator, BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "korean-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data by G to pre-train D\n",
    "real_pos_event_type_seqs = pos_event_type_seqs[0:N_real_D, :, :]\n",
    "real_pos_timestamp_seqs = pos_timestamp_seqs[0:N_real_D, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "outstanding-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_D = N_fake_D + N_real_D\n",
    "\n",
    "pretrain_D_et = tf.concat([fake_pos_event_type_seqs, real_pos_event_type_seqs], axis=0)\n",
    "pretrain_D_ts = tf.concat([fake_pos_timestamp_seqs, real_pos_timestamp_seqs], axis=0)\n",
    "pretrain_D_labels = tf.concat([np.zeros((N_fake_D, 1)), np.ones((N_real_D, 1))], axis=0)\n",
    "\n",
    "EPOCHS = 1\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_D / BATCH_SIZE)\n",
    "\n",
    "pretrain_D_dataset = create_dataset((pretrain_D_et, pretrain_D_ts),\n",
    "                                    pretrain_D_labels,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    buffer_size=N_total_D) # shuffle the entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "direct-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_disc_token_loss_history = []\n",
    "\n",
    "pretrained_discriminator = build_D(batch_size=BATCH_SIZE,\n",
    "                                   T=T,\n",
    "                                   event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "                                   emb_dim=EMB_DIM,\n",
    "                                   hidden_dim=HIDDEN_DIM,    \n",
    "                                   dropout_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "external-extent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f4807e290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f4807e290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "total discriminator loss:0.703598470116161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2\n",
      "total discriminator loss:0.6830114051045489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3\n",
      "total discriminator loss:0.6670575900989302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4\n",
      "total discriminator loss:0.6366159271587752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5\n",
      "total discriminator loss:0.6216779262451122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6\n",
      "total discriminator loss:0.5955789889881881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7\n",
      "total discriminator loss:0.5805332934225175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8\n",
      "total discriminator loss:0.5703157834632441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9\n",
      "total discriminator loss:0.5282789871662232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 10\n",
      "total discriminator loss:0.5312463369799714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:05,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 11\n",
      "total discriminator loss:0.49730150914915033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:06,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 12\n",
      "total discriminator loss:0.45445829907848007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:06,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 13\n",
      "total discriminator loss:0.39019445966044697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:07,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14\n",
      "total discriminator loss:0.41271928418021514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:07,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15\n",
      "total discriminator loss:0.3682390786997698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16\n",
      "total discriminator loss:0.37250702455100526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:08,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17\n",
      "total discriminator loss:0.32443891637038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:09,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 18\n",
      "total discriminator loss:0.3138747709381744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:09,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 19\n",
      "total discriminator loss:0.27675061746049334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:09,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 20\n",
      "total discriminator loss:0.2192536412899822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 21\n",
      "total discriminator loss:0.2460170627621315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:10,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 22\n",
      "total discriminator loss:0.2159178246373006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:11,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.18521321730368095\n",
      "Training Step: 24\n",
      "total discriminator loss:0.1529252078110578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:12,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 25\n",
      "total discriminator loss:0.16463541732986778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [00:12,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 26\n",
      "total discriminator loss:0.09298411488760631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:13,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 27\n",
      "total discriminator loss:0.16263635861386963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [00:13,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 28\n",
      "total discriminator loss:0.07884539138212875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [00:14,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 29\n",
      "total discriminator loss:0.11109962442800901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [00:14,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 30\n",
      "total discriminator loss:0.09452716111499987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [00:15,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 31\n",
      "total discriminator loss:0.033331530965415815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:16,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "OPTIMIZER = Adam(lr=1e-3)\n",
    "# _TOTAL_STEPS = 100\n",
    "\n",
    "for feature_batch, labels in tqdm(pretrain_D_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    step += 1\n",
    "    print('Training Step:', step)\n",
    "\n",
    "    disc_token_loss = pretrain_discriminator(event_type_batch, time_delta_batch, labels, pretrained_discriminator, verbose=True, optimizer=OPTIMIZER)\n",
    "    pretrain_disc_token_loss_history.append(disc_token_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "working-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/pretrained_disc_weights'):\n",
    "    os.makedirs(model_save_dir + '/pretrained_disc_weights')\n",
    "\n",
    "D_save_path = model_save_dir + '/pretrained_disc_weights/model.tf'\n",
    "pretrained_discriminator.save_weights(D_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cultural-travel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      80          event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_token (LSTM)               (256, 128)           74752       tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_time (LSTM)                (256, 128)           74752       tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (256, 256)           0           lstm_token[0][0]                 \n",
      "                                                                 lstm_time[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (256, 256)           0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "final (Dense)                   (256, 1)             257         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 149,841\n",
      "Trainable params: 149,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload_pretrained_disc = build_D(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,    \n",
    "    dropout_rate=0.25)\n",
    "\n",
    "reload_pretrained_disc.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "reload_pretrained_disc.load_weights(D_save_path)\n",
    "reload_pretrained_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-bacon",
   "metadata": {},
   "source": [
    "## Monte-Carlo with Critic  Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "indian-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_mcc(generator, discriminator, critic, batch_size, T, verbose=False,                   \n",
    "                    optimizer=Adam(lr=0.001)):\n",
    "    \n",
    "    # clear critic states for a new batch\n",
    "    critic.reset_states()\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:     \n",
    "                        \n",
    "        gen_step_loss = []\n",
    "        critic_step_loss = []\n",
    "\n",
    "        G_sample_et, G_sample_ts, G_token_logits = generate_sequences_mcc(batch_size, generator, batch_size, T)        \n",
    "        \n",
    "        true_return = discriminator([G_sample_et, G_sample_ts])\n",
    "        \n",
    "        # Monte-Carlo with Critic\n",
    "        for i in range(T):  \n",
    "            curr_state_et = G_sample_et[:, -1:, :]\n",
    "            curr_state_ts = G_sample_ts[:, -1:, :]\n",
    "            curr_token_logits = G_token_logits[:, -1:, :]\n",
    "        \n",
    "            q_value = critic([curr_state_et, curr_state_ts])\n",
    "            advantage = true_return - q_value\n",
    "        \n",
    "            # averge loss over batch at each rollout step: -E[log_prob * Q]\n",
    "            policy_gradient_loss = -tf.reduce_mean(tf.math.log(tf.nn.softmax(curr_token_logits)) * advantage)\n",
    "            gen_step_loss.append(policy_gradient_loss)\n",
    "            \n",
    "            critic_mse_loss = tf.reduce_mean(tf.keras.losses.MSE(true_return, q_value))\n",
    "            critic_step_loss.append(critic_mse_loss)\n",
    "            \n",
    "        generator_loss = tf.reduce_mean(gen_step_loss)\n",
    "        critic_loss = tf.reduce_mean(critic_step_loss)\n",
    "        \n",
    "    if verbose:\n",
    "        print('generator loss:{}'.format(generator_loss))\n",
    "        print('critic loss:{}'.format(critic_loss))\n",
    "        print('-----------------------')\n",
    "\n",
    "    # update generator\n",
    "    generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "    \n",
    "    # update critic\n",
    "    critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "\n",
    "    # explicitly drop tape because persistent=True\n",
    "    del tape\n",
    "\n",
    "    return generator_loss, critic_loss\n",
    "\n",
    "\n",
    "def train_discriminator_mcc(real_data_batch_et, real_data_batch_ts, generator, discriminator, batch_size, T, verbose=False,\n",
    "                        optimizer=Adam(lr=0.001), label_smoothing=False, label_flipping=False):\n",
    "\n",
    "    # data prep\n",
    "    real_labels = tf.ones((batch_size//2, 1))\n",
    "    fake_labels = tf.zeros((batch_size//2, 1))\n",
    "    \n",
    "    real_data_batch_et, real_data_batch_ts = real_data_batch_et[:batch_size//2, :, :], real_data_batch_ts[:batch_size//2, :, :]    \n",
    "    fake_data_batch_et, fake_data_batch_ts = generate_sequences(batch_size//2, generator, batch_size, T)\n",
    "    \n",
    "    if label_smoothing:\n",
    "        fake_labels = fake_labels + tf.random.normal(fake_labels.shape, mean=0, stddev=0.3)\n",
    "        fake_labels = tf.clip_by_value(fake_labels, clip_value_min=0., clip_value_max=0.3)\n",
    "\n",
    "        real_labels = real_labels + tf.random.normal(real_labels.shape, mean=0, stddev=0.3)\n",
    "        real_labels = tf.clip_by_value(real_labels, clip_value_min=0.7, clip_value_max=1.0)\n",
    "\n",
    "    if label_flipping:\n",
    "        if tf.random.uniform((1,)) < 0.05:\n",
    "            fake_labels, real_labels = real_labels, fake_labels\n",
    "    \n",
    "    total_data_et = tf.concat([fake_data_batch_et, real_data_batch_et], axis=0)\n",
    "    total_data_ts = tf.concat([fake_data_batch_ts, real_data_batch_ts], axis=0)\n",
    "    total_labels = tf.concat([fake_labels, real_labels], axis=0)        \n",
    "        \n",
    "    # train the discriminator\n",
    "    with tf.GradientTape() as tape:                                                           \n",
    "        # train discriminator\n",
    "        pred_prob = discriminator([total_data_et, total_data_ts])\n",
    "\n",
    "        # cross-entropy loss\n",
    "        discriminator_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(total_labels, pred_prob, from_logits=False))\n",
    "\n",
    "        # average true return\n",
    "        average_true_return = tf.reduce_mean(pred_prob)\n",
    "        \n",
    "        if verbose:\n",
    "            print('total discriminator loss:{}'.format(discriminator_loss))\n",
    "            print('average true return:{}'.format(average_true_return))\n",
    "            print('-----------------------')\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    return discriminator_loss, average_true_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "alternate-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_training(step, G, save_path=None, verbose=True, plot=True):\n",
    "    _gen_seqs_et, _gen_seqs_ts, _ = generate_sequences_mcc(N_DATA, G, BATCH_SIZE, T)\n",
    "    \n",
    "    # convert one-hot event types to indices; convert normalized timestamps to original\n",
    "    _gen_seqs_et_ind = tf.argmax(_gen_seqs_et, axis=2).numpy().reshape(N_DATA, T, 1)\n",
    "    _gen_seqs_ts_ori = apply_mean_std(_gen_seqs_ts, GLOBAL_MEAN, GLOBAL_STD)\n",
    "    _gen_seqs_for_rules = np.dstack((_gen_seqs_et_ind, _gen_seqs_ts_ori))\n",
    "    \n",
    "    _mad_score = calculate_MAD_score(_gen_seqs_et_ind)\n",
    "    _fid_score = calculate_FID_score(_gen_seqs_ts_ori)\n",
    "    _rule_score = calculate_rule_score(_gen_seqs_for_rules)\n",
    "\n",
    "    if verbose:\n",
    "        print('event_types:', _gen_seqs_et_ind[0,:, :].squeeze().tolist())\n",
    "        print('mad_score:', _mad_score)\n",
    "        print('fid_score:', _fid_score)\n",
    "        print('rule_score:', _rule_score)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        x = np.arange(_gen_seqs_et[0,:,:].shape[0])\n",
    "        y = _gen_seqs_ts[0,:,:]\n",
    "        plt.plot(x, y)\n",
    "        plt.title(f'wave shape after {step} steps')\n",
    "        plt.show()\n",
    "\n",
    "    if save_path:     \n",
    "        G_save_path = os.path.join(save_path, f'G_{step}', 'model_weights.tf')\n",
    "        G.save_weights(G_save_path)\n",
    "        print('G saved to:', G_save_path)\n",
    "\n",
    "        D_save_path = os.path.join(save_path, f'D_{step}', 'model_weights.tf')\n",
    "        D.save_weights(D_save_path)\n",
    "        print('D saved to:', D_save_path)\n",
    "        \n",
    "    return _mad_score, _fid_score, _rule_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "immediate-perry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      80          event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_28 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_token (LSTM)               (256, 128)           74752       tf_op_layer_concat_28[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_time (LSTM)                (256, 128)           74752       tf_op_layer_concat_28[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (256, 256)           0           lstm_token[0][0]                 \n",
      "                                                                 lstm_time[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_combination (Dense)       (256, 128)           32896       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_token (Dense)             (256, 4)             516         dense_combination[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_time (Dense)              (256, 1)             129         dense_combination[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 183,125\n",
      "Trainable params: 183,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      80          event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_29 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_token (LSTM)               (256, 128)           74752       tf_op_layer_concat_29[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_time (LSTM)                (256, 128)           74752       tf_op_layer_concat_29[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (256, 256)           0           lstm_token[0][0]                 \n",
      "                                                                 lstm_time[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (256, 256)           0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "final (Dense)                   (256, 1)             257         dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 149,841\n",
      "Trainable params: 149,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      80          event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_30 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_token (LSTM)               (256, 128)           74752       tf_op_layer_concat_30[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_time (LSTM)                (256, 128)           74752       tf_op_layer_concat_30[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (256, 256)           0           lstm_token[0][0]                 \n",
      "                                                                 lstm_time[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (256, 256)           0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "critic_final (Dense)            (256, 1)             257         dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 149,841\n",
      "Trainable params: 149,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_save_path = model_save_dir + '/pretrained_gen_weights/model.tf'\n",
    "D_save_path = model_save_dir + '/pretrained_disc_weights/model.tf'\n",
    "\n",
    "G = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "G.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "G.load_weights(G_save_path)\n",
    "G.summary()\n",
    "\n",
    "D = build_D(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,    \n",
    "    dropout_rate=0.25)\n",
    "\n",
    "D.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "D.load_weights(D_save_path)\n",
    "D.summary()\n",
    "\n",
    "critic = build_critic(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,    \n",
    "    dropout_rate=0.25)\n",
    "\n",
    "critic.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "twelve-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40\n",
      "1562\n"
     ]
    }
   ],
   "source": [
    "N_total_G = pos_event_type_seqs.shape[0]\n",
    "\n",
    "EPOCHS = 100\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_G / BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_dataset = create_dataset((pos_event_type_seqs, pos_timestamp_seqs),\n",
    "                             np.ones((N_total_G, 1)),\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             epochs=EPOCHS,\n",
    "                             buffer_size=N_total_G)\n",
    "\n",
    "gen_loss_history = []\n",
    "disc_loss_history = []\n",
    "critic_loss_history = []\n",
    "average_true_return_history = []\n",
    "mad_history = []\n",
    "fid_history = []\n",
    "rule_history = []\n",
    "\n",
    "step = 0\n",
    "\n",
    "G_optimizer = Adam(learning_rate=1e-3)\n",
    "D_optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "_G_STEPS = 1\n",
    "_D_STEPS = 1\n",
    "\n",
    "now_str = datetime.strftime(datetime.now(), format='%Y-%m-%d-%H-%M-%S')\n",
    "model_save_path = os.path.join(model_save_dir, now_str)\n",
    "print(model_save_path)\n",
    "print(_TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "tribal-parking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 0\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f0442c810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3f0442c810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "event_types: [1, 0, 2, 0, 3, 2, 3, 3, 0, 2, 2, 1, 2, 0, 1, 2, 3, 0, 2, 2]\n",
      "mad_score: 0.4315125\n",
      "fid_score: 9481.020606434931\n",
      "rule_score: 0.475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/G_0/model_weights.tf\n",
      "D saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/D_0/model_weights.tf\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3ef77e6b90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3ef77e6b90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3ef77ad410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3ef77ad410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "generator loss:-0.7050638772959272\n",
      "critic loss:0.2596851983457747\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:12, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.46529876630464984\n",
      "average true return:0.5452324771155109\n",
      "-----------------------\n",
      "Training Step: 1\n",
      "generator loss:-0.7595786349489344\n",
      "critic loss:0.25084452388530815\n",
      "-----------------------\n",
      "total discriminator loss:1.2176856955314939\n",
      "average true return:0.19484974091241658\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:15,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2\n",
      "generator loss:-0.6805482427681384\n",
      "critic loss:0.18943528174434512\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:19,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.5369816858662858\n",
      "average true return:0.436901378897223\n",
      "-----------------------\n",
      "Training Step: 3\n",
      "generator loss:-0.31344079850409434\n",
      "critic loss:0.08125033005520357\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:22,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.44023194513963393\n",
      "average true return:0.5747128174907181\n",
      "-----------------------\n",
      "Training Step: 4\n",
      "generator loss:0.3560983244369912\n",
      "critic loss:0.12634120854963865\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:25,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6872947877240523\n",
      "average true return:0.7298441618991163\n",
      "-----------------------\n",
      "Training Step: 5\n",
      "event_types: [2, 2, 0, 2, 2, 3, 3, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2]\n",
      "mad_score: 0.31865\n",
      "fid_score: 24538.892743339988\n",
      "rule_score: 0.00075\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/G_5/model_weights.tf\n",
      "D saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/D_5/model_weights.tf\n",
      "generator loss:0.019119570395921964\n",
      "critic loss:0.04779427112481026\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:37,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:2.9832029444390273\n",
      "average true return:0.6121956548198104\n",
      "-----------------------\n",
      "Training Step: 6\n",
      "generator loss:0.23627847999229606\n",
      "critic loss:0.057143449310299486\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:40,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.4969317291273889\n",
      "average true return:0.6841017524595656\n",
      "-----------------------\n",
      "Training Step: 7\n",
      "generator loss:0.25155592492413353\n",
      "critic loss:0.0458741676611691\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:43,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.48121098778421845\n",
      "average true return:0.6703732441337573\n",
      "-----------------------\n",
      "Training Step: 8\n",
      "generator loss:0.07767002259613934\n",
      "critic loss:0.022594713407002115\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:47,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3842220367743528\n",
      "average true return:0.6181045590440412\n",
      "-----------------------\n",
      "Training Step: 9\n",
      "generator loss:-0.1192232418117349\n",
      "critic loss:0.01210638094340945\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:50,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3665435962749114\n",
      "average true return:0.5828290675299651\n",
      "-----------------------\n",
      "Training Step: 10\n",
      "event_types: [1, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1]\n",
      "mad_score: 0.29065\n",
      "fid_score: 110534.2256213154\n",
      "rule_score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/G_10/model_weights.tf\n",
      "D saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/D_10/model_weights.tf\n",
      "generator loss:-0.2401976548086549\n",
      "critic loss:0.01899397171980165\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:02,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3186980765590589\n",
      "average true return:0.5553024936012096\n",
      "-----------------------\n",
      "Training Step: 11\n",
      "generator loss:-0.2874356245538361\n",
      "critic loss:0.022228341272948444\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:05,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.37810274610453143\n",
      "average true return:0.5407579499273759\n",
      "-----------------------\n",
      "Training Step: 12\n",
      "generator loss:-0.3025260495751162\n",
      "critic loss:0.02056509705198052\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:09,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35109272363609023\n",
      "average true return:0.5303742744125031\n",
      "-----------------------\n",
      "Training Step: 13\n",
      "generator loss:-0.3002509704936927\n",
      "critic loss:0.016251474824636992\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [01:12,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3259428939715375\n",
      "average true return:0.5193252725163137\n",
      "-----------------------\n",
      "Training Step: 14\n",
      "generator loss:-0.27584907292150335\n",
      "critic loss:0.011614871860026323\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:15,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:2.407368059733326\n",
      "average true return:0.5080488658937155\n",
      "-----------------------\n",
      "Training Step: 15\n",
      "event_types: [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "mad_score: 0.1260875\n",
      "fid_score: 253726.73643481382\n",
      "rule_score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/G_15/model_weights.tf\n",
      "D saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/D_15/model_weights.tf\n",
      "generator loss:-0.1439720978526736\n",
      "critic loss:0.006268545816825698\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:28,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.31518667382388615\n",
      "average true return:0.5107182621961435\n",
      "-----------------------\n",
      "Training Step: 16\n",
      "generator loss:0.025348682151695993\n",
      "critic loss:0.0052831781406195094\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [01:32,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33145616183255633\n",
      "average true return:0.49647042112595985\n",
      "-----------------------\n",
      "Training Step: 17\n",
      "generator loss:0.15388161081088403\n",
      "critic loss:0.006339670177959458\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [01:35,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32099511926532237\n",
      "average true return:0.48870079765200336\n",
      "-----------------------\n",
      "Training Step: 18\n",
      "generator loss:0.207522021370192\n",
      "critic loss:0.007242644054563356\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [01:39,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33418972338444464\n",
      "average true return:0.48208430253248247\n",
      "-----------------------\n",
      "Training Step: 19\n",
      "generator loss:0.20690103390613773\n",
      "critic loss:0.007667602790203519\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [01:42,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3206630864468787\n",
      "average true return:0.47724864276731077\n",
      "-----------------------\n",
      "Training Step: 20\n",
      "event_types: [2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "mad_score: 0.0974375\n",
      "fid_score: 127815.4111585349\n",
      "rule_score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAo3klEQVR4nO3deZwU9ZnH8c8zPRfHcM4IDAyggCiiIIwYiBhdCR5RiK4abxNjUKOr2Y0xGt2YrJuNiZvNpQaPJJ6JV+KNosYDDSIMhlNuBLkZQGA45n72jypIO/bAQM9M9Ux/369Xv7qOX3c9U93zrepfVXeZuyMiIq1fRtQFiIhI81Dgi4ikCQW+iEiaUOCLiKQJBb6ISJpQ4IuIpAkFvqQ8M3vbzK6Muo79MbNrzGyDme0ws65R1yNSlwJfpBGYWRbwf8BYd28PHG1mqxt5GV8ws9fNbIuZlZrZ02bWI26+mdnPzGxzePuZmdlBLGeFmY1pzNolNSjwRRpHNyAXmN8YT2ZmmQkmdwbuB/oCfYAy4I9x8ycAXwWGAMcAZwFXNUY90joo8NOUmX3DzF6MG19iZk/Hja8ys6Hh8K/D8e1mNtPMRofTC81st5l1iXvcsWa2KdzjxcyuMLMFZvapmU02sz711JNrZo+Fe6ZbzWyGmXWLa9LHzP5uZmVm9pqZ5cc99mkzW29m28xsipkdFTfvITObGO4Zl5nZO/E1mNkRcXvNi8zs/P2sswXh8yw3s6vC6YcDi8JmW83sLeAVoDDs3tkRrqsMM7vZzJaFf+dTe9admfU1Mzezb5rZJ8CbdZfv7q+4+9Puvt3ddwF3A1+Ma3I58At3X+3ua4BfAF+v52/JN7OXwnW9xczeDet7FOgNvBjWfVPY/gtmNjVsP9vMTop7rrfN7KdmNj18jzwf93ft73WV5uTuuqXhDTgM2Eqw0S8EVgKr4+Z9CmSE45cAXYFM4LvAeiA3nPcm8K24570LmBgOjweWAkeGj70NmFpPPVcBLwJtgRgwHOgQznsbWAYcDrQJx++Me+wVQB6QA/wKmBU37yGCPeETw/m/Bt4L57UDVgHfCOs7FtgEDKqnxq8A/QADvgTsAoaF8/oCDmSG4yftWZ9xj78BmAb0Cmu5D/hzncc/EtbVpgGv4XeAaXHj24Dj48aLgbJ6HvtTYCKQFd5GAxbOWwGMiWvbE9gMnBG+X74cjhfEvT5rgMFh7X8BHtvf66pbBP/3URegW4QvfhB2w4ALCLoKpgNHhAH4wj4e9ykwJBy+EngzHLbwOU8Mx18Bvhn3uIwwJPskeM4rgKnAMQnmvQ3cFjf+beDVemrrFAZnx3D8IeCJuPntgRqgCPga8G6dx98H3N7A9fcccEM43JDAXwCcEjfeA6gi2NjsefxhDVz2McAWYHTctBrgiLjxAeFzWoLH/xfwPNA/wby6gf994NE6bSYDl8e9PvEb4EFAZRjw9b6uujX/TV066e0dgmA6MRx+m2DP9UvhOABmdmPYlbHNzLYCHYE9XSp/AUaGBw9PBGqBd8N5fYBfhx/ltxIElBHsMdb1KEGIPGFma83s53u6hULr44Z3EQQ3ZhYzszvDbpLtBGFFXH0QbIQAcPcdYR2FYX3H76kvrPFioHuilWVmp5vZtLALZCvBHm9+orb16AM8G7esBQQhHd/FsSrRA+vU0Z9gY3qDu78bN2sH0CFuvAOww8MUruMugk9fr4XdUzfvp+7z6qynEwg2WInqXknwqSGf/b+u0owU+OltT+CPDoffoU7gh/31NwHnA53dvRNB14EBuPunwGsEe8sXEexN7wmYVcBV7t4p7tbG3afWLcTdq9z9x+4+CBgFnAlc1oC/4SKCrqMxBBuivuH0+LNTivYMmFl7oAuwNqzvnTr1tXf3a+ouxMxyCDZu/wt0C9fDpDrL+cyflGDaKuD0OsvL9aC/fV+Pi6+jD/AGcIe7P1pn9nyCA7Z7DKGeg8juXubu33X3w4BxwH+Y2Sn11LCKYA8/vu527n5nXJuiuOHeBJ9cNiXxukoTUOCnt3eAkwn6i1cT7JmfRtBf/4+wTR5QDZQCmWb2Qz67FwnwJ4J/4nPD4T0mArfsOYhqZh3N7LxEhZjZyWZ2tJnFgO0EgVHbgL8hD6gg6FNuC/xPgjZnmNkJZpYN3EHQ770KeAk43MwuNbOs8HacmR2Z4DmyCfrdS4FqMzsdGLuPujYAXc2sY9y0icBP9hw0NrMCMxvfgL+RsH1PgmMmd7v7xARNHiEI7p5mVkhwvOWhep7rTDPrb2ZGsAGv4Z/rewPBcZw9HgPOMrNTw09UuWZ2kpn1imtziZkNMrO2BN1Fz7h7TRKvqzQBBX4ac/fFBN0A74bj24HlwN/dvSZsNhl4FVhM8FG9nM93O7xA0F+83t1nxz3/s8DPCD7ObwfmAafXU0534BmCUFhAsDGquwebyCNhXWuAjwgOitb1J+B2gq6c4QQHoXH3MoLQvoBgj399WG9O3ScI214PPEVwDOOi8O9OyN0XAn8GlofdIIUEB4xfIOhGKQtrPb4Bf+MeVxIE8Y/izv7ZETf/PoIDpHMJ1vXL4bREBhB8UtgBvA/c6+5vhfN+CtwW1n1juHEcD/yAYIO3Cvgen82PRwk2LusJTk+9Ppx+sK+rNIE9R+VFWiUze4jg4OltUdfSWpnZ2wRn5TwYdS2yb9rDFxFJEwp8EZE0oS4dEZE0oT18EZE0kegHmlJGfn6+9+3bN+oyRERajJkzZ25y94JE81I68Pv27UtJSUnUZYiItBhmtrK+eerSERFJEwp8EZE0ocAXEUkTCnwRkTShwBcRSRMKfBGRNKHAFxFJE60u8Murarh/yjKmLt0UdSkiIiml1QV+ViyDB979mEfer/e7ByIiaanVBX4sw/jK0T14c9FGysqroi5HRCRltLrABxg3tJDK6lpem78h6lJERFJGqwz8Y4s60atzG16YvTbqUkREUkarDHwz46whhby3dBObd1REXY6ISEpolYEPMG5IITW1zqR566MuRUQkJbTawD+iex4DDmnPi7PUrSMiAq048M2McUMKmb5iC2u37o66HBGRyLXawAc4a0ghAC/N0V6+iEirDvy++e0Y0qujztYREaGVBz4Ee/nz1mxneemOqEsREYlUqw/8M48pxAxenL0u6lJERCLV6gO/e8dcRvTtwguz1+DuUZcjIhKZVh/4EPzUwrLSnXy0bnvUpYiIRCapwDez88xsvpnVmlnxPtqdZmaLzGypmd2czDIPxhmDe5CZYTp4KyJpLdk9/HnAOcCU+hqYWQy4BzgdGARcaGaDklzuAencLpvRA/J5afY6amvVrSMi6SmpwHf3Be6+aD/NRgBL3X25u1cCTwDjk1nuwRg3tJA1W3fz4SefNveiRURSQnP04fcEVsWNrw6nJWRmE8ysxMxKSktLG62ILw/qTk5mhrp1RCRt7TfwzewNM5uX4NYke+nufr+7F7t7cUFBQaM9b/ucTMYc2Y1Jc9dRXVPbaM8rItJSZO6vgbuPSXIZa4CiuPFe4bRmd9aQQl6eu473l29m9IDG25iIiLQEzdGlMwMYYGaHmlk2cAHwQjMs93NOGlhAXk4mL+gXNEUkDSV7WubZZrYaGAm8bGaTw+mFZjYJwN2rgeuAycAC4Cl3n59c2QcnNyvG2KO68+r89VRU10RRgohIZJI9S+dZd+/l7jnu3s3dTw2nr3X3M+LaTXL3w929n7v/JNmikzFuaCFl5dW8vajxDgiLiLQEafFN23hf7NeVru2ydbaOiKSdtAv8zFgGZxzdg78t2MDOiuqoyxERaTZpF/gQdOuUV9Xy+kcboi5FRKTZpGXgD+/dmcKOuerWEZG0kpaBn5FhnDWkkCmLS/l0Z2XU5YiINIu0DHwIvoRVXeu8On991KWIiDSLtA38owo7cFh+O30JS0TSRtoGvlnQrTPt481s2F4edTkiIk0ubQMfgrN13OGlObrerYi0fmkd+P0K2nNUYQedrSMiaSGtAx9g3JBCZq/aysrNO6MuRUSkSaV94J85pBCAF7WXLyKtXNoHfs9ObTiub2d164hIq5f2gQ/BOfmLN+xg4frtUZciItJkFPjAGUf3IJZh6tYRkVZNgQ/kt89hVL+uvDh7He4edTkiIk1CgR8aN6SQT7bsYtaqrVGXIiLSJBT4oVMHdyc7M0MHb0Wk1VLghzrkZnHywAJemrOOmlp164hI66PAjzNuSE9Kyyr4YPnmqEsREWl0Cvw4pxx5CO2yY+rWEZFWSYEfJzcrxtijuvPKvPVUVtdGXY6ISKNS4Ndx1pAebNtdxZTFpVGXIiLSqBT4dYweUEDXdtk8/P6KqEsREWlUCvw6smIZXPWlw3h3ySam6eCtiLQiSQW+mZ1nZvPNrNbMivfRboWZzTWzWWZWkswym8NlI/vSrUMOd01epG/eikirkewe/jzgHGBKA9qe7O5D3b3eDUOqyM2Kcf0pA5i58lPeXLgx6nJERBpFUoHv7gvcfVFjFZNKzi8uok/Xttw1eRG1+iKWiLQCzdWH78BrZjbTzCbsq6GZTTCzEjMrKS2N7kyZrFgG//Hlw1m4vowX5+i8fBFp+fYb+Gb2hpnNS3AbfwDLOcHdhwGnA9ea2Yn1NXT3+9292N2LCwoKDmARje+sYwo5onsev3x9MVU1Oi9fRFq2/Qa+u49x98EJbs83dCHuvia83wg8C4w4+JKbT0aGcePYgazYvIunS1ZHXY6ISFKavEvHzNqZWd6eYWAswcHeFuGUIw9hWO9O/OZvSyivqom6HBGRg5bsaZlnm9lqYCTwsplNDqcXmtmksFk34D0zmw1MB15291eTWW5zMjO+d+oRrN9ezqPvr4y6HBGRg5aZzIPd/VmCLpq609cCZ4TDy4EhySwnaiP7dWX0gHzufXspF4woIi83K+qSREQOmL5p20DfO3Ugn+6q4sF3P466FBGRg6LAb6BjenXi9MHdefDd5WzZWRl1OSIiB0yBfwC+O/ZwdlfVcO9bS6MuRUTkgCnwD0D/Q/I4Z1gvHpm2knXbdkddjojIAVHgH6DvjBmAu/Obvy2JuhQRkQOiwD9AvTq35eLj+/BUyWqWl+6IuhwRkQZT4B+Ea0/uT3Ysg1++ob18EWk5FPgHoSAvhytO6MuLs9cyf+22qMsREWkQBf5BmnBiPzrkZvKL1xZHXYqISIMo8A9SxzZZXH1SP95cuJGSFVuiLkdEZL8U+En4xqhDKcjL4eev6lKIIpL6FPhJaJMd4/p/6c/0FVt4Z3F0F2sREWkIBX6SvnZcb4q6tNGlEEUk5Snwk5SdmcG/jzmc+Wu388q89VGXIyJSLwV+Ixg/tCeHd2vPL15fRLUuhSgiKUqB3whiGcZ3xw5keelO/vrhmqjLERFJSIHfSMYO6saQok786o3FVFTrUogiknoU+I3EzLjp1IGs3VbO49M+ibocEZHPUeA3oi/2z2dUv67c89ZSdlRUR12OiMhnKPAb2fdOHcjmnZXc/aYukiIiqUWB38iO7d2ZrxUXMfGdZbw6b13U5YiI7KXAbwI/Hn8UQ4s68R9PzWbh+u1RlyMiAijwm0RuVoz7Lx1OXm4mVz5coouei0hKUOA3kUM65HLfpcVsLKvg2sc/pEpfyBKRiCUV+GZ2l5ktNLM5ZvasmXWqp91pZrbIzJaa2c3JLLMlGVrUiTvPOZr3l2/mJy8viLocEUlzye7hvw4MdvdjgMXALXUbmFkMuAc4HRgEXGhmg5JcbotxzrBefGv0oTw0dQVPztD5+SISnaQC391fc/c9J5xPA3olaDYCWOruy929EngCGJ/Mclua7592BKMH5HPbc/N0sRQRiUxj9uFfAbySYHpPYFXc+OpwWtrIjGVw94XD6NmpDVc/9iFrt+6OuiQRSUP7DXwze8PM5iW4jY9rcytQDTyebEFmNsHMSsyspLS09VxUpGPbLB68vJjyqhquenQm5VX6vR0RaV77DXx3H+PugxPcngcws68DZwIXe+Lr/K0BiuLGe4XT6lve/e5e7O7FBQUFB/THpLr+h+Txq68NZd7abXz/L3N0WUQRaVbJnqVzGnATMM7dd9XTbAYwwMwONbNs4ALghWSW25KNGdSNG8cO5PlZa7lvyvKoyxGRNJJsH/7dQB7wupnNMrOJAGZWaGaTAMKDutcBk4EFwFPuPj/J5bZo3z6pH2ce04OfvbqQtxZujLocEUkTlsrdCsXFxV5SUhJ1GU1id2UN506cyidbdvHctV+kX0H7qEsSkVbAzGa6e3GiefqmbUTaZMe4/7JismMZfOvhErbtroq6JBFp5RT4EerZqQ2/u2Q4n2zZxQ1P/IOa2tT9tCUiLZ8CP2IjDu3Cj8cfxduLSvn55IVRlyMirVhm1AUIXHx8Hxas28597yxnUI8OjB+aVt9LE5Fmoj38FHH7WUcx4tAu3PTMHOas3hp1OSLSCinwU0RWLIPfXTyM/PY5XPXoTDaWlUddkoi0Mgr8FNK1fQ4PXFbM1l1VfPuxD6ms1m/oi0jjUeCnmEGFHfj5ucdQsvJT/vvlj6IuR0RaER20TUFnDSlk3ppt3DdlOYN7duT84qL9P0hEZD+0h5+ivnfqQL7Yvyu3PTeP2au2Rl2OiLQCCvwUlRnL4LcXDqOgfQ5XPzaTTTsqoi5JRFo4BX4K69Ium/suHc6WnZW6ELqIJE2Bn+IG9+zInf96NB98vIWfTtI3cUXk4OmgbQtw9rG9mLN6G3/4+8cc3asDZx+b6NLBIiL7pj38FuIHZxzJ8Yd24ea/zGXemm1RlyMiLZACv4XIimVwz8XD6NIum6sencmWnZVRlyQiLYwCvwXJb5/DxEuGU7qjgn/784dU6yCuiBwABX4LM6SoE//91cH8felm7pq8KOpyRKQF0UHbFuj84iLmrv7nN3HPGlIYdUki0gJoD7+F+s8zB1HcpzM3PTOHheu3R12OiLQACvwWKjszg3svGUZebiYTHpnJ1l06iCsi+6bAb8EOycvld5cMZ9223dzwxCxdE1dE9kmB38IN79OZH48bzDuLS/nl64ujLkdEUpgCvxW46PjeXDiiiLvfWsqr89ZFXY6IpCgFfivxo3FHMbSoE999ajZLNpRFXY6IpKCkAt/M7jKzhWY2x8yeNbNO9bRbYWZzzWyWmZUks0xJLCczxsRLhtMmO5MJj85ke3lV1CWJSIpJdg//dWCwux8DLAZu2Ufbk919qLsXJ7lMqUf3jrnce/EwVm3ZxXV/+od+TllEPiOpwHf319y9OhydBuhnHCM24tAu/OTswUxZXMr3n5mDu87cEZFAY/bhXwG8Us88B14zs5lmNmFfT2JmE8ysxMxKSktLG7G89PG143rz3S8fzl//sYafvaqfXxCRwH5/WsHM3gC6J5h1q7s/H7a5FagGHq/naU5w9zVmdgjwupktdPcpiRq6+/3A/QDFxcXaPT1I1/1LfzaUlTPxnWUckpfDFSccGnVJIhKx/Qa+u4/Z13wz+zpwJnCK19N/4O5rwvuNZvYsMAJIGPjSOMyMH48bzKaySu54+SMK8nL0mzsiaS7Zs3ROA24Cxrn7rnratDOzvD3DwFhgXjLLlYaJZRi/umAox/Xpwnefms3UpZuiLklEIpRsH/7dQB5BN80sM5sIYGaFZjYpbNMNeM/MZgPTgZfd/dUklysNlJsV44HLiumb35YJj85k/lpdLUskXVkqn8VRXFzsJSU6bb8xrNu2m3PunUp1rfPXa0ZR1KVt1CWJSBMws5n1nf6ub9qmiR4d2/DIFSOorK7l8j9M1yUSRdKQAj+NDOiWx+8vL2bN1t1c8dAMdlVW7/9BItJqKPDTTHHfLvzmwmOZs3or1z7+ob6NK5JGFPhp6NSjunPHVwfz1qJSfvDXufo2rkia0DVt09TFx/dh4/YKfv23JXTrkMuNpw6MuiQRaWIK/DT2nTED2FhWwd1vLeWQDjlcNrJv1CWJSBNS4KcxM+OO8UexaUcFt78wn/z2OZxxdI+oyxKRJqI+/DSXGcvgtxcey7DenfnOE7OYtnxz1CWJSBNR4Au5WTF+f3kxvbu25VuPlLBw/faoSxKRJqDAFwA6tc3m4StG0C47k8v/MJ3Vnyb8aSQRacEU+LJXz05tePiKEeyqrOHCB6bxyWaFvkhrosCXzxjYPY/HrzyesvJqzrtvqi6ILtKKKPDlc47p1YknJ4yk1uH8+95n7mr9wqZIa6DAl4QGds/j6atG0jY7k4semMb0j7dEXZKIJEmBL/Xqm9+OZ64ZSUGHHC77wwe8s1jXGBZpyRT4sk89OrbhqatGclh+e658eAavzF0XdUkicpAU+LJf+e1z+POEL3BMr05c+6cPeWbm6qhLEpGDoMCXBunYJotHvzmCUf3yufHp2Tw8dUXUJYnIAVLgS4O1zc7kwcuL+fKgbtz+wnzueWtp1CWJyAFQ4MsByc2Kce/Fwzj72J7cNXkRd76yUL+nL9JC6Ncy5YBlxTL4xXlDaJcTY+I7yygrr+KO8YPJyLCoSxORfVDgy0HJyDDuGD+Y9jlZTHxnGbsqa7jr3GPIjOlDo0iqUuDLQTMzbj79CPJyM7lr8iJ2VlTz24uOJSczFnVpIpKAdsckadee3J8fjzuK1z7awDcfKmFXZXXUJYlIAgp8aRSXj+rL/543hKnLNnHp76ezbXdV1CWJSB1JB76Z3WFmc8xslpm9ZmaF9bS73MyWhLfLk12upJ5zh/finouGMWf1Vs793VRWbNoZdUkiEqcx9vDvcvdj3H0o8BLww7oNzKwLcDtwPDACuN3MOjfCsiXFnH50Dx6+YgSbdlQw7u739Ps7Iikk6cB39/jr4bUDEp2UfSrwurtvcfdPgdeB05JdtqSmUf3yeeG6Eyjs1IZv/HE6909ZpnP1RVJAo/Thm9lPzGwVcDEJ9vCBnsCquPHV4bREzzXBzErMrKS0VHuHLVVRl7b85ZpRnDa4O/8zaSH//uQsyqtqoi5LJK01KPDN7A0zm5fgNh7A3W919yLgceC6ZApy9/vdvdjdiwsKCpJ5KolYu5xM7rloGDeOPZznZ6/lvInvs3br7qjLEklbDQp8dx/j7oMT3J6v0/Rx4F8TPMUaoChuvFc4TVo5M+O6fxnAA5cW8/GmnYy7+z1mrNDFVESi0Bhn6QyIGx0PLEzQbDIw1sw6hwdrx4bTJE2MGdSN564dRV5uFhc9MI0/ffBJ1CWJpJ3G6MO/M+zemUMQ5DcAmFmxmT0I4O5bgDuAGeHtv8Jpkkb6H5LHc9d+kVH98vnBs3O59dm5VFbXRl2WSNqwVD57ori42EtKSqIuQxpZTa3z88kLue+d5Yzo24V7LxlGfvucqMsSaRXMbKa7Fyeap2/aSrOLZRi3nH4kv75gKLNXb2Xcb99j3pptUZcl0uop8CUy44f25C/XjALgX383ledn6Ti+SFNS4EukBvfsyAv/dgJDenXihidm8dNJC6ipTd1uRpGWTIEvkctvn8NjVx7PJV/ozX1TlnPFQzPYtks/vibS2BT4khKyMzP4768ezf+cfTRTl23i9F9P4d0l+qa1SGNS4EtKuej43jx11UjaZMe49PfTueWvcykr196+SGNQ4EvKObZ3Z16+fjRXnXgYT874hNN+9S7vLdkUdVkiLZ4CX1JSblaMW844kqevHkVOVgaX/P4DbvnrXHZU6GpaIgdLgS8pbXifzky6fjQTTjyMJ2Z8wqm/nKK9fZGDpMCXlJebFeMHZxzJM1ePIicz2Nu/9Vnt7YscKAW+tBjD+3Rm0g2j+dboQ/nT9GBvf+pS7e2LNJQCX1qU3KwYt35lEM9cPZKczAwuevADbntuLju1ty+yXwp8aZGG9+nCpBtGc+UJh/L4B59w6q+0ty+yPwp8abFys2LcduYgnr5qJFmxYG//P5+bp719kXoo8KXFK+7bhUnXj+abJxzKYx+s5LRfT+HtRRt14XSROhT40iq0yY7xn2cO4qmrRpKZkcHX/ziDC+6fRokupyiylwJfWpXj+nbh1e+M5sfjjmJZ6U7Onfg+3/jjdP3evgi64pW0Yrsqq3l46komvrOMbbur+MrRPfj3Lx9O/0PaR12aSJPZ1xWvFPjS6m0vr+LBKcv5/Xsfs7uqhnOG9eKGUwZQ1KVt1KWJNDoFvgiweUcFv3t7GY9MW4m7c+GI3lx3cn8O6ZAbdWkijUaBLxJn/bZyfvvmEp6csYrMmHH5qL5cfWI/OrfLjro0kaQp8EUSWLl5J796YwnPzVpD++xMrhx9GN8cfSjtczKjLk3koCnwRfZh0foy/u/1RUyev4Eu7bK55kv9uHRkH3KzYlGXJnLAFPgiDTB71Vb+97VFvLtkEx3bZPHVoYWcf1wRRxV2jLo0kQZT4IscgOkfb+GxaSt5df56KqtrGdyzA+cXFzF+SE86ts2KujyRfWqywDezO4DxQC2wEfi6u69N0K4GmBuOfuLu4xry/Ap8idLWXZU8P2stT85YxUfrtpOdmcHpg7tzfnERIw/rSkaGRV2iyOc0ZeB3cPft4fD1wCB3vzpBux3ufsDfdlHgS6qYt2YbT5Ws4rl/rGF7eTVFXdpw3vAizh3ei8JObaIuT2SvZunSMbNbgN7ufk2CeQp8aRXKq2qYPH89T5Ws4u9LN2MGowcU8LXiIsYMOoScTB3olWg1aeCb2U+Ay4BtwMnuXpqgTTUwC6gG7nT35/bxfBOACQC9e/cevnLlyqTqE2kqq7bs4umZq3mmZBVrt5XTuW0WXz22J+cXF3Fkjw5RlydpKqnAN7M3gO4JZt3q7s/HtbsFyHX32xM8R093X2NmhwFvAqe4+7L9Fa49fGkJamqd95Zu4qmSVbw+fwOVNbUc3q09owcUcMKAfI4/tAtts3VuvzSP5urS6Q1McvfB+2n3EPCSuz+zv+dU4EtLs2VnJc/PWsPfFmxk+ootVFbXkh3LYFifTsEGoH8+g3t2JKYDvtJEmvKg7QB3XxIO/xvwJXc/t06bzsAud68ws3zgfWC8u3+0v+dX4EtLVl5Vw4wVW3hvySamLNnEgnXbAejUNotR/bpyQv8CRg/I14+4SaPaV+An+znzTjMbSHBa5krg6nCBxcDV7n4lcCRwn5nVEvz+/p0NCXuRli43K8boAQWMHlDALUBpWQVTl23i3SWbeG/JJibNXQ9A365tOWFAPif0L2Bkv650bKNz/aVp6ItXIhFwd5aV7tgb/tOWb2ZnZQ0ZBkOKOjGibxeO6JHHEd070K+gPdmZulaRNIy+aSuS4iqra5m1aivvLSllypJNfLR2O5U1tQBkZhj9Ctrv3QAc0T2PI3rk0b1DLmY6FiCfpcAXaWGqampZsWknC9aXsXDddhatL2Ph+jLWbN29t03HNlkM7J7Hkd3zOKJHBwZ2z2Ngtzza6dc+01pT9uGLSBPIimUwoFseA7rlMW5I4d7p23ZXsXhDsBFYsL6MRevLeGbmanZW1uxt06drWw7Lb0f3jrl079CGHh1zg+HwlpeTqU8GKai21tlZWc2Oimoqqmrpm9+u0ZehwBdpQTq2yeK4vl04rm+XvdNqa501W3ezMPw0sHB9GSu37GTumm1s2lH5uedolx375wYgfoPQIbjv0TGXzm2z9VtBDeDuVFTXsrOiml2VNeysrGZnRQ27KqspK69mR3k1ZRXVlJVXsaM8CPOycNqO8qqgTUXQbkdlNXs6XArycphx65hGr1eBL9LCZWQYRV3aUtSlLV8e1O0z8yqqa9i4vYL128tZt62cDduC+/Xbd7NuWzlTl21iY1kFNbWf7do1g/bZmeTlZtI+N5O83Cza5wTDHXIzaZ+TaFpW2DaTNlkxMmNGZkZGeB8OZ1iTb0jcneraIIgrqmqC++paKqprqKj6/HD53jbhfVUtu6tq2F1Zzc7KILx3VtSwOwz0XZU1ewN+V2U1tQ3sFW+bHdu7vvLC9XdIXu7edZaX88913amJztRS4Iu0YjmZsb0bg/rU1DqbdlQEG4JtwYbg052VbI/b+yyrqGLrrkpWbdkV7p1Ws7uqpt7n3JcMg8xYRrgRsM8PxwwDaj2ordad2lqnxp2a2iDQg+Fgeq1DTVybxjgsmRUz2mZn0i47Rtuc8D47k+4dcj8z3jY7RtucGO3C4XY5mbTJDsbz9gZ5Fu1yYmTGoj/TSoEvkuZiGUa3Drl065ALRZ0a/LiqmqAro6y8em/XRFl5FTsqqtldWUN1rVNdUxvcxw/X1BmvraWm1qmq+ec09+CTS8yC+wwzYmbhcFBzhll4v6dtMG5mZGUYuVkxcrIyyMnMICczFtxnxQ1nJp6fHctIiXBuCgp8ETkoWbEMOrXNplNbXfy9pWidmzEREfkcBb6ISJpQ4IuIpAkFvohImlDgi4ikCQW+iEiaUOCLiKQJBb6ISJpI6Z9HNrNSgitpHYx8YFMjltPYVF9yVF9yVF9yUrm+Pu5ekGhGSgd+MsyspL7fhE4Fqi85qi85qi85qV5ffdSlIyKSJhT4IiJpojUH/v1RF7Afqi85qi85qi85qV5fQq22D19ERD6rNe/hi4hIHAW+iEiaaPGBb2anmdkiM1tqZjcnmJ9jZk+G8z8ws77NWFuRmb1lZh+Z2XwzuyFBm5PMbJuZzQpvP2yu+sLlrzCzueGySxLMNzP7Tbj+5pjZsGasbWDcepllZtvN7Dt12jTr+jOzP5jZRjObFzeti5m9bmZLwvvO9Tz28rDNEjO7vBnru8vMFoav37Nm1qmex+7zvdCE9f3IzNbEvYZn1PPYff6vN2F9T8bVtsLMZtXz2CZff0lz9xZ7A2LAMuAwIBuYDQyq0+bbwMRw+ALgyWasrwcwLBzOAxYnqO8k4KUI1+EKIH8f888AXgEM+ALwQYSv9XqCL5VEtv6AE4FhwLy4aT8Hbg6HbwZ+luBxXYDl4X3ncLhzM9U3FsgMh3+WqL6GvBeasL4fATc24PXf5/96U9VXZ/4vgB9Gtf6SvbX0PfwRwFJ3X+7ulcATwPg6bcYDD4fDzwCnmJk1R3Huvs7dPwyHy4AFQM/mWHYjGg884oFpQCcz6xFBHacAy9z9YL953SjcfQqwpc7k+PfYw8BXEzz0VOB1d9/i7p8CrwOnNUd97v6au1eHo9OAXo293IaqZ/01REP+15O2r/rC3Dgf+HNjL7e5tPTA7wmsihtfzecDdW+b8E2/DejaLNXFCbuSjgU+SDB7pJnNNrNXzOyo5q0MB14zs5lmNiHB/Ias4+ZwAfX/o0W5/gC6ufu6cHg90C1Bm1RZj1cQfGJLZH/vhaZ0Xdjl9Id6usRSYf2NBja4+5J65ke5/hqkpQd+i2Bm7YG/AN9x9+11Zn9I0E0xBPgt8Fwzl3eCuw8DTgeuNbMTm3n5+2Vm2cA44OkEs6Nef5/hwWf7lDzX2cxuBaqBx+tpEtV74XdAP2AosI6g2yQVXci+9+5T/n+ppQf+GqAobrxXOC1hGzPLBDoCm5ulumCZWQRh/7i7/7XufHff7u47wuFJQJaZ5TdXfe6+JrzfCDxL8NE5XkPWcVM7HfjQ3TfUnRH1+gtt2NPNFd5vTNAm0vVoZl8HzgQuDjdKn9OA90KTcPcN7l7j7rXAA/UsN+r1lwmcAzxZX5uo1t+BaOmBPwMYYGaHhnuBFwAv1GnzArDnjIhzgTfre8M3trDP7/fAAnf/v3radN9zTMHMRhC8Js2yQTKzdmaWt2eY4ODevDrNXgAuC8/W+QKwLa77ornUu2cV5fqLE/8euxx4PkGbycBYM+scdlmMDac1OTM7DbgJGOfuu+pp05D3QlPVF39M6Ox6ltuQ//WmNAZY6O6rE82Mcv0dkKiPGid7IziLZDHBEfxbw2n/RfDmBsgl6ApYCkwHDmvG2k4g+Hg/B5gV3s4ArgauDttcB8wnOOtgGjCqGes7LFzu7LCGPesvvj4D7gnX71yguJlf33YEAd4xblpk649gw7MOqCLoR/4mwTGhvwFLgDeALmHbYuDBuMdeEb4PlwLfaMb6lhL0f+95D+45a60QmLSv90Iz1fdo+N6aQxDiPerWF45/7n+9OeoLpz+05z0X17bZ11+yN/20gohImmjpXToiItJACnwRkTShwBcRSRMKfBGRNKHAFxFJEwp8EZE0ocAXEUkT/w/1GRgo7RIEhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/G_20/model_weights.tf\n",
      "D saved to: /home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-mcc-v11/2021-03-30-10-26-40/D_20/model_weights.tf\n",
      "generator loss:0.16928992012499852\n",
      "critic loss:0.007729484941959003\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [01:55,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32226539541710253\n",
      "average true return:0.47385667726912284\n",
      "-----------------------\n",
      "Training Step: 21\n",
      "generator loss:0.13302902663890037\n",
      "critic loss:0.007943159562627262\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:57,  5.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-15c701f4a518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# train the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_G_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator_mcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mgen_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcritic_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-719fbef2d716>\u001b[0m in \u001b[0;36mtrain_generator_mcc\u001b[0;34m(generator, discriminator, critic, batch_size, T, verbose, optimizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# update generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mgenerator_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5604\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5605\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5606\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5607\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5608\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature_batch, _ in tqdm(train_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    print('Training Step:', step)\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        _mad_score, _fid_score, _rule_score = track_training(step, G, model_save_path, verbose=True, plot=True)\n",
    "        mad_history.append(_mad_score)\n",
    "        fid_history.append(_fid_score)\n",
    "        rule_history.append(_rule_score)\n",
    "        \n",
    "    # train the generator\n",
    "    for _ in range(_G_STEPS):\n",
    "        gen_loss, critic_loss = train_generator_mcc(G, D, critic, BATCH_SIZE, T, verbose=True, optimizer=G_optimizer)\n",
    "        gen_loss_history.append(gen_loss.numpy())\n",
    "        critic_loss_history.append(critic_loss.numpy())\n",
    "    \n",
    "    # train the discriminator\n",
    "    for _ in range(_D_STEPS):\n",
    "        disc_loss, ave_true_return = train_discriminator_mcc(event_type_batch, time_delta_batch, G, D, BATCH_SIZE, T,\n",
    "                                                                verbose=True, optimizer=D_optimizer, \n",
    "                                                                label_smoothing=True, label_flipping=True)\n",
    "        disc_loss_history.append(disc_loss.numpy())\n",
    "        average_true_return_history.append(ave_true_return.numpy())\n",
    "                \n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(gen_loss_history))\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, gen_loss_history)\n",
    "plt.title('Generator Loss History')\n",
    "plt.xlabel('Training steps')\n",
    "\n",
    "x = range(len(disc_loss_history))\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, disc_loss_history)\n",
    "plt.title('Discriminator Loss History')\n",
    "plt.xlabel('Training steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-fossil",
   "metadata": {},
   "source": [
    "## Compare between G0, G1 and G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "seqs_random_et, seqs_random_ts = generate_sequences_gumbel(10, G0, BATCH_SIZE, T)\n",
    "print(tf.argmax(seqs_random_et, axis=2))\n",
    "\n",
    "ind = 1\n",
    "x = np.arange(seqs_random_ts[ind,:,:].shape[0])\n",
    "y = seqs_random_ts[ind,:,:]\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = pretrained_generator\n",
    "seqs_pretrained_et, seqs_pretrained_ts = generate_sequences_gumbel(10, G1, BATCH_SIZE, T)\n",
    "print(tf.argmax(seqs_pretrained_et, axis=2))\n",
    "\n",
    "ind = 1\n",
    "x = np.arange(seqs_pretrained_ts[ind,:,:].shape[0])\n",
    "y = seqs_pretrained_ts[ind,:,:]\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = G\n",
    "seqs_trained_et, seqs_trained_ts = generate_sequences_gumbel(10, G2, BATCH_SIZE, T)\n",
    "\n",
    "print(tf.argmax(seqs_trained_et, axis=2))\n",
    "\n",
    "ind = 3\n",
    "x = np.arange(seqs_trained_ts[ind,:,:].shape[0])\n",
    "y = seqs_trained_ts[ind,:,:]\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seqs_trained_et_100, raw_seqs_trained_ts_100 = generate_sequences_gumbel(400, G2, BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.argmax(raw_seqs_trained_et_100, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mean_std(raw_seqs_trained_ts_100, *get_mean_std(raw_pos_timestamp_seqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-cuisine",
   "metadata": {},
   "source": [
    "## Save trained G and D weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/G_run_syn_v11_200'):\n",
    "    os.makedirs(model_save_dir + '/G_run_syn_v11_200')\n",
    "\n",
    "G_save_path = model_save_dir + '/G_run_syn_v11_200/model.tf'\n",
    "                \n",
    "if not os.path.exists(model_save_dir + '/D_run_syn_v11_200'):\n",
    "    os.makedirs(model_save_dir + '/D_run_syn_v11_200')\n",
    "\n",
    "D_save_path = model_save_dir + '/D_run_syn_v11_200/model.tf'\n",
    "\n",
    "G.save_weights(G_save_path)\n",
    "D.save_weights(D_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-uncle",
   "metadata": {},
   "source": [
    "## Generate Synthesized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_save_path = '/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-gs-v11/G_run_syn_v11_200/model.tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_200 = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "G_200.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "G.load_weights(G_save_path)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_100 = G2\n",
    "raw_seqs_trained_et_100, raw_seqs_trained_ts_100 = generate_sequences_gumbel(400000, G_100, BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_save_et_100 = tf.argmax(raw_seqs_trained_et_100[:400000, :, :], axis=2)\n",
    "seqs_save_ts_100 = apply_mean_std(raw_seqs_trained_ts_100[:400000, :, :], *get_mean_std(raw_pos_timestamp_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pos_seqs_filename_et = 'syn_positive_type_sequences.pickle'\n",
    "pos_seqs_filename_ts = 'syn_positive_time_sequences.pickle'\n",
    "\n",
    "repo_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/\"\n",
    "\n",
    "with open(os.path.join(repo_path, 'syn_data', 'gumbel_softmax_100it', pos_seqs_filename_et), 'wb') as f:\n",
    "    pickle.dump(seqs_save_et_100, f)\n",
    "    \n",
    "with open(os.path.join(repo_path, 'syn_data', 'gumbel_softmax_100it', pos_seqs_filename_ts), 'wb') as f:\n",
    "    pickle.dump(seqs_save_ts_100, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_save_et_100[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_save_ts_100[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
