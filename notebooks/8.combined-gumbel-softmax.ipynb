{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "starting-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/\"\n",
    "data_path = \"/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/data/long_seqs_v10/\"\n",
    "model_save_dir = '/home/lun/project-basileus/multitype-sequence-generation-by-tlstm-gan/models/combined-gs'\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funny-swaziland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blessed-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "T = 20 + 1\n",
    "VOCAB = ['END/PADDING', 'INIT', 'start', 'view', 'click', 'install']\n",
    "EVENT_VOCAB_DIM = len(VOCAB)\n",
    "EMB_DIM = 16\n",
    "HIDDEN_DIM = 16\n",
    "\n",
    "END_TOKEN = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-object",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data_path = os.path.join(data_path, 'positive_long_sequences.pickle')\n",
    "# neg_data_path = os.path.join(data_path, 'negative_long_sequences.pickle')\n",
    "\n",
    "def load_sequence_from_pickle_to_numpy(pickle_file_path):\n",
    "    \"\"\"\n",
    "        A list of sequence in format of (event_type, time_delta)\n",
    "    :param pickle_file_path: e.g. /.../project-basileus/seq-gan/data/fixed_length/valid_sequences.pickle\n",
    "    :return: (event_type_seqs, time_delta)\n",
    "    \"\"\"\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "        raw_seqs = pickle.load(f)\n",
    "\n",
    "    if not raw_seqs or not raw_seqs[0]:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    N = len(raw_seqs)\n",
    "    T = len(raw_seqs[0])\n",
    "    \n",
    "    seqs = np.array(raw_seqs)\n",
    "#     print(seqs.shape)\n",
    "    \n",
    "    et_seqs = seqs[:, :, 0].astype(np.float64).reshape((N, T, 1))\n",
    "    ts_seqs = seqs[:, :, 1].astype(np.float64).reshape((N, T, 1))\n",
    "    return et_seqs, ts_seqs\n",
    "    \n",
    "pos_event_type_seqs, pos_timestamp_seqs = load_sequence_from_pickle_to_numpy(pos_data_path)\n",
    "# neg_event_type_seqs, neg_timestamp_seqs = load_sequence_from_pickle_to_numpy(neg_data_path)\n",
    "\n",
    "# cast indicator data into one-hot\n",
    "pos_event_type_seqs = tf.cast(pos_event_type_seqs, tf.int32)\n",
    "pos_event_type_seqs = tf.one_hot(pos_event_type_seqs, depth=EVENT_VOCAB_DIM, axis=2, dtype=tf.float64)\n",
    "pos_event_type_seqs = tf.squeeze(pos_event_type_seqs, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(features: np.array, labels: np.array, batch_size=2, epochs=10, buffer_size=10000):\n",
    "    \"\"\"\n",
    "    Create dataset from numpy arrays\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-organic",
   "metadata": {},
   "source": [
    "## Create multitype SeqGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "linear-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Reshape, Dense, Dropout, Activation, Multiply, Add, Lambda\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sgtlstm.TimeLSTM import TimeLSTM0, TimeLSTM1, TimeLSTM2, TimeLSTM3\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "def build_G(batch_size, event_vocab_dim, emb_dim, hidden_dim=16):\n",
    "    # inputs of Time-LSTM:\n",
    "    i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "    i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "    i_noise = Input(batch_shape=(batch_size, hidden_dim), name='hidden_noise')\n",
    "\n",
    "    embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "    merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "    hm, tm = TimeLSTM1(hidden_dim,\n",
    "                       name='time_lstm',\n",
    "                       stateful=True, \n",
    "                       return_sequences=False,\n",
    "                       kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                       recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                       bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)    \n",
    "    \n",
    "    hm_with_noise = tf.concat([hm, i_noise], axis=1)\n",
    "    tm_with_noise = tf.concat([tm, i_noise], axis=1)\n",
    "    \n",
    "    token_logits = Dense(event_vocab_dim,\n",
    "                   activation='linear',\n",
    "                   name='dense_token',\n",
    "                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                   bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(hm_with_noise)\n",
    "        \n",
    "    time_delta_out = Dense(1,\n",
    "                   activation='softplus', # linear\n",
    "                   name='dense_time',\n",
    "                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                   bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(tm_with_noise)\n",
    "    \n",
    "    generator = Model(\n",
    "        inputs=[i_et, i_ts, i_noise],\n",
    "        outputs=[token_logits, time_delta_out])\n",
    "        \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "worthy-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_D(batch_size, T, event_vocab_dim, emb_dim, hidden_dim, dropout_rate=0.25):\n",
    "    # normal LSTM\n",
    "    i_et = Input(batch_shape=(batch_size, None, event_vocab_dim), name='event_type')  # input of discrete feature event type\n",
    "    i_ts = Input(batch_shape=(batch_size, None, 1), name='time_delta_in')  # input of continuous feature timestamp\n",
    "    \n",
    "    embed0 = Dense(emb_dim, name='dense_emb')(i_et) # dense matrix size: 6*16\n",
    "    merged0 = tf.concat([embed0, i_ts], axis=2)\n",
    "    \n",
    "    hm, tm = TimeLSTM1(hidden_dim,\n",
    "                       name='time_lstm',\n",
    "                       stateful=True, \n",
    "                       return_sequences=False,\n",
    "                       kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                       recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                       bias_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))(merged0)\n",
    "    \n",
    "    token_time_comb = tf.keras.layers.concatenate([hm, tm], axis=1)\n",
    "    \n",
    "    dropped = Dropout(rate=dropout_rate)(token_time_comb)\n",
    "    \n",
    "    prob = Dense(1, \n",
    "             activation='sigmoid',\n",
    "             name='final',\n",
    "             kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None),\n",
    "             bias_initializer=tf.keras.initializers.Constant(value=0.1))(dropped)\n",
    "        \n",
    "    discriminator = Model(\n",
    "        inputs=[i_et, i_ts],\n",
    "        outputs=prob)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-peninsula",
   "metadata": {},
   "source": [
    "## test initial G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "absent-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "constant-savings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f3319337c90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "grave-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_index = tf.ones([BATCH_SIZE, 1, 1], dtype=tf.int32)\n",
    "init_token_prefix = tf.squeeze(tf.one_hot(init_token_index, EVENT_VOCAB_DIM, axis=2, dtype=tf.float64), axis=3)\n",
    "init_time_delta = tf.zeros([BATCH_SIZE, 1, 1], dtype=tf.float64)\n",
    "\n",
    "noise=tf.random.normal(shape=[BATCH_SIZE, HIDDEN_DIM], mean=0.0, stddev=0.1, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "foreign-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_logits, time_delta_out = G0([init_token_prefix, init_time_delta, noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "respected-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "D0 = build_D(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim = HIDDEN_DIM,\n",
    "    dropout_rate=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "static-flush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1), dtype=float64, numpy=\n",
       "array([[0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846],\n",
       "       [0.5358846]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = D0([init_token_prefix, init_time_delta])\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-looking",
   "metadata": {},
   "source": [
    "## Define rollout and sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "infrared-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    U = tf.random.uniform(shape,minval=0,maxval=1)   #gumbel noise\n",
    "#     print('noise:{}'.format(U))\n",
    "    return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature=0.5): \n",
    "    y = logits + tf.cast(sample_gumbel(tf.shape(logits)), logits.dtype)\n",
    "    return tf.nn.softmax( y / temperature)  # use softmax to approximate argmax\n",
    "\n",
    "def gumbel_softmax(logits, temperature=0.5, hard=True):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    logits = tf.cast(logits, tf.float64)\n",
    "    y = gumbel_softmax_sample(logits, temperature) # this is differentiable\n",
    "    if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keepdims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "crude-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_from_prefix_gumbel(\n",
    "        G, batch_size, prefix_et, prefix_ts, L=T):\n",
    "    # Begin from dummy init state (init_token=1, init_timestamp=0.0)\n",
    "    all_state_et = prefix_et\n",
    "    all_state_ts = prefix_ts\n",
    "    \n",
    "    l_prefix = prefix_et.shape[1]\n",
    "    \n",
    "    G.reset_states()\n",
    "\n",
    "    for _ in range(L-l_prefix):  # sequence length\n",
    "        curr_state_et = all_state_et[:, -1:, :]\n",
    "        curr_state_ts = all_state_ts[:, -1:, :]\n",
    "        step_noise = tf.random.normal(shape=[batch_size, HIDDEN_DIM], mean=0.0, stddev=0.1, dtype=tf.float64)\n",
    "        \n",
    "        token_logits, time_delta_out = G([curr_state_et, curr_state_ts, step_noise])\n",
    "        \n",
    "        # sample event types using Gumbel-softmax\n",
    "        sampled_et = gumbel_softmax(token_logits)  # this is differentiable\n",
    "        sampled_et = tf.reshape(sampled_et, [batch_size, 1, EVENT_VOCAB_DIM])        \n",
    "        sampled_et = tf.cast(sampled_et, dtype=tf.float64) # cast sampled_et into float\n",
    "        \n",
    "        time_delta_out = tf.reshape(time_delta_out, [batch_size, 1, 1]) \n",
    "        \n",
    "        # Do NOT stop genererating once hit end_token; G is supposed to learn it.\n",
    "        all_state_et = tf.concat([all_state_et, sampled_et], axis=1)\n",
    "        all_state_ts = tf.concat([all_state_ts, time_delta_out], axis=1)\n",
    "\n",
    "    return all_state_et, all_state_ts\n",
    "\n",
    "\n",
    "def generate_sequences_gumbel(N_gen, generator, batch_size, T):\n",
    "    \"\"\"\n",
    "        Generate sequences batch per batch\n",
    "    :param N_gen: total number of seqs to be generated\n",
    "    :param generator:\n",
    "    :param batch_size:\n",
    "    :param T:\n",
    "    :return: a python list of shape [N_gen, T, 1]\n",
    "    \"\"\"\n",
    "    N = 0\n",
    "    all_type_seq = None\n",
    "    all_time_seq = None\n",
    "    \n",
    "    init_token_index = tf.ones([batch_size, 1, 1], dtype=tf.int32)\n",
    "    init_token_prefix = tf.squeeze(tf.one_hot(init_token_index, EVENT_VOCAB_DIM, axis=2, dtype=tf.float64), axis=3)\n",
    "    init_time_delta = tf.zeros([batch_size, 1, 1], dtype=tf.float64)\n",
    "        \n",
    "    while N < N_gen:\n",
    "        batch_state_et, batch_state_ts = rollout_from_prefix_gumbel(generator, batch_size, init_token_prefix, init_time_delta, T)\n",
    "\n",
    "        if all_type_seq is None or all_time_seq is None:\n",
    "            all_type_seq = batch_state_et\n",
    "            all_time_seq = batch_state_ts\n",
    "        else:\n",
    "            all_type_seq = tf.concat([all_type_seq, batch_state_et], axis=0)\n",
    "            all_time_seq = tf.concat([all_time_seq, batch_state_ts], axis=0)\n",
    "\n",
    "        N += batch_size\n",
    "\n",
    "    all_type_seq = all_type_seq[:N_gen, :, :]\n",
    "    all_time_seq = all_time_seq[:N_gen, :, :]\n",
    "\n",
    "    return all_type_seq, all_time_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-singles",
   "metadata": {},
   "source": [
    "## Pre-Training of Gumbel-Softmax SeqGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dense-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_discriminator(event_type_batch, time_delta_batch, label_batch, discriminator, verbose=False, optimizer=Adam(lr=0.001)):\n",
    "    # train the discriminator\n",
    "    with tf.GradientTape() as tape:\n",
    "        # train discriminator\n",
    "        true_prob = discriminator([event_type_batch, time_delta_batch])\n",
    "\n",
    "        # cross-entropy loss\n",
    "        discriminator_loss = ce_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(label_batch, true_prob, from_logits=False)\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print('total discriminator loss:{}'.format(discriminator_loss))\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    return discriminator_loss\n",
    "\n",
    "\n",
    "def pretrain_generator(event_type_batch, time_delta_batch, generator, verbose=False, optimizer=Adam(lr=0.001)):\n",
    "    _, T, _ = event_type_batch.shape\n",
    "    \n",
    "    # train the generator\n",
    "    with tf.GradientTape() as tape:\n",
    "        generator.reset_states()\n",
    "        step_token_ce_loss_list = []\n",
    "        step_time_mse_loss_list = []\n",
    "\n",
    "        for i in range(0, T - 1):\n",
    "            curr_state_et = event_type_batch[:, i:i + 1, :]\n",
    "            curr_state_ts = time_delta_batch[:, i:i + 1, :]\n",
    "            \n",
    "            target_et = event_type_batch[:, i + 1, :]\n",
    "            target_ts = time_delta_batch[:, i + 1, :]\n",
    "            \n",
    "            step_noise = tf.random.normal(shape=[BATCH_SIZE, HIDDEN_DIM], mean=0.0, stddev=0.1, dtype=tf.float64)\n",
    "            \n",
    "            token_logits, time_delta_out = generator([curr_state_et, curr_state_ts, step_noise])\n",
    "\n",
    "            token_ce_losses = tf.keras.losses.categorical_crossentropy(target_et, token_logits, from_logits=True)\n",
    "            token_ce_loss = tf.reduce_mean(token_ce_losses)\n",
    "            step_token_ce_loss_list.append(token_ce_loss)\n",
    "            \n",
    "            time_mse_losses = tf.keras.losses.MSE(target_ts, time_delta_out)\n",
    "            time_mse_loss = tf.reduce_mean(time_mse_losses)\n",
    "            step_time_mse_loss_list.append(time_mse_loss)                        \n",
    "    \n",
    "        episode_token_ce_loss = tf.reduce_mean(step_token_ce_loss_list)\n",
    "        episode_time_mse_loss = tf.reduce_mean(step_time_mse_loss_list)\n",
    "        generator_loss = episode_token_ce_loss + episode_time_mse_loss\n",
    "\n",
    "    if verbose:\n",
    "        print('token ce loss:{}'.format(episode_token_ce_loss))\n",
    "        print('time mse loss:{}'.format(episode_time_mse_loss))\n",
    "        print('train loss:{}'.format(generator_loss))\n",
    "\n",
    "    # apply gradient decent per batch\n",
    "    grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "    return generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-worker",
   "metadata": {},
   "source": [
    "### pre-train G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "attached-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_G = pos_event_type_seqs.shape[0]\n",
    "\n",
    "EPOCHS = 1\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_G / BATCH_SIZE)\n",
    "\n",
    "pretrain_G_dataset = create_dataset((pos_event_type_seqs, pos_timestamp_seqs),\n",
    "                                  np.ones((N_total_G, 1)),\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  buffer_size=N_total_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "mobile-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_gen_loss_history = []\n",
    "\n",
    "pretrained_generator = build_G(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "charitable-woman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7477264099131051\n",
      "time mse loss:466.1688719547541\n",
      "train loss:467.9165983646672\n",
      "Training Step: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7447334212749372\n",
      "time mse loss:475.7460601347634\n",
      "train loss:477.49079355603834\n",
      "Training Step: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7440211466244064\n",
      "time mse loss:478.708232322622\n",
      "train loss:480.4522534692464\n",
      "Training Step: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7423646803409572\n",
      "time mse loss:469.12018516428935\n",
      "train loss:470.86254984463034\n",
      "Training Step: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7413894686487494\n",
      "time mse loss:465.74901800465767\n",
      "train loss:467.49040747330645\n",
      "Training Step: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7415569204769235\n",
      "time mse loss:470.2252113414288\n",
      "train loss:471.9667682619057\n",
      "Training Step: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7374521035600066\n",
      "time mse loss:479.82538652439536\n",
      "train loss:481.5628386279554\n",
      "Training Step: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7363607500050815\n",
      "time mse loss:465.09744982251357\n",
      "train loss:466.83381057251864\n",
      "Training Step: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:04,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7355218975573075\n",
      "time mse loss:471.6618865434019\n",
      "train loss:473.3974084409592\n",
      "Training Step: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:04,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7355473111980655\n",
      "time mse loss:474.70825122975003\n",
      "train loss:476.4437985409481\n",
      "Training Step: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:05,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7318679061814783\n",
      "time mse loss:470.1271692278776\n",
      "train loss:471.85903713405907\n",
      "Training Step: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:05,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7301992830759165\n",
      "time mse loss:461.04754888436855\n",
      "train loss:462.7777481674445\n",
      "Training Step: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:06,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7276615799268562\n",
      "time mse loss:471.863371489588\n",
      "train loss:473.5910330695149\n",
      "Training Step: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:06,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7259960014556248\n",
      "time mse loss:478.28784373409843\n",
      "train loss:480.01383973555403\n",
      "Training Step: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:06,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7246113995814176\n",
      "time mse loss:465.38239529552357\n",
      "train loss:467.107006695105\n",
      "Training Step: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:07,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7253295228136385\n",
      "time mse loss:470.2655132411609\n",
      "train loss:471.9908427639745\n",
      "Training Step: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:07,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7220604756123\n",
      "time mse loss:484.3557470715352\n",
      "train loss:486.0778075471475\n",
      "Training Step: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:08,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7181671975951527\n",
      "time mse loss:476.03032041653523\n",
      "train loss:477.7484876141304\n",
      "Training Step: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:08,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7166935066486055\n",
      "time mse loss:461.7089071761855\n",
      "train loss:463.4256006828341\n",
      "Training Step: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:09,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7184521574997766\n",
      "time mse loss:468.30913478893154\n",
      "train loss:470.0275869464313\n",
      "Training Step: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:09,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.717112673637623\n",
      "time mse loss:478.6529672187222\n",
      "train loss:480.37007989235985\n",
      "Training Step: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:09,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7151550504304474\n",
      "time mse loss:466.3826128087876\n",
      "train loss:468.09776785921804\n",
      "Training Step: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:10,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.712567036401141\n",
      "time mse loss:477.3529602782286\n",
      "train loss:479.0655273146297\n",
      "Training Step: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:10,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7103526813451517\n",
      "time mse loss:466.21164786465533\n",
      "train loss:467.9220005460005\n",
      "Training Step: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [00:11,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7075644999730628\n",
      "time mse loss:463.82957641125495\n",
      "train loss:465.537140911228\n",
      "Training Step: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7060218423944888\n",
      "time mse loss:470.8985417879353\n",
      "train loss:472.6045636303298\n",
      "Training Step: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [00:12,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7048945763475278\n",
      "time mse loss:470.4638106708593\n",
      "train loss:472.16870524720684\n",
      "Training Step: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [00:12,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6998489165052486\n",
      "time mse loss:469.696438359376\n",
      "train loss:471.3962872758812\n",
      "Training Step: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [00:12,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.703127062581651\n",
      "time mse loss:478.0023602763516\n",
      "train loss:479.70548733893327\n",
      "Training Step: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [00:13,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.7007536510548\n",
      "time mse loss:481.2901248390819\n",
      "train loss:482.9908784901367\n",
      "Training Step: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [00:13,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6964185467428075\n",
      "time mse loss:478.65230658148573\n",
      "train loss:480.3487251282285\n",
      "Training Step: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6915880231818783\n",
      "time mse loss:469.30873808913185\n",
      "train loss:471.0003261123137\n",
      "Training Step: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [00:14,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6886741522544302\n",
      "time mse loss:459.6403169153993\n",
      "train loss:461.3289910676537\n",
      "Training Step: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [00:15,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6885864793063028\n",
      "time mse loss:470.4420316684711\n",
      "train loss:472.1306181477774\n",
      "Training Step: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [00:15,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.682347964547639\n",
      "time mse loss:462.31609352474425\n",
      "train loss:463.9984414892919\n",
      "Training Step: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [00:16,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6803805267945848\n",
      "time mse loss:465.9872490498133\n",
      "train loss:467.66762957660785\n",
      "Training Step: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [00:16,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6781592852316394\n",
      "time mse loss:469.29922697663113\n",
      "train loss:470.97738626186276\n",
      "Training Step: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [00:16,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6709992851297497\n",
      "time mse loss:465.4081051602135\n",
      "train loss:467.07910444534326\n",
      "Training Step: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [00:17,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6723902683073852\n",
      "time mse loss:463.83180544734694\n",
      "train loss:465.5041957156543\n",
      "Training Step: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [00:17,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6691743025695611\n",
      "time mse loss:469.60519559454616\n",
      "train loss:471.2743698971157\n",
      "Training Step: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [00:18,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6604613258382082\n",
      "time mse loss:455.4728008038478\n",
      "train loss:457.133262129686\n",
      "Training Step: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [00:18,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.658767281331525\n",
      "time mse loss:460.50353641476534\n",
      "train loss:462.16230369609684\n",
      "Training Step: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [00:19,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6559681019948762\n",
      "time mse loss:476.402335078276\n",
      "train loss:478.05830318027085\n",
      "Training Step: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.650003930882923\n",
      "time mse loss:462.85446684369026\n",
      "train loss:464.5044707745732\n",
      "Training Step: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [00:19,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6437440465392334\n",
      "time mse loss:462.2363651311418\n",
      "train loss:463.880109177681\n",
      "Training Step: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [00:20,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6389588655373024\n",
      "time mse loss:454.8758084108511\n",
      "train loss:456.5147672763884\n",
      "Training Step: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [00:20,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.630833508516762\n",
      "time mse loss:459.65340064407854\n",
      "train loss:461.28423415259533\n",
      "Training Step: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [00:21,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.623591086758082\n",
      "time mse loss:460.32600307628474\n",
      "train loss:461.94959416304283\n",
      "Training Step: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [00:21,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.6198197419258022\n",
      "time mse loss:463.45961352820234\n",
      "train loss:465.07943327012816\n",
      "Training Step: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "50it [00:22,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.614769481015918\n",
      "time mse loss:470.08075242548637\n",
      "train loss:471.6955219065023\n",
      "Training Step: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [00:22,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.605449385230378\n",
      "time mse loss:450.71018627299964\n",
      "train loss:452.31563565823\n",
      "Training Step: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52it [00:23,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.601565614296281\n",
      "time mse loss:461.9229437544501\n",
      "train loss:463.5245093687464\n",
      "Training Step: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [00:23,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5948444932619221\n",
      "time mse loss:460.9836404914007\n",
      "train loss:462.5784849846626\n",
      "Training Step: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [00:23,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5860088666793029\n",
      "time mse loss:460.110518973321\n",
      "train loss:461.69652784000033\n",
      "Training Step: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [00:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5864113046871509\n",
      "time mse loss:454.39745899295514\n",
      "train loss:455.9838702976423\n",
      "Training Step: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [00:24,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5749167827158097\n",
      "time mse loss:466.2197793625147\n",
      "train loss:467.79469614523055\n",
      "Training Step: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [00:25,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.569422330299861\n",
      "time mse loss:458.01342376504016\n",
      "train loss:459.58284609534\n",
      "Training Step: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [00:25,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.558364638975135\n",
      "time mse loss:461.87020282004033\n",
      "train loss:463.4285674590155\n",
      "Training Step: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [00:26,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.553828971751536\n",
      "time mse loss:446.9554639047278\n",
      "train loss:448.5092928764794\n",
      "Training Step: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [00:26,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5481632406951404\n",
      "time mse loss:461.1054203492992\n",
      "train loss:462.65358358999435\n",
      "Training Step: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [00:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.542916105270907\n",
      "time mse loss:448.9650577215547\n",
      "train loss:450.5079738268256\n",
      "Training Step: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [00:27,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5356132659145005\n",
      "time mse loss:445.7319693610751\n",
      "train loss:447.26758262698957\n",
      "Training Step: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [00:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5292223889635452\n",
      "time mse loss:449.51557386738205\n",
      "train loss:451.0447962563456\n",
      "Training Step: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [00:28,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5248340062704049\n",
      "time mse loss:452.0900178289727\n",
      "train loss:453.6148518352431\n",
      "Training Step: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [00:28,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5220531067226901\n",
      "time mse loss:448.5865334285492\n",
      "train loss:450.1085865352719\n",
      "Training Step: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [00:29,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5164951887520273\n",
      "time mse loss:456.09272600719015\n",
      "train loss:457.60922119594215\n",
      "Training Step: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [00:29,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5089731020853219\n",
      "time mse loss:458.2817363750696\n",
      "train loss:459.79070947715496\n",
      "Training Step: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [00:30,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.5063596938549124\n",
      "time mse loss:445.63033270785735\n",
      "train loss:447.13669240171225\n",
      "Training Step: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [00:30,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.500683894265515\n",
      "time mse loss:445.9024238977587\n",
      "train loss:447.40310779202423\n",
      "Training Step: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [00:31,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.496754475801163\n",
      "time mse loss:444.02344591748005\n",
      "train loss:445.5202003932812\n",
      "Training Step: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [00:31,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4878402831451256\n",
      "time mse loss:450.09138176205636\n",
      "train loss:451.5792220452015\n",
      "Training Step: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "72it [00:31,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4937734113620853\n",
      "time mse loss:461.152132404403\n",
      "train loss:462.6459058157651\n",
      "Training Step: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "73it [00:32,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.483498767125574\n",
      "time mse loss:453.0581966118718\n",
      "train loss:454.54169537899736\n",
      "Training Step: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "74it [00:32,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4809192517151841\n",
      "time mse loss:445.1702414285037\n",
      "train loss:446.6511606802189\n",
      "Training Step: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "75it [00:33,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4747393975495429\n",
      "time mse loss:458.97137056728735\n",
      "train loss:460.4461099648369\n",
      "Training Step: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "76it [00:33,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4733317070916958\n",
      "time mse loss:442.82248165648815\n",
      "train loss:444.29581336357984\n",
      "Training Step: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "77it [00:34,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4714202881989162\n",
      "time mse loss:450.2613852716264\n",
      "train loss:451.73280555982535\n",
      "Training Step: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "78it [00:34,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4656098683920522\n",
      "time mse loss:445.60038073457633\n",
      "train loss:447.0659906029684\n",
      "Training Step: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "79it [00:34,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.462569752946511\n",
      "time mse loss:452.9306292666861\n",
      "train loss:454.3931990196326\n",
      "Training Step: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "80it [00:35,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4586027615571822\n",
      "time mse loss:442.74628554927256\n",
      "train loss:444.20488831082974\n",
      "Training Step: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "81it [00:35,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4578338142937795\n",
      "time mse loss:446.30167916188964\n",
      "train loss:447.75951297618343\n",
      "Training Step: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "82it [00:36,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.453632913746866\n",
      "time mse loss:444.4203796938142\n",
      "train loss:445.87401260756104\n",
      "Training Step: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "83it [00:36,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4477930881567436\n",
      "time mse loss:442.99404905063966\n",
      "train loss:444.4418421387964\n",
      "Training Step: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "84it [00:37,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4422493247476127\n",
      "time mse loss:440.32275933620656\n",
      "train loss:441.76500866095415\n",
      "Training Step: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "85it [00:37,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4484491516927358\n",
      "time mse loss:440.78824064277615\n",
      "train loss:442.2366897944689\n",
      "Training Step: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "86it [00:38,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4411747727465685\n",
      "time mse loss:440.3754059823024\n",
      "train loss:441.816580755049\n",
      "Training Step: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "87it [00:38,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.439179261768932\n",
      "time mse loss:434.2002271483551\n",
      "train loss:435.639406410124\n",
      "Training Step: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "88it [00:38,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4332774896642122\n",
      "time mse loss:436.73251251150293\n",
      "train loss:438.1657900011671\n",
      "Training Step: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "89it [00:39,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.430549204072798\n",
      "time mse loss:438.3067634287528\n",
      "train loss:439.7373126328256\n",
      "Training Step: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "90it [00:39,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.431646794131033\n",
      "time mse loss:435.96707207339796\n",
      "train loss:437.398718867529\n",
      "Training Step: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "91it [00:40,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4282445956076535\n",
      "time mse loss:432.8378269140465\n",
      "train loss:434.2660715096542\n",
      "Training Step: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "92it [00:40,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.426547337850355\n",
      "time mse loss:431.8485641879124\n",
      "train loss:433.2751115257628\n",
      "Training Step: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "93it [00:41,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.429603598017703\n",
      "time mse loss:436.55957828500084\n",
      "train loss:437.98918188301855\n",
      "Training Step: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "94it [00:41,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4170313099285239\n",
      "time mse loss:442.5675501966869\n",
      "train loss:443.9845815066154\n",
      "Training Step: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "95it [00:42,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4161761514807802\n",
      "time mse loss:432.63646778850745\n",
      "train loss:434.05264393998823\n",
      "Training Step: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "96it [00:42,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4128381600169473\n",
      "time mse loss:424.08897609217127\n",
      "train loss:425.50181425218824\n",
      "Training Step: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "97it [00:42,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4116010374349257\n",
      "time mse loss:430.9735770589643\n",
      "train loss:432.3851780963992\n",
      "Training Step: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "98it [00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.4097565740981781\n",
      "time mse loss:434.7743638963795\n",
      "train loss:436.1841204704777\n",
      "Training Step: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "99it [00:43,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.407318657693662\n",
      "time mse loss:436.4522239956729\n",
      "train loss:437.8595426533666\n",
      "Training Step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100it [00:44,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ce loss:1.404188631165133\n",
      "time mse loss:428.7517344026031\n",
      "train loss:430.15592303376826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:44,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "OPTIMIZER = Adam(lr=1e-3)\n",
    "_TOTAL_STEPS = 100\n",
    "\n",
    "for feature_batch, _ in tqdm(pretrain_G_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    step += 1\n",
    "    print('Training Step:', step)\n",
    "        \n",
    "    gen_loss =  pretrain_generator(event_type_batch, time_delta_batch, pretrained_generator, verbose=True, optimizer=OPTIMIZER)                    \n",
    "    pretrain_gen_loss_history.append(gen_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "driven-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/pretrained_gen_weights'):\n",
    "    os.makedirs(model_save_dir + '/pretrained_gen_weights')\n",
    "\n",
    "G_save_path = model_save_dir + '/pretrained_gen_weights/model.tf'\n",
    "pretrained_generator.save_weights(G_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "configured-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      112         event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_63 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_lstm (TimeLSTM1)           [(256, 16), (256, 16 2464        tf_op_layer_concat_63[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_noise (InputLayer)       [(256, 16)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_64 (TensorFl [(256, 32)]          0           time_lstm[0][0]                  \n",
      "                                                                 hidden_noise[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_65 (TensorFl [(256, 32)]          0           time_lstm[0][1]                  \n",
      "                                                                 hidden_noise[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_token (Dense)             (256, 6)             198         tf_op_layer_concat_64[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_time (Dense)              (256, 1)             33          tf_op_layer_concat_65[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,807\n",
      "Trainable params: 2,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload_pretrained_gen = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "reload_pretrained_gen.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "reload_pretrained_gen.load_weights(G_save_path)\n",
    "reload_pretrained_gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-container",
   "metadata": {},
   "source": [
    "### pre-train D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "shaped-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fake_D = N_real_D = N_total_G // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "discrete-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data by G to pre-train D\n",
    "fake_pos_event_type_seqs, fake_pos_timestamp_seqs = generate_sequences_gumbel(N_fake_D, pretrained_generator, BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "korean-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake data by G to pre-train D\n",
    "real_pos_event_type_seqs = pos_event_type_seqs[0:N_real_D, :, :]\n",
    "real_pos_timestamp_seqs = pos_timestamp_seqs[0:N_real_D, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "outstanding-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_D = N_fake_D + N_real_D\n",
    "\n",
    "pretrain_D_et = tf.concat([fake_pos_event_type_seqs, real_pos_event_type_seqs], axis=0)\n",
    "pretrain_D_ts = tf.concat([fake_pos_timestamp_seqs, real_pos_timestamp_seqs], axis=0)\n",
    "pretrain_D_labels = tf.concat([np.zeros((N_fake_D, 1)), np.ones((N_real_D, 1))], axis=0)\n",
    "\n",
    "EPOCHS = 1\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_D / BATCH_SIZE)\n",
    "\n",
    "pretrain_D_dataset = create_dataset((pretrain_D_et, pretrain_D_ts),\n",
    "                                    pretrain_D_labels,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    buffer_size=N_total_D) # shuffle the entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "direct-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_disc_token_loss_history = []\n",
    "\n",
    "pretrained_discriminator = build_D(batch_size=BATCH_SIZE,\n",
    "                                   T=T,\n",
    "                                   event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "                                   emb_dim=EMB_DIM,\n",
    "                                   hidden_dim=HIDDEN_DIM,    \n",
    "                                   dropout_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "external-extent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1\n",
      "total discriminator loss:0.6890776943826158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2\n",
      "total discriminator loss:0.692735757166364\n",
      "Training Step: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6815093749014393\n",
      "Training Step: 4\n",
      "total discriminator loss:0.6843269043307428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5\n",
      "total discriminator loss:0.683640533724807\n",
      "Training Step: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:01,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6895141045190103\n",
      "Training Step: 7\n",
      "total discriminator loss:0.6825861045769128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:01,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8\n",
      "total discriminator loss:0.6803490802912955\n",
      "Training Step: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:01,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6841603150966515\n",
      "Training Step: 10\n",
      "total discriminator loss:0.6847384781117478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:02,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6823723610428156\n",
      "Training Step: 12\n",
      "total discriminator loss:0.6783211534844649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:02,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 13\n",
      "total discriminator loss:0.6771725383816039\n",
      "Training Step: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:03,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6743567108047106\n",
      "Training Step: 15\n",
      "total discriminator loss:0.6787685007789926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:03,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16\n",
      "total discriminator loss:0.6754372975344873\n",
      "Training Step: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:03,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6729704614282511\n",
      "Training Step: 18\n",
      "total discriminator loss:0.673159350507511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:03,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 19\n",
      "total discriminator loss:0.6712844905227691\n",
      "Training Step: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:04,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6678859938030823\n",
      "Training Step: 21\n",
      "total discriminator loss:0.667199627265458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:04,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 22\n",
      "total discriminator loss:0.6648399523472504\n",
      "Training Step: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.663045575226092\n",
      "Training Step: 24\n",
      "total discriminator loss:0.6628346695100629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:05,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 25\n",
      "total discriminator loss:0.6591226927236333\n",
      "Training Step: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:05,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6565285126847547\n",
      "Training Step: 27\n",
      "total discriminator loss:0.6546593097878901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:05,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 28\n",
      "total discriminator loss:0.6514904768134191\n",
      "Training Step: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [00:05,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6490997965289107\n",
      "Training Step: 30\n",
      "total discriminator loss:0.6465601180824737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:06,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 31\n",
      "total discriminator loss:0.6428905038448458\n",
      "Training Step: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [00:06,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6411634666356558\n",
      "Training Step: 33\n",
      "total discriminator loss:0.6350259259616466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:06,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 34\n",
      "total discriminator loss:0.6304604722644863\n",
      "Training Step: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [00:06,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6266906529902585\n",
      "Training Step: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [00:07,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6209705985868744\n",
      "Training Step: 37\n",
      "total discriminator loss:0.6179276318535332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:07,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 38\n",
      "total discriminator loss:0.6128626081453947\n",
      "Training Step: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [00:07,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.6090893780514827\n",
      "Training Step: 40\n",
      "total discriminator loss:0.6006954676964209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:08,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 41\n",
      "total discriminator loss:0.5965479046334099\n",
      "Training Step: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [00:08,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.59047802513449\n",
      "Training Step: 43\n",
      "total discriminator loss:0.5826315334272567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:08,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 44\n",
      "total discriminator loss:0.5753131326688982\n",
      "Training Step: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [00:09,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.5671296044175147\n",
      "Training Step: 46\n",
      "total discriminator loss:0.5522968203507632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:09,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 47\n",
      "total discriminator loss:0.5436842827402679\n",
      "Training Step: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [00:09,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.5433201687631157\n",
      "Training Step: 49\n",
      "total discriminator loss:0.5277861594470765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:09,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 50\n",
      "total discriminator loss:0.5221563066212274\n",
      "Training Step: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [00:10,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.5088051106797862\n",
      "Training Step: 52\n",
      "total discriminator loss:0.49993171404498593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:10,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 53\n",
      "total discriminator loss:0.4936560170863519\n",
      "Training Step: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [00:10,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.49012307970344104\n",
      "Training Step: 55\n",
      "total discriminator loss:0.4844646716978618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:11,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 56\n",
      "total discriminator loss:0.4806448714033758\n",
      "Training Step: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [00:11,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.4777729045096385\n",
      "Training Step: 58\n",
      "total discriminator loss:0.46255037372364705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:11,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59\n",
      "total discriminator loss:0.46125555284792347\n",
      "Training Step: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [00:11,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.45222843828910253\n",
      "Training Step: 61\n",
      "total discriminator loss:0.4500224809273781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [00:12,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [00:12,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.4361164290715174\n",
      "Training Step: 63\n",
      "total discriminator loss:0.4232212263029853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:12,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 64\n",
      "total discriminator loss:0.4284048556006298\n",
      "Training Step: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [00:12,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.4143117205455134\n",
      "Training Step: 66\n",
      "total discriminator loss:0.4009724683644499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:13,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 67\n",
      "total discriminator loss:0.3937774826035713\n",
      "Training Step: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [00:13,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3858597248497665\n",
      "Training Step: 69\n",
      "total discriminator loss:0.3863191845416716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:13,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 70\n",
      "total discriminator loss:0.38768824071063546\n",
      "Training Step: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [00:14,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.38839192628159913\n",
      "Training Step: 72\n",
      "total discriminator loss:0.3886259740594674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:14,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 73\n",
      "total discriminator loss:0.3800717269512947\n",
      "Training Step: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "74it [00:14,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.39109252550990503\n",
      "Training Step: 75\n",
      "total discriminator loss:0.3895262528223322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:15,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 76\n",
      "total discriminator loss:0.36908583620718344\n",
      "Training Step: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "77it [00:15,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.37845722333308984\n",
      "Training Step: 78\n",
      "total discriminator loss:0.38709763596123714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:15,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 79\n",
      "total discriminator loss:0.4047044962858436\n",
      "Training Step: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "80it [00:15,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.4101236149100775\n",
      "Training Step: 81\n",
      "total discriminator loss:0.41644230169754715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:16,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 82\n",
      "total discriminator loss:0.3771385526991453\n",
      "Training Step: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "83it [00:16,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3841131298500494\n",
      "Training Step: 84\n",
      "total discriminator loss:0.3692121987406884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:16,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 85\n",
      "total discriminator loss:0.36153186020959194\n",
      "Training Step: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "86it [00:16,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36796956134622\n",
      "Training Step: 87\n",
      "total discriminator loss:0.374627741639752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:17,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 88\n",
      "total discriminator loss:0.36597908047351513\n",
      "Training Step: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "89it [00:17,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3578137240481725\n",
      "Training Step: 90\n",
      "total discriminator loss:0.36025751691845315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:18,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 91\n",
      "total discriminator loss:0.3379778392296903\n",
      "Training Step: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "92it [00:18,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33453108487055205\n",
      "Training Step: 93\n",
      "total discriminator loss:0.3154650633112791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:18,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 94\n",
      "total discriminator loss:0.31790629243867974\n",
      "Training Step: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "95it [00:18,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.31510898733450726\n",
      "Training Step: 96\n",
      "total discriminator loss:0.3127435862516952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:19,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 97\n",
      "total discriminator loss:0.3042343162319759\n",
      "Training Step: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "98it [00:19,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3015667818804445\n",
      "Training Step: 99\n",
      "total discriminator loss:0.3036764912743922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:19,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 100\n",
      "total discriminator loss:0.2833421220417538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:19,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "OPTIMIZER = Adam(lr=1e-3)\n",
    "_TOTAL_STEPS = 100\n",
    "\n",
    "for feature_batch, labels in tqdm(pretrain_D_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    step += 1\n",
    "    print('Training Step:', step)\n",
    "\n",
    "    disc_token_loss = pretrain_discriminator(event_type_batch, time_delta_batch, labels, pretrained_discriminator, verbose=True, optimizer=OPTIMIZER)\n",
    "    pretrain_disc_token_loss_history.append(disc_token_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "working-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/pretrained_disc_weights'):\n",
    "    os.makedirs(model_save_dir + '/pretrained_disc_weights')\n",
    "\n",
    "D_save_path = model_save_dir + '/pretrained_disc_weights/model.tf'\n",
    "pretrained_discriminator.save_weights(D_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cultural-travel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      112         event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_67 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_lstm (TimeLSTM1)           [(256, 16), (256, 16 2464        tf_op_layer_concat_67[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (256, 32)            0           time_lstm[0][0]                  \n",
      "                                                                 time_lstm[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (256, 32)            0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "final (Dense)                   (256, 1)             33          dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,609\n",
      "Trainable params: 2,609\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload_pretrained_disc = build_D(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,    \n",
    "    dropout_rate=0.25)\n",
    "\n",
    "reload_pretrained_disc.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "reload_pretrained_disc.load_weights(D_save_path)\n",
    "reload_pretrained_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-bacon",
   "metadata": {},
   "source": [
    "## Gumbel  Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "indian-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_gumbel(generator, discriminator, batch_size, T, verbose=False,                   \n",
    "                    optimizer=Adam(lr=0.001)):\n",
    "    \n",
    "    with tf.GradientTape() as tape:                        \n",
    "\n",
    "        G_sample_et, G_sample_ts = generate_sequences_gumbel(batch_size, generator, batch_size, T)\n",
    "        D_fake = discriminator([G_sample_et, G_sample_ts])\n",
    "\n",
    "        generator_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(D_fake), D_fake))\n",
    "        \n",
    "    if verbose:\n",
    "        print('generator loss:{}'.format(generator_loss))\n",
    "        print('-----------------------')\n",
    "\n",
    "    # update generator\n",
    "    generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "\n",
    "    return generator_loss\n",
    "\n",
    "\n",
    "def train_discriminator_gumbel(real_data_batch_et, real_data_batch_ts, generator, discriminator, batch_size, T, verbose=False,\n",
    "                        optimizer=Adam(lr=0.001), label_smoothing=False, label_flipping=False):\n",
    "\n",
    "    # data prep\n",
    "    real_labels = tf.ones((batch_size//2, 1))        \n",
    "    fake_labels = tf.zeros((batch_size//2, 1))    \n",
    "    \n",
    "    real_data_batch_et, real_data_batch_ts = real_data_batch_et[:batch_size//2, :, :], real_data_batch_ts[:batch_size//2, :, :]    \n",
    "    fake_data_batch_et, fake_data_batch_ts = generate_sequences_gumbel(batch_size//2, generator, batch_size, T)\n",
    "    \n",
    "    if label_smoothing:\n",
    "        fake_labels = fake_labels + tf.random.normal(fake_labels.shape, mean=0, stddev=0.3)\n",
    "        fake_labels = tf.clip_by_value(fake_labels, clip_value_min=0., clip_value_max=0.3)\n",
    "\n",
    "        real_labels = real_labels + tf.random.normal(real_labels.shape, mean=0, stddev=0.3)\n",
    "        real_labels = tf.clip_by_value(real_labels, clip_value_min=0.7, clip_value_max=1.0)\n",
    "\n",
    "    if label_flipping:\n",
    "        if tf.random.uniform((1,)) < 0.05:\n",
    "            fake_labels, real_labels = real_labels, fake_labels\n",
    "    \n",
    "    total_data_et = tf.concat([fake_data_batch_et, real_data_batch_et], axis=0)\n",
    "    total_data_ts = tf.concat([fake_data_batch_ts, real_data_batch_ts], axis=0)\n",
    "    total_labels = tf.concat([fake_labels, real_labels], axis=0)        \n",
    "        \n",
    "    # train the discriminator\n",
    "    with tf.GradientTape() as tape:                                                           \n",
    "        # train discriminator\n",
    "        pred_prob = discriminator([total_data_et, total_data_ts])\n",
    "\n",
    "        # cross-entropy loss\n",
    "        discriminator_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(total_labels, pred_prob, from_logits=False))\n",
    "\n",
    "        # average true return\n",
    "        average_true_return = tf.reduce_mean(pred_prob)\n",
    "        \n",
    "        if verbose:\n",
    "            print('total discriminator loss:{}'.format(discriminator_loss))\n",
    "            print('average true return:{}'.format(average_true_return))\n",
    "            print('-----------------------')\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    return discriminator_loss, average_true_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "immediate-perry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      112         event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_72 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_lstm (TimeLSTM1)           [(256, 16), (256, 16 2464        tf_op_layer_concat_72[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_noise (InputLayer)       [(256, 16)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_73 (TensorFl [(256, 32)]          0           time_lstm[0][0]                  \n",
      "                                                                 hidden_noise[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_74 (TensorFl [(256, 32)]          0           time_lstm[0][1]                  \n",
      "                                                                 hidden_noise[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_token (Dense)             (256, 6)             198         tf_op_layer_concat_73[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_time (Dense)              (256, 1)             33          tf_op_layer_concat_74[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,807\n",
      "Trainable params: 2,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "event_type (InputLayer)         [(256, None, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_emb (Dense)               (256, None, 16)      112         event_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_delta_in (InputLayer)      [(256, None, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_75 (TensorFl [(256, None, 17)]    0           dense_emb[0][0]                  \n",
      "                                                                 time_delta_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_lstm (TimeLSTM1)           [(256, 16), (256, 16 2464        tf_op_layer_concat_75[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (256, 32)            0           time_lstm[0][0]                  \n",
      "                                                                 time_lstm[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (256, 32)            0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "final (Dense)                   (256, 1)             33          dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,609\n",
      "Trainable params: 2,609\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_save_path = model_save_dir + '/pretrained_gen_weights/model.tf'\n",
    "D_save_path = model_save_dir + '/pretrained_disc_weights/model.tf'\n",
    "\n",
    "G = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "\n",
    "G.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "G.load_weights(G_save_path)\n",
    "G.summary()\n",
    "\n",
    "D = build_D(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    T=T,\n",
    "    event_vocab_dim=EVENT_VOCAB_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,    \n",
    "    dropout_rate=0.25)\n",
    "\n",
    "D.build(input_shape=((BATCH_SIZE, T, 1)))\n",
    "D.load_weights(D_save_path)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "twelve-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total_G = pos_event_type_seqs.shape[0]\n",
    "\n",
    "EPOCHS = 1\n",
    "_TOTAL_STEPS = int(EPOCHS * N_total_G / BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_dataset = create_dataset((pos_event_type_seqs, pos_timestamp_seqs),\n",
    "                             np.ones((N_total_G, 1)),\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             epochs=EPOCHS,\n",
    "                             buffer_size=N_total_G)\n",
    "\n",
    "gen_loss_history = []\n",
    "disc_loss_history = []\n",
    "average_true_return_history = []\n",
    "\n",
    "step = 0\n",
    "\n",
    "G_optimizer = Adam(learning_rate=1e-3)\n",
    "D_optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "_G_STEPS = 1\n",
    "_D_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "tribal-parking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1\n",
      "generator loss:1.0510841162965103\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35805379997320397\n",
      "average true return:0.554798941822021\n",
      "-----------------------\n",
      "Training Step: 2\n",
      "generator loss:1.2671331859094122\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3607415072589883\n",
      "average true return:0.5284976827562917\n",
      "-----------------------\n",
      "Training Step: 3\n",
      "generator loss:1.4468470434143725\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3653486116201786\n",
      "average true return:0.5179288955941111\n",
      "-----------------------\n",
      "Training Step: 4\n",
      "generator loss:1.5326956438936308\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:04,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3245841807430946\n",
      "average true return:0.5062767445462253\n",
      "-----------------------\n",
      "Training Step: 5\n",
      "generator loss:1.5845799320204268\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:05,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3401552730343198\n",
      "average true return:0.5004328894797614\n",
      "-----------------------\n",
      "Training Step: 6\n",
      "generator loss:1.637062816189884\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:06,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:1.5492425430406471\n",
      "average true return:0.4935092648545836\n",
      "-----------------------\n",
      "Training Step: 7\n",
      "generator loss:1.6619902812001417\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:07,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36523070480253583\n",
      "average true return:0.4867366210500341\n",
      "-----------------------\n",
      "Training Step: 8\n",
      "generator loss:1.6790290146612976\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:08,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3653744205096251\n",
      "average true return:0.4808555164608638\n",
      "-----------------------\n",
      "Training Step: 9\n",
      "generator loss:1.685658882237794\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:10,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3735588994048117\n",
      "average true return:0.47108766011407766\n",
      "-----------------------\n",
      "Training Step: 10\n",
      "generator loss:1.6882606295272629\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:11,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3673825222149455\n",
      "average true return:0.46418986322414374\n",
      "-----------------------\n",
      "Training Step: 11\n",
      "generator loss:1.6897740455230066\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:12,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36176513567857166\n",
      "average true return:0.4623096527569984\n",
      "-----------------------\n",
      "Training Step: 12\n",
      "generator loss:1.6915597485239011\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:13,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3705536895734103\n",
      "average true return:0.46437505965231385\n",
      "-----------------------\n",
      "Training Step: 13\n",
      "generator loss:1.6913636059997041\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:14,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3661908069105334\n",
      "average true return:0.46453298596236287\n",
      "-----------------------\n",
      "Training Step: 14\n",
      "generator loss:1.6888275818534724\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:15,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3579870941348388\n",
      "average true return:0.4684477403446317\n",
      "-----------------------\n",
      "Training Step: 15\n",
      "generator loss:1.6817593662621038\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:16,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3640142947778483\n",
      "average true return:0.46498574441271123\n",
      "-----------------------\n",
      "Training Step: 16\n",
      "generator loss:1.6771771597269853\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:17,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3654435779690472\n",
      "average true return:0.47323502468744955\n",
      "-----------------------\n",
      "Training Step: 17\n",
      "generator loss:1.6712485325886832\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:18,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36482644056077396\n",
      "average true return:0.47225376010349907\n",
      "-----------------------\n",
      "Training Step: 18\n",
      "generator loss:1.6670828216698077\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:19,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3730203465566807\n",
      "average true return:0.47640015066207464\n",
      "-----------------------\n",
      "Training Step: 19\n",
      "generator loss:1.6619005001095557\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:20,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35503780621942527\n",
      "average true return:0.4788738902570921\n",
      "-----------------------\n",
      "Training Step: 20\n",
      "generator loss:1.6584112316599695\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:22,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36637800146776967\n",
      "average true return:0.4777581766509695\n",
      "-----------------------\n",
      "Training Step: 21\n",
      "generator loss:1.6542244476125028\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:23,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3372743374824425\n",
      "average true return:0.48655029037244985\n",
      "-----------------------\n",
      "Training Step: 22\n",
      "generator loss:1.6457088240345876\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:24,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.34957202935721854\n",
      "average true return:0.4892343901540014\n",
      "-----------------------\n",
      "Training Step: 23\n",
      "generator loss:1.636117679001701\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:25,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36478446698128464\n",
      "average true return:0.4936172711290468\n",
      "-----------------------\n",
      "Training Step: 24\n",
      "generator loss:1.6344792007337614\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:26,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3544273799051934\n",
      "average true return:0.4908110077588439\n",
      "-----------------------\n",
      "Training Step: 25\n",
      "generator loss:1.624326762087023\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [00:27,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3648236620508486\n",
      "average true return:0.4921717047598558\n",
      "-----------------------\n",
      "Training Step: 26\n",
      "generator loss:1.621378381494595\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [00:28,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3470113226972842\n",
      "average true return:0.49712712006160564\n",
      "-----------------------\n",
      "Training Step: 27\n",
      "generator loss:1.6139925426184223\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [00:29,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3476199380132639\n",
      "average true return:0.4962818017782519\n",
      "-----------------------\n",
      "Training Step: 28\n",
      "generator loss:1.6094524949698634\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [00:30,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3405125662073902\n",
      "average true return:0.49764787141802713\n",
      "-----------------------\n",
      "Training Step: 29\n",
      "generator loss:1.6088126424899847\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [00:31,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33456918939672875\n",
      "average true return:0.49342006386095705\n",
      "-----------------------\n",
      "Training Step: 30\n",
      "generator loss:1.6030677586735584\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [00:32,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3463830265776569\n",
      "average true return:0.4951363233779371\n",
      "-----------------------\n",
      "Training Step: 31\n",
      "generator loss:1.591244862489035\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [00:34,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3647329555872575\n",
      "average true return:0.49521025933824836\n",
      "-----------------------\n",
      "Training Step: 32\n",
      "generator loss:1.5821338276208559\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [00:35,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3406238507021392\n",
      "average true return:0.4991483611892278\n",
      "-----------------------\n",
      "Training Step: 33\n",
      "generator loss:1.5757121743833422\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [00:36,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3418210089196301\n",
      "average true return:0.4976135899030754\n",
      "-----------------------\n",
      "Training Step: 34\n",
      "generator loss:1.5500201707138666\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [00:37,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35664048181902136\n",
      "average true return:0.5023636653117498\n",
      "-----------------------\n",
      "Training Step: 35\n",
      "generator loss:1.534348151152766\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [00:38,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33672422508349587\n",
      "average true return:0.5003340715081959\n",
      "-----------------------\n",
      "Training Step: 36\n",
      "generator loss:1.5169271953815728\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [00:39,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3235212085874803\n",
      "average true return:0.4990378375295246\n",
      "-----------------------\n",
      "Training Step: 37\n",
      "generator loss:1.5102062396586884\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [00:40,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3411965524568027\n",
      "average true return:0.5027232386054685\n",
      "-----------------------\n",
      "Training Step: 38\n",
      "generator loss:1.4988620954366398\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [00:41,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35695223513543217\n",
      "average true return:0.5009484315132234\n",
      "-----------------------\n",
      "Training Step: 39\n",
      "generator loss:1.496541309099301\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [00:42,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3572620883666889\n",
      "average true return:0.4977753796617197\n",
      "-----------------------\n",
      "Training Step: 40\n",
      "generator loss:1.4918505339105121\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [00:43,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33703484433729575\n",
      "average true return:0.49809507875698233\n",
      "-----------------------\n",
      "Training Step: 41\n",
      "generator loss:1.4892542232314545\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [00:44,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.34702822102800734\n",
      "average true return:0.49869230835460376\n",
      "-----------------------\n",
      "Training Step: 42\n",
      "generator loss:1.486788938844592\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [00:45,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3169854343715386\n",
      "average true return:0.497856646978776\n",
      "-----------------------\n",
      "Training Step: 43\n",
      "generator loss:1.4788682030875424\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [00:47,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33560311534257836\n",
      "average true return:0.4966452120275259\n",
      "-----------------------\n",
      "Training Step: 44\n",
      "generator loss:1.4773430057815977\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [00:48,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33698758553542546\n",
      "average true return:0.5001815951936162\n",
      "-----------------------\n",
      "Training Step: 45\n",
      "generator loss:1.4764211436845058\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [00:49,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3480092928923334\n",
      "average true return:0.5011782331717798\n",
      "-----------------------\n",
      "Training Step: 46\n",
      "generator loss:1.4623160726892932\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [00:50,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3247175689836924\n",
      "average true return:0.49731570254269286\n",
      "-----------------------\n",
      "Training Step: 47\n",
      "generator loss:1.452941859177184\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [00:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35239822933133474\n",
      "average true return:0.4980542966578394\n",
      "-----------------------\n",
      "Training Step: 48\n",
      "generator loss:1.4353789394997274\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [00:52,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.34592112031666666\n",
      "average true return:0.49782633465916226\n",
      "-----------------------\n",
      "Training Step: 49\n",
      "generator loss:1.423269923164484\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [00:53,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3297845452481652\n",
      "average true return:0.49295191082426226\n",
      "-----------------------\n",
      "Training Step: 50\n",
      "generator loss:1.4167417989891176\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "50it [00:54,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3163951572030293\n",
      "average true return:0.4946060088154984\n",
      "-----------------------\n",
      "Training Step: 51\n",
      "generator loss:1.3979985777370896\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [00:56,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.31863135350458394\n",
      "average true return:0.4955574956399207\n",
      "-----------------------\n",
      "Training Step: 52\n",
      "generator loss:1.3732654453241595\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52it [00:57,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32869681656574595\n",
      "average true return:0.4938900496622831\n",
      "-----------------------\n",
      "Training Step: 53\n",
      "generator loss:1.3547447285111867\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [00:58,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36178513616372543\n",
      "average true return:0.493131917408166\n",
      "-----------------------\n",
      "Training Step: 54\n",
      "generator loss:1.3319942861329892\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [00:59,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3079277332155243\n",
      "average true return:0.49592118949775715\n",
      "-----------------------\n",
      "Training Step: 55\n",
      "generator loss:1.3200894403602321\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [01:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3189195925738853\n",
      "average true return:0.49270884317069125\n",
      "-----------------------\n",
      "Training Step: 56\n",
      "generator loss:1.3031126413499554\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [01:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3165811448755339\n",
      "average true return:0.4948198872649074\n",
      "-----------------------\n",
      "Training Step: 57\n",
      "generator loss:1.2834507024553667\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [01:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.30488031148103845\n",
      "average true return:0.4949661102713909\n",
      "-----------------------\n",
      "Training Step: 58\n",
      "generator loss:1.2722997109918195\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [01:03,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.31067230548010544\n",
      "average true return:0.49185132886748884\n",
      "-----------------------\n",
      "Training Step: 59\n",
      "generator loss:1.2584080733115097\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [01:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33352454115993047\n",
      "average true return:0.4940536455130042\n",
      "-----------------------\n",
      "Training Step: 60\n",
      "generator loss:1.2433370824572039\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [01:05,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3137450658462119\n",
      "average true return:0.49212884776472776\n",
      "-----------------------\n",
      "Training Step: 61\n",
      "generator loss:1.2268729735567716\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [01:06,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3295134125750352\n",
      "average true return:0.489737571268546\n",
      "-----------------------\n",
      "Training Step: 62\n",
      "generator loss:1.2064167659366465\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [01:07,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.331609474055305\n",
      "average true return:0.496076032213592\n",
      "-----------------------\n",
      "Training Step: 63\n",
      "generator loss:1.193008726674238\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [01:09,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33392182738541765\n",
      "average true return:0.4981630530205735\n",
      "-----------------------\n",
      "Training Step: 64\n",
      "generator loss:1.1912771326465021\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [01:10,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3300379215856723\n",
      "average true return:0.49591358637717\n",
      "-----------------------\n",
      "Training Step: 65\n",
      "generator loss:1.1916016469653208\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [01:11,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32080319422197984\n",
      "average true return:0.4942058143907656\n",
      "-----------------------\n",
      "Training Step: 66\n",
      "generator loss:1.191782725168684\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [01:12,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3111174747771014\n",
      "average true return:0.4955052725198159\n",
      "-----------------------\n",
      "Training Step: 67\n",
      "generator loss:1.193417827730424\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [01:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.337682503672697\n",
      "average true return:0.49836096173257627\n",
      "-----------------------\n",
      "Training Step: 68\n",
      "generator loss:1.2012355008349782\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [01:14,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3383915123728045\n",
      "average true return:0.4944490975864865\n",
      "-----------------------\n",
      "Training Step: 69\n",
      "generator loss:1.2120305800345512\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [01:15,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.31963976314327724\n",
      "average true return:0.48992619849208213\n",
      "-----------------------\n",
      "Training Step: 70\n",
      "generator loss:1.2199338232483299\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [01:16,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3417232722830291\n",
      "average true return:0.48740064616964374\n",
      "-----------------------\n",
      "Training Step: 71\n",
      "generator loss:1.2215446199567692\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [01:18,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:1.8240779088615346\n",
      "average true return:0.4914953025969415\n",
      "-----------------------\n",
      "Training Step: 72\n",
      "generator loss:1.2007871270920496\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "72it [01:19,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.30859346824799505\n",
      "average true return:0.4909466753434748\n",
      "-----------------------\n",
      "Training Step: 73\n",
      "generator loss:1.1790291644147561\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "73it [01:20,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3277296319768509\n",
      "average true return:0.4907406222203766\n",
      "-----------------------\n",
      "Training Step: 74\n",
      "generator loss:1.1614501843493827\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "74it [01:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3528004486389563\n",
      "average true return:0.4900608902771989\n",
      "-----------------------\n",
      "Training Step: 75\n",
      "generator loss:1.1479845846017613\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "75it [01:22,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3278978875295355\n",
      "average true return:0.49104287917371925\n",
      "-----------------------\n",
      "Training Step: 76\n",
      "generator loss:1.1378891227923866\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "76it [01:23,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33833755274892974\n",
      "average true return:0.4918334220276258\n",
      "-----------------------\n",
      "Training Step: 77\n",
      "generator loss:1.1308650173460495\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "77it [01:24,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3439411042436734\n",
      "average true return:0.4930668985830022\n",
      "-----------------------\n",
      "Training Step: 78\n",
      "generator loss:1.1273721308415747\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "78it [01:25,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:1.701186844775128\n",
      "average true return:0.4931259302102364\n",
      "-----------------------\n",
      "Training Step: 79\n",
      "generator loss:1.1182250930592403\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "79it [01:26,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33690650333241745\n",
      "average true return:0.4930061159084732\n",
      "-----------------------\n",
      "Training Step: 80\n",
      "generator loss:1.1083808505325492\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "80it [01:27,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3308698958732609\n",
      "average true return:0.4933123639773119\n",
      "-----------------------\n",
      "Training Step: 81\n",
      "generator loss:1.0986176675087997\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "81it [01:28,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3462443222711665\n",
      "average true return:0.4953988425277176\n",
      "-----------------------\n",
      "Training Step: 82\n",
      "generator loss:1.0904975824744914\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "82it [01:30,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33339782812067303\n",
      "average true return:0.4990473155996352\n",
      "-----------------------\n",
      "Training Step: 83\n",
      "generator loss:1.0806650940522537\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "83it [01:31,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33247808295306447\n",
      "average true return:0.49765084040763324\n",
      "-----------------------\n",
      "Training Step: 84\n",
      "generator loss:1.0737337416072223\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "84it [01:32,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32746311263216704\n",
      "average true return:0.49898785579572186\n",
      "-----------------------\n",
      "Training Step: 85\n",
      "generator loss:1.0659001754598347\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "85it [01:33,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3386252869372105\n",
      "average true return:0.499767063965332\n",
      "-----------------------\n",
      "Training Step: 86\n",
      "generator loss:1.0602004768904583\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "86it [01:34,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3208079530281658\n",
      "average true return:0.5000581072943722\n",
      "-----------------------\n",
      "Training Step: 87\n",
      "generator loss:1.0553678526181924\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "87it [01:35,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32530231287729366\n",
      "average true return:0.5019345479025401\n",
      "-----------------------\n",
      "Training Step: 88\n",
      "generator loss:1.056075494017543\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "88it [01:36,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.36087568032280826\n",
      "average true return:0.49992898231304517\n",
      "-----------------------\n",
      "Training Step: 89\n",
      "generator loss:1.0570662285678964\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "89it [01:37,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3583150815482391\n",
      "average true return:0.49942051043586627\n",
      "-----------------------\n",
      "Training Step: 90\n",
      "generator loss:1.055237393322571\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "90it [01:38,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.33050587032940015\n",
      "average true return:0.5005739844829846\n",
      "-----------------------\n",
      "Training Step: 91\n",
      "generator loss:1.0538670645777914\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "91it [01:40,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.334832777069692\n",
      "average true return:0.5018217287191143\n",
      "-----------------------\n",
      "Training Step: 92\n",
      "generator loss:1.0531669255187284\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "92it [01:41,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.34585539798649834\n",
      "average true return:0.5023985651958811\n",
      "-----------------------\n",
      "Training Step: 93\n",
      "generator loss:1.0517461498512963\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "93it [01:42,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.34927813590907997\n",
      "average true return:0.502238042265104\n",
      "-----------------------\n",
      "Training Step: 94\n",
      "generator loss:1.05075683424967\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "94it [01:43,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.35102467305511\n",
      "average true return:0.502917139508853\n",
      "-----------------------\n",
      "Training Step: 95\n",
      "generator loss:1.0507085998374999\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "95it [01:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3407236474426546\n",
      "average true return:0.5026599048616434\n",
      "-----------------------\n",
      "Training Step: 96\n",
      "generator loss:1.0497517339357503\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "96it [01:45,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3290412541130655\n",
      "average true return:0.5038893961381217\n",
      "-----------------------\n",
      "Training Step: 97\n",
      "generator loss:1.047941361546074\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "97it [01:46,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.32539562501440045\n",
      "average true return:0.5058901659365582\n",
      "-----------------------\n",
      "Training Step: 98\n",
      "generator loss:1.0472724605368777\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "98it [01:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:1.6871064264192754\n",
      "average true return:0.5057546848473615\n",
      "-----------------------\n",
      "Training Step: 99\n",
      "generator loss:1.0352500351658158\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "99it [01:48,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3454050075822681\n",
      "average true return:0.5077917515880678\n",
      "-----------------------\n",
      "Training Step: 100\n",
      "generator loss:1.0254171248139006\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100it [01:50,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total discriminator loss:0.3106748893595338\n",
      "average true return:0.5082735176396278\n",
      "-----------------------\n",
      "Training Step: 101\n",
      "generator loss:1.0185875318917101\n",
      "-----------------------\n",
      "total discriminator loss:0.3263390576399599\n",
      "average true return:0.5103026811278453\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:51,  1.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-980f75635ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         disc_loss, ave_true_return = train_discriminator_gumbel(event_type_batch, time_delta_batch, G, D, BATCH_SIZE, T,\n\u001b[1;32m     13\u001b[0m                                                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                                                 label_smoothing=True, label_flipping=True)\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdisc_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maverage_true_return_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mave_true_return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-17bffeb92cce>\u001b[0m in \u001b[0;36mtrain_discriminator_gumbel\u001b[0;34m(real_data_batch_et, real_data_batch_ts, generator, discriminator, batch_size, T, verbose, optimizer, label_smoothing, label_flipping)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[0;32m-> 1226\u001b[0;31m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[1;32m   1227\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[0;34m(x, y, grad)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       and isinstance(grad, ops.Tensor)):\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m   \"\"\"\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m     if isinstance(\n\u001b[1;32m    565\u001b[0m         input, (sparse_tensor.SparseTensor, sparse_tensor.SparseTensorValue)):\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values)\u001b[0m\n\u001b[1;32m   6179\u001b[0m     \u001b[0;31m# TODO(slebedev): this is Keras-specific and should be removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6180\u001b[0m     \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6181\u001b[0;31m     graph_value = next((value for value in values if type(value) == Tensor),\n\u001b[0m\u001b[1;32m   6182\u001b[0m                        None)\n\u001b[1;32m   6183\u001b[0m     \u001b[0;31m# pylint: enable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature_batch, _ in tqdm(train_dataset.take(_TOTAL_STEPS)):\n",
    "    event_type_batch, time_delta_batch = feature_batch\n",
    "    step += 1\n",
    "    print('Training Step:', step)\n",
    "    # train the generator\n",
    "    for _ in range(_G_STEPS):\n",
    "        gen_loss = train_generator_gumbel(G, D, BATCH_SIZE, T, verbose=True, optimizer=G_optimizer)\n",
    "        gen_loss_history.append(gen_loss.numpy())\n",
    "    \n",
    "    # train the discriminator\n",
    "    for _ in range(_D_STEPS):\n",
    "        disc_loss, ave_true_return = train_discriminator_gumbel(event_type_batch, time_delta_batch, G, D, BATCH_SIZE, T,\n",
    "                                                                verbose=True, optimizer=D_optimizer, \n",
    "                                                                label_smoothing=True, label_flipping=True)\n",
    "        disc_loss_history.append(disc_loss.numpy())\n",
    "        average_true_return_history.append(ave_true_return.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "floral-annual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training steps')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(gen_loss_history))\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, gen_loss_history)\n",
    "plt.title('Generator Loss History')\n",
    "plt.xlabel('Training steps')\n",
    "\n",
    "x = range(len(disc_loss_history))\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, disc_loss_history)\n",
    "plt.title('Discriminator Loss History')\n",
    "plt.xlabel('Training steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-fossil",
   "metadata": {},
   "source": [
    "## Compare generated sequences between Random G and trained G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "tropical-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = build_G(\n",
    "    batch_size = BATCH_SIZE,\n",
    "    event_vocab_dim = EVENT_VOCAB_DIM,\n",
    "    emb_dim = EMB_DIM,\n",
    "    hidden_dim= HIDDEN_DIM,\n",
    ")\n",
    "seqs_random_et, seqs_random_ts = generate_sequences_gumbel(1000, G0,BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "muslim-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_trained_et, seqs_trained_ts = generate_sequences_gumbel(1000, G, BATCH_SIZE, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "greater-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 21), dtype=int64, numpy=\n",
       "array([[1, 2, 4, ..., 1, 4, 4],\n",
       "       [1, 1, 4, ..., 1, 3, 5],\n",
       "       [1, 5, 4, ..., 4, 0, 1],\n",
       "       ...,\n",
       "       [1, 4, 4, ..., 2, 0, 5],\n",
       "       [1, 1, 2, ..., 2, 1, 2],\n",
       "       [1, 1, 4, ..., 3, 1, 5]])>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(seqs_random_et, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "threaded-kernel",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected dimension in the range [-2, 2), but got 2 [Op:ArgMax]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-26b78079a66d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_trained_et\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36margmax_v2\u001b[0;34m(input, axis, output_type, name)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36marg_max\u001b[0;34m(input, dimension, output_type, name)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/basileus/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [-2, 2), but got 2 [Op:ArgMax]"
     ]
    }
   ],
   "source": [
    "tf.argmax(seqs_trained_et, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-cuisine",
   "metadata": {},
   "source": [
    "## Save trained G and D weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir + '/G_run_2021-03-27'):\n",
    "    os.makedirs(model_save_dir + '/G_run_2021-03-27')\n",
    "\n",
    "G_save_path = model_save_dir + '/G_run_2021-03-27/model.tf'\n",
    "                \n",
    "if not os.path.exists(model_save_dir + '/D_run_2021-03-27'):\n",
    "    os.makedirs(model_save_dir + '/D_run_2021-03-27')\n",
    "\n",
    "D_save_path = model_save_dir + '/D_run_2021-03-27/model.tf'\n",
    "\n",
    "G.save_weights(G_save_path)\n",
    "D.save_weights(D_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-selling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
